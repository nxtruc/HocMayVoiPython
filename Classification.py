import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import openml
import joblib
import shutil
import pandas as pd
import os
import mlflow
from sklearn import datasets
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import cross_val_score, KFold
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from streamlit_drawable_canvas import st_canvas
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from streamlit_drawable_canvas import st_canvas
from PIL import Image, ImageOps
from mlflow.tracking import MlflowClient

# Load dá»¯ liá»‡u MNIST
def ly_thuyet_Decision_tree():
    st.header("ğŸ“– LÃ½ thuyáº¿t vá» Decision Tree") 
    st.header("ğŸŒ³ Giá»›i thiá»‡u vá» Decision Tree")
    st.markdown(" ### 1ï¸âƒ£ Decision Tree lÃ  gÃ¬?")
    st.write("""
    Decision Tree (CÃ¢y quyáº¿t Ä‘á»‹nh) lÃ  má»™t thuáº­t toÃ¡n há»c cÃ³ giÃ¡m sÃ¡t Ä‘Æ°á»£c sá»­ dá»¥ng trong **phÃ¢n loáº¡i (classification)** vÃ  **há»“i quy (regression)**.
    NÃ³ hoáº¡t Ä‘á»™ng báº±ng cÃ¡ch chia dá»¯ liá»‡u thÃ nh cÃ¡c nhÃ³m nhá» hÆ¡n dá»±a trÃªn cÃ¡c Ä‘iá»u kiá»‡n Ä‘Æ°á»£c thiáº¿t láº­p táº¡i cÃ¡c **nÃºt (nodes)** cá»§a cÃ¢y.
    """) 
    
    st.markdown(" ### ğŸ“Œ Cáº¥u trÃºc cá»§a Decision Tree") 
    image_url = "https://trituenhantao.io/wp-content/uploads/2019/06/dt.png"
    st.image(image_url, caption="VÃ­ dá»¥ vá» cÃ¡ch CÃ¢y quyáº¿t Ä‘á»‹nh phÃ¢n chia dá»¯ liá»‡u", use_column_width=True)

    st.write("""
    - **NÃºt gá»‘c (Root Node)**: LÃ  Ä‘iá»ƒm báº¯t Ä‘áº§u cá»§a cÃ¢y, chá»©a toÃ n bá»™ dá»¯ liá»‡u.
    - **NÃºt quyáº¿t Ä‘á»‹nh (Decision Nodes)**: CÃ¡c nÃºt trung gian nÆ¡i dá»¯ liá»‡u Ä‘Æ°á»£c chia nhá» dá»±a trÃªn má»™t Ä‘iá»u kiá»‡n.
    - **NhÃ¡nh (Branches)**: CÃ¡c Ä‘Æ°á»ng ná»‘i giá»¯a cÃ¡c nÃºt, thá»ƒ hiá»‡n lá»±a chá»n cÃ³ thá»ƒ xáº£y ra.
    - **NÃºt lÃ¡ (Leaf Nodes)**: Äiá»ƒm cuá»‘i cá»§a cÃ¢y, Ä‘áº¡i diá»‡n cho quyáº¿t Ä‘á»‹nh cuá»‘i cÃ¹ng hoáº·c nhÃ£n dá»± Ä‘oÃ¡n.
    """)

    st.markdown(" ### ğŸ” CÃ¡ch hoáº¡t Ä‘á»™ng cá»§a Decision Tree")
    st.write("""
    1. **Chá»n Ä‘áº·c trÆ°ng tá»‘t nháº¥t Ä‘á»ƒ chia dá»¯ liá»‡u** báº±ng cÃ¡c tiÃªu chÃ­ nhÆ°:
    - Gini Impurity: ÄÃ¡nh giÃ¡ Ä‘á»™ láº«n lá»™n cá»§a táº­p dá»¯ liá»‡u.
    - Entropy (dÃ¹ng trong ID3): XÃ¡c Ä‘á»‹nh má»©c Ä‘á»™ khÃ´ng cháº¯c cháº¯n.
    - Reduction in Variance (dÃ¹ng cho há»“i quy).
    2. **Táº¡o cÃ¡c nhÃ¡nh con** tá»« Ä‘áº·c trÆ°ng Ä‘Æ°á»£c chá»n.
    3. **Láº·p láº¡i quy trÃ¬nh** trÃªn tá»«ng nhÃ¡nh con cho Ä‘áº¿n khi Ä‘áº¡t Ä‘iá»u kiá»‡n dá»«ng.
    4. **Dá»± Ä‘oÃ¡n dá»¯ liá»‡u má»›i** báº±ng cÃ¡ch Ä‘i theo cÃ¢y tá»« gá»‘c Ä‘áº¿n lÃ¡.
    """)

    st.markdown("### ğŸŒ³ CÃ´ng Thá»©c ChÃ­nh cá»§a CÃ¢y Quyáº¿t Äá»‹nh vÃ  CÃ¡ch Ãp Dá»¥ng")

    st.subheader("ğŸ“Œ 1. Entropy â€“ Äá»™ há»—n loáº¡n cá»§a dá»¯ liá»‡u")
    st.write("Entropy Ä‘o lÆ°á»ng má»©c Ä‘á»™ há»—n loáº¡n trong dá»¯ liá»‡u. Náº¿u má»™t táº­p dá»¯ liá»‡u cÃ ng Ä‘á»“ng nháº¥t, entropy cÃ ng tháº¥p.")
    st.latex(r"H(S) = - \sum_{i=1}^{c} p_i \log_2 p_i")

    st.write("""
    - Náº¿u táº¥t cáº£ dá»¯ liá»‡u thuá»™c cÃ¹ng má»™t lá»›p â†’ Entropy = 0 (thuáº§n khiáº¿t).
    - Náº¿u dá»¯ liá»‡u Ä‘Æ°á»£c phÃ¢n bá»‘ Ä‘á»u giá»¯a cÃ¡c lá»›p â†’ Entropy Ä‘áº¡t giÃ¡ trá»‹ cao nháº¥t.
    """)

    st.subheader("ğŸ“Œ 2. Information Gain â€“ Má»©c Ä‘á»™ giáº£m Ä‘á»™ há»—n loáº¡n sau khi chia dá»¯ liá»‡u")
    st.latex(r"IG = H(S) - \sum_{j=1}^{k} \frac{|S_j|}{|S|} H(S_j)")

    st.write("""
    - IG cÃ ng cao â†’ thuá»™c tÃ­nh Ä‘Ã³ giÃºp phÃ¢n loáº¡i dá»¯ liá»‡u tá»‘t hÆ¡n.
    - IG tháº¥p â†’ thuá»™c tÃ­nh Ä‘Ã³ khÃ´ng cÃ³ nhiá»u giÃ¡ trá»‹ trong viá»‡c phÃ¢n tÃ¡ch dá»¯ liá»‡u.
    """)

    st.subheader("ğŸ“Œ 3. Gini Impurity â€“ Äo lÆ°á»ng má»©c Ä‘á»™ há»—n loáº¡n thay tháº¿ Entropy")
    st.latex(r"Gini(S) = 1 - \sum_{i=1}^{c} p_i^2")

    st.write("""
    - Gini = 0 â†’ táº­p dá»¯ liá»‡u hoÃ n toÃ n thuáº§n khiáº¿t.
    - Gini cÃ ng cao â†’ dá»¯ liá»‡u cÃ ng há»—n loáº¡n.
    """)

    st.subheader("ğŸ’¡ CÃ¡ch Ãp Dá»¥ng Ä‘á»ƒ XÃ¢y Dá»±ng Decision Tree")
    st.write("""
    1. TÃ­nh Entropy hoáº·c Gini cá»§a táº­p dá»¯ liá»‡u ban Ä‘áº§u.
    2. TÃ­nh Entropy hoáº·c Gini cá»§a tá»«ng táº­p con sau khi chia theo tá»«ng thuá»™c tÃ­nh.
    3. TÃ­nh Information Gain cho tá»«ng thuá»™c tÃ­nh.
    4. Chá»n thuá»™c tÃ­nh cÃ³ Information Gain cao nháº¥t Ä‘á»ƒ chia nhÃ¡nh.
    5. Láº·p láº¡i quy trÃ¬nh trÃªn cho Ä‘áº¿n khi táº¥t cáº£ dá»¯ liá»‡u trong cÃ¡c nhÃ¡nh Ä‘á»u thuáº§n khiáº¿t hoáº·c Ä‘áº¡t Ä‘iá»u kiá»‡n dá»«ng.
    """)

    st.markdown("""
    **ğŸ“Œ LÆ°u Ã½:**  
    - Náº¿u cÃ¢y quÃ¡ sÃ¢u â†’ cÃ³ thá»ƒ gÃ¢y overfitting, cáº§n sá»­ dá»¥ng cáº¯t tá»‰a (pruning).  
    - Decision Tree cÃ³ thá»ƒ sá»­ dá»¥ng vá»›i cáº£ phÃ¢n loáº¡i (Classification) vÃ  há»“i quy (Regression).  
    """)

    st.write("ğŸš€ CÃ¢y quyáº¿t Ä‘á»‹nh lÃ  má»™t thuáº­t toÃ¡n máº¡nh máº½ vÃ  dá»… hiá»ƒu, nhÆ°ng cáº§n Ä‘iá»u chá»‰nh Ä‘á»ƒ trÃ¡nh overfitting vÃ  tá»‘i Æ°u hiá»‡u suáº¥t!") 
    
    
    
def ly_thuyet_SVM():
    # TiÃªu Ä‘á» chÃ­nh
    st.title("ğŸ“– LÃ½ Thuyáº¿t Vá» Support Vector Machine (SVM)")
    st.image("https://neralnetwork.wordpress.com/wp-content/uploads/2018/01/svm1.png", caption="HÃ¬nh minh há»a SVM")

    st.markdown("""
    Support Vector Machine (SVM) lÃ  má»™t thuáº­t toÃ¡n há»c mÃ¡y máº¡nh máº½ thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng cho bÃ i toÃ¡n **phÃ¢n loáº¡i (classification)** vÃ  **há»“i quy (regression)**. 
    NÃ³ hoáº¡t Ä‘á»™ng dá»±a trÃªn nguyÃªn lÃ½ tÃ¬m **siÃªu pháº³ng (hyperplane)** tá»‘i Æ°u Ä‘á»ƒ phÃ¢n tÃ¡ch dá»¯ liá»‡u.
    """)

    # 1. NguyÃªn lÃ½ hoáº¡t Ä‘á»™ng
    st.header("1. NguyÃªn LÃ½ Hoáº¡t Äá»™ng cá»§a SVM")

    st.subheader("ğŸ“Œ 1.1. TÃ¬m SiÃªu Pháº³ng Tá»‘i Æ¯u")
    st.markdown("""
    - Má»™t **siÃªu pháº³ng (hyperplane)** lÃ  má»™t Ä‘Æ°á»ng (trong khÃ´ng gian 2D) hoáº·c má»™t máº·t pháº³ng (trong khÃ´ng gian 3D) dÃ¹ng Ä‘á»ƒ phÃ¢n tÃ¡ch dá»¯ liá»‡u thÃ nh cÃ¡c nhÃ³m.
    - SVM tÃ¬m **siÃªu pháº³ng tá»‘i Æ°u** sao cho khoáº£ng cÃ¡ch tá»« siÃªu pháº³ng Ä‘áº¿n cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u gáº§n nháº¥t (**support vectors**) lÃ  lá»›n nháº¥t.
    """)

    st.write("ğŸš€ **CÃ´ng thá»©c siÃªu pháº³ng:**")
    st.latex(r"w \cdot x + b = 0")

    st.markdown("""
    Trong Ä‘Ã³:
    - \( w \) lÃ  **vector trá»ng sá»‘**,
    - \( x \) lÃ  **vector dá»¯ liá»‡u Ä‘áº§u vÃ o**,
    - \( b \) lÃ  **bias**.
    """)

    st.subheader("ğŸ“Œ 1.2. Khoáº£ng CÃ¡ch Lá» (Margin)")
    st.markdown("""
    - **Soft Margin SVM**: Cháº¥p nháº­n má»™t sá»‘ Ä‘iá»ƒm bá»‹ phÃ¢n loáº¡i sai nhÆ°ng tÄƒng kháº£ nÄƒng tá»•ng quÃ¡t hÃ³a (**giáº£m overfitting**).
    - **Hard Margin SVM**: YÃªu cáº§u phÃ¢n tÃ¡ch hoÃ n háº£o, khÃ´ng cho phÃ©p lá»—i nhÆ°ng dá»… bá»‹ **overfitting**.
    """)

    # 2. HÃ m má»¥c tiÃªu
    st.header("2. HÃ m Má»¥c TiÃªu trong SVM")
    st.markdown("""
    Má»¥c tiÃªu cá»§a SVM lÃ  tÃ¬m \( w \) vÃ  \( b \) Ä‘á»ƒ tá»‘i Ä‘a hÃ³a khoáº£ng cÃ¡ch lá» \( \frac{2}{||w||} \), tÆ°Æ¡ng Ä‘Æ°Æ¡ng vá»›i bÃ i toÃ¡n tá»‘i Æ°u:
    """)

    st.latex(r"\min_{w, b} \frac{1}{2} ||w||^2")

    st.markdown("Sao cho:")

    st.latex(r"y_i (w \cdot x_i + b) \geq 1, \forall i")

    st.markdown("""
    Trong Ä‘Ã³:
    - \( y_i \) lÃ  **nhÃ£n cá»§a dá»¯ liá»‡u** (1 hoáº·c -1),
    - \( x_i \) lÃ  **Ä‘iá»ƒm dá»¯ liá»‡u**.
    """)

    # 3. Kernel Trick
    st.header("3. Kernel Trick â€“ Má»Ÿ Rá»™ng SVM Cho Dá»¯ Liá»‡u Phi Tuyáº¿n")
    st.markdown("""
    Khi dá»¯ liá»‡u khÃ´ng thá»ƒ phÃ¢n tÃ¡ch tuyáº¿n tÃ­nh, SVM sá»­ dá»¥ng **hÃ m kernel** Ä‘á»ƒ Ã¡nh xáº¡ dá»¯ liá»‡u vÃ o khÃ´ng gian chiá»u cao hÆ¡n, nÆ¡i cÃ³ thá»ƒ phÃ¢n tÃ¡ch tuyáº¿n tÃ­nh.

    ğŸ“Œ **Má»™t sá»‘ loáº¡i Kernel phá»• biáº¿n**:
    """)

    st.subheader("1ï¸âƒ£ Linear Kernel")
    st.latex(r"K(x_i, x_j) = x_i \cdot x_j")
    st.markdown("ğŸ‘‰ Sá»­ dá»¥ng khi dá»¯ liá»‡u cÃ³ thá»ƒ phÃ¢n tÃ¡ch tuyáº¿n tÃ­nh.")

    st.subheader("2ï¸âƒ£ Polynomial Kernel")
    st.latex(r"K(x_i, x_j) = (x_i \cdot x_j + c)^d")
    st.markdown("ğŸ‘‰ PhÃ¹ há»£p vá»›i dá»¯ liá»‡u cÃ³ ranh giá»›i phi tuyáº¿n.")

    st.subheader("3ï¸âƒ£ Radial Basis Function (RBF) Kernel")
    st.latex(r"K(x_i, x_j) = \exp(- \gamma ||x_i - x_j||^2)")
    st.markdown("ğŸ‘‰ Phá»• biáº¿n nháº¥t vÃ¬ cÃ³ thá»ƒ xá»­ lÃ½ **má»i loáº¡i dá»¯ liá»‡u**.")

    st.write("ğŸš€ SVM lÃ  má»™t thuáº­t toÃ¡n máº¡nh máº½, nhÆ°ng cáº§n Ä‘iá»u chá»‰nh Ä‘Ãºng tham sá»‘ Ä‘á»ƒ Ä‘áº¡t hiá»‡u suáº¥t tá»‘i Æ°u!")


def data():
    st.header("MNIST Dataset")
    st.title("Tá»•ng quan vá» táº­p dá»¯ liá»‡u MNIST")

    st.header("1. Giá»›i thiá»‡u")
    st.write("Táº­p dá»¯ liá»‡u MNIST (Modified National Institute of Standards and Technology) lÃ  má»™t trong nhá»¯ng táº­p dá»¯ liá»‡u phá»• biáº¿n nháº¥t trong lÄ©nh vá»±c Machine Learning vÃ  Computer Vision, thÆ°á»ng Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ huáº¥n luyá»‡n vÃ  kiá»ƒm thá»­ cÃ¡c mÃ´ hÃ¬nh phÃ¢n loáº¡i chá»¯ sá»‘ viáº¿t tay.") 

    st.image("https://datasets.activeloop.ai/wp-content/uploads/2019/12/MNIST-handwritten-digits-dataset-visualized-by-Activeloop.webp", use_container_width=True)

    st.subheader("Ná»™i dung")
    st.write("- 70.000 áº£nh grayscale (Ä‘en tráº¯ng) cá»§a cÃ¡c chá»¯ sá»‘ viáº¿t tay tá»« 0 Ä‘áº¿n 9.")
    st.write("- KÃ­ch thÆ°á»›c áº£nh: 28x28 pixel.")
    st.write("- Äá»‹nh dáº¡ng: Má»—i áº£nh Ä‘Æ°á»£c biá»ƒu diá»…n báº±ng má»™t ma tráº­n 28x28 cÃ³ giÃ¡ trá»‹ pixel tá»« 0 (Ä‘en) Ä‘áº¿n 255 (tráº¯ng).")
    st.write("- NhÃ£n: Má»™t sá»‘ nguyÃªn tá»« 0 Ä‘áº¿n 9 tÆ°Æ¡ng á»©ng vá»›i chá»¯ sá»‘ trong áº£nh.")

    st.header("2. Nguá»“n gá»‘c vÃ  Ã½ nghÄ©a")
    st.write("- ÄÆ°á»£c táº¡o ra tá»« bá»™ dá»¯ liá»‡u chá»¯ sá»‘ viáº¿t tay gá»‘c cá»§a NIST, do LeCun, Cortes vÃ  Burges chuáº©n bá»‹.")
    st.write("- DÃ¹ng lÃ m benchmark cho cÃ¡c thuáº­t toÃ¡n nháº­n diá»‡n hÃ¬nh áº£nh, Ä‘áº·c biá»‡t lÃ  máº¡ng nÆ¡-ron nhÃ¢n táº¡o (ANN) vÃ  máº¡ng nÆ¡-ron tÃ­ch cháº­p (CNN).")
    st.write("- Ráº¥t há»¯u Ã­ch cho viá»‡c kiá»ƒm thá»­ mÃ´ hÃ¬nh trÃªn dá»¯ liá»‡u hÃ¬nh áº£nh thá»±c táº¿ nhÆ°ng Ä‘Æ¡n giáº£n.")

    st.header("3. PhÃ¢n chia táº­p dá»¯ liá»‡u")
    st.write("- Táº­p huáº¥n luyá»‡n: 60.000 áº£nh.")
    st.write("- Táº­p kiá»ƒm thá»­: 10.000 áº£nh.")
    st.write("- Má»—i táº­p cÃ³ phÃ¢n bá»‘ Ä‘á»“ng Ä‘á»u vá» sá»‘ lÆ°á»£ng chá»¯ sá»‘ tá»« 0 Ä‘áº¿n 9.")

    st.header("4. á»¨ng dá»¥ng")
    st.write("- Huáº¥n luyá»‡n vÃ  Ä‘Ã¡nh giÃ¡ cÃ¡c thuáº­t toÃ¡n nháº­n diá»‡n chá»¯ sá»‘ viáº¿t tay.")
    st.write("- Kiá»ƒm thá»­ vÃ  so sÃ¡nh hiá»‡u suáº¥t cá»§a cÃ¡c mÃ´ hÃ¬nh há»c sÃ¢u (Deep Learning).")
    st.write("- LÃ m bÃ i táº­p thá»±c hÃ nh vá» xá»­ lÃ½ áº£nh, trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng, mÃ´ hÃ¬nh phÃ¢n loáº¡i.")
    st.write("- Cung cáº¥p má»™t baseline Ä‘Æ¡n giáº£n cho cÃ¡c bÃ i toÃ¡n liÃªn quan Ä‘áº¿n Computer Vision.")

    st.header("5. PhÆ°Æ¡ng phÃ¡p tiáº¿p cáº­n phá»• biáº¿n")
    st.write("- TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng truyá»n thá»‘ng: PCA, HOG, SIFT...")
    st.write("- Machine Learning: KNN, SVM, Random Forest, Logistic Regression...")
    st.write("- Deep Learning: MLP, CNN (LeNet-5, AlexNet, ResNet...), RNN")

    st.caption("á»¨ng dá»¥ng hiá»ƒn thá»‹ thÃ´ng tin vá» táº­p dá»¯ liá»‡u MNIST báº±ng Streamlit ğŸš€")
    


def up_load_db():
    # TiÃªu Ä‘á»
    st.header("ğŸ“¥ Táº£i Dá»¯ Liá»‡u")

    # Kiá»ƒm tra xem dá»¯ liá»‡u Ä‘Ã£ táº£i chÆ°a
    if "data" in st.session_state and st.session_state.data is not None:
        st.warning("ğŸ”¸ **Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c táº£i lÃªn rá»“i!** Báº¡n cÃ³ thá»ƒ tiáº¿p tá»¥c vá»›i cÃ¡c bÆ°á»›c tiá»n xá»­ lÃ½ vÃ  chia dá»¯ liá»‡u.")
    else:
        # Chá»n nguá»“n dá»¯ liá»‡u
        option = st.radio("Chá»n nguá»“n dá»¯ liá»‡u:", ["Táº£i tá»« OpenML", "Upload dá»¯ liá»‡u"], key="data_source_radio")

        # Biáº¿n Ä‘á»ƒ lÆ°u trá»¯ dá»¯ liá»‡u
        if "data" not in st.session_state:
            st.session_state.data = None

        # Náº¿u chá»n táº£i tá»« OpenML
        if option == "Táº£i tá»« OpenML":
            st.markdown("#### ğŸ“‚ Táº£i dá»¯ liá»‡u MNIST tá»« OpenML")
            if st.button("Táº£i dá»¯ liá»‡u MNIST", key="download_mnist_button"):
                st.write("ğŸ”„ Äang táº£i dá»¯ liá»‡u MNIST tá»« OpenML...")
                
                # Táº£i dá»¯ liá»‡u MNIST tá»« file .npy
                X = np.load("X.npy")
                y = np.load("y.npy")
                
                st.success("âœ… Dá»¯ liá»‡u MNIST Ä‘Ã£ Ä‘Æ°á»£c táº£i thÃ nh cÃ´ng!")
                st.session_state.data = (X, y)  # LÆ°u dá»¯ liá»‡u vÃ o session_state

        # Náº¿u chá»n upload dá»¯ liá»‡u tá»« mÃ¡y
        else:
            st.markdown("#### ğŸ“¤ Upload dá»¯ liá»‡u cá»§a báº¡n")

            uploaded_file = st.file_uploader("Chá»n má»™t file áº£nh", type=["png", "jpg", "jpeg"], key="file_upload")

            if uploaded_file is not None:
                image = Image.open(uploaded_file)
                st.image(image, caption="áº¢nh Ä‘Ã£ táº£i lÃªn", use_column_width=True)

                if image.size != (28, 28):
                    st.error("âŒ áº¢nh khÃ´ng Ä‘Ãºng kÃ­ch thÆ°á»›c 28x28 pixel. Vui lÃ²ng táº£i láº¡i áº£nh Ä‘Ãºng Ä‘á»‹nh dáº¡ng.")
                else:
                    st.success("âœ… áº¢nh há»£p lá»‡!")
                    image = image.convert('L')
                    image_array = np.array(image).reshape(1, 28, 28, 1)
                    st.session_state.data = image_array

    # Kiá»ƒm tra náº¿u dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c táº£i
    if st.session_state.data is not None:
        st.markdown("#### âœ… Dá»¯ liá»‡u Ä‘Ã£ sáºµn sÃ ng!")
        
        if isinstance(st.session_state.data, tuple):
            X, y = st.session_state.data
            st.markdown("##### ğŸ”„ Tiáº¿n hÃ nh tiá»n xá»­ lÃ½ dá»¯ liá»‡u MNIST")

            preprocess_option = st.selectbox("Chá»n phÆ°Æ¡ng phÃ¡p tiá»n xá»­ lÃ½ dá»¯ liá»‡u:", 
                                            ["Chuáº©n hÃ³a dá»¯ liá»‡u (Normalization)", "Chuáº©n hÃ³a dá»¯ liá»‡u (Standardization)", "Xá»­ lÃ½ dá»¯ liá»‡u missing", "KhÃ´ng tiá»n xá»­ lÃ½"], key="preprocess_mnist")

            X_reshaped = X.reshape(X.shape[0], -1)
            
            st.markdown("### áº¢nh chÆ°a tiá»n xá»­ lÃ½")
            fig, axes = plt.subplots(1, 5, figsize=(10, 2))
            for i in range(5):
                axes[i].imshow(X[i].reshape(28, 28), cmap='gray')
                axes[i].set_title(f"Label: {y[i]}")
                axes[i].axis('off')
            st.pyplot(fig)
            
            st.markdown("### Káº¿t quáº£ sau khi tiá»n xá»­ lÃ½")
            fig, axes = plt.subplots(1, 5, figsize=(10, 2))
            
            if preprocess_option == "Chuáº©n hÃ³a dá»¯ liá»‡u (Normalization)":
                X_normalized = MinMaxScaler().fit_transform(X_reshaped)
                for i in range(5):
                    axes[i].imshow(X_normalized[i].reshape(28, 28), cmap='gray')
                    axes[i].set_title(f"Label: {y[i]}")
                    axes[i].axis('off')
                st.success("âœ… ÄÃ£ chuáº©n hÃ³a dá»¯ liá»‡u!")
            
            elif preprocess_option == "Chuáº©n hÃ³a dá»¯ liá»‡u (Standardization)":
                X_standardized = StandardScaler().fit_transform(X_reshaped)
                for i in range(5):
                    axes[i].imshow(X_standardized[i].reshape(28, 28), cmap='gray')
                    axes[i].set_title(f"Label: {y[i]}")
                    axes[i].axis('off')
                st.success("âœ… ÄÃ£ chuáº©n hÃ³a dá»¯ liá»‡u!")
            
            elif preprocess_option == "Xá»­ lÃ½ dá»¯ liá»‡u missing":
                imputer = SimpleImputer(strategy='mean')
                X_imputed = imputer.fit_transform(X_reshaped)
                for i in range(5):
                    axes[i].imshow(X_imputed[i].reshape(28, 28), cmap='gray')
                    axes[i].set_title(f"Label: {y[i]}")
                    axes[i].axis('off')
                st.success("âœ… ÄÃ£ xá»­ lÃ½ dá»¯ liá»‡u thiáº¿u!")
            else:
                for i in range(5):
                    axes[i].imshow(X[i].reshape(28, 28), cmap='gray')
                    axes[i].set_title(f"Label: {y[i]}")
                    axes[i].axis('off')
                st.success("âœ… KhÃ´ng thá»±c hiá»‡n tiá»n xá»­ lÃ½!")
            
            st.pyplot(fig)
    
    else:
        st.warning("ğŸ”¸ Vui lÃ²ng táº£i dá»¯ liá»‡u trÆ°á»›c khi tiáº¿p tá»¥c lÃ m viá»‡c.")

def chia_du_lieu():
    st.title("ğŸ“Œ Chia dá»¯ liá»‡u Train/Test")

    # Kiá»ƒm tra xem dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c táº£i hay chÆ°a
    if not os.path.exists("X.npy") or not os.path.exists("y.npy"):
        st.error("âŒ Dá»¯ liá»‡u chÆ°a Ä‘Æ°á»£c táº£i! Vui lÃ²ng táº£i dá»¯ liá»‡u trÆ°á»›c khi chia.")
        return

    # Äá»c dá»¯ liá»‡u tá»« file
    X = np.load("X.npy")
    y = np.load("y.npy")
    total_samples = X.shape[0]

    # Náº¿u dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia trÆ°á»›c Ä‘Ã³, hiá»ƒn thá»‹ thÃ´ng tin vÃ  khÃ´ng chia láº¡i
    if "X_train" in st.session_state:
        st.success("âœ… **Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia, khÃ´ng cáº§n cháº¡y láº¡i!**")

        # Hiá»ƒn thá»‹ báº£ng dá»¯ liá»‡u Ä‘Ã£ chia
        summary_df = pd.DataFrame({
            "Táº­p dá»¯ liá»‡u": ["Train", "Validation", "Test"],
            "Sá»‘ lÆ°á»£ng máº«u": [
                len(st.session_state["X_train"]),
                len(st.session_state["X_val"]),
                len(st.session_state["X_test"])
            ]
        })
        st.table(summary_df)
        return

    # Thanh chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train
    num_samples = st.slider("ğŸ“Œ Chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train:", 1000, total_samples, 10000)

    # Thanh chá»n % dá»¯ liá»‡u Test
    test_size = st.slider("ğŸ“Œ Chá»n % dá»¯ liá»‡u Test", 10, 50, 20)
    remaining_size = 100 - test_size  # TÃ­nh pháº§n cÃ²n láº¡i cá»§a táº­p Train

    # Thanh chá»n % dá»¯ liá»‡u Validation (trong táº­p Train)
    val_size = st.slider("ğŸ“Œ Chá»n % dá»¯ liá»‡u Validation (trong pháº§n Train)", 0, 50, 15)

    st.markdown(f"### ğŸ“Œ **Tá»· lá»‡ phÃ¢n chia:** Test={test_size}%, Validation={val_size}%, Train={remaining_size - val_size}%")

    if st.button("âœ… XÃ¡c nháº­n & LÆ°u"):
        # Chá»n táº­p dá»¯ liá»‡u theo sá»‘ lÆ°á»£ng máº«u mong muá»‘n
        X_selected, _, y_selected, _ = train_test_split(X, y, train_size=num_samples, stratify=y, random_state=42)

        # Chia train/test
        X_train_full, X_test, y_train_full, y_test = train_test_split(X_selected, y_selected, 
                                                                      test_size=test_size / 100, 
                                                                      stratify=y_selected, random_state=42)

        # Chia train/val
        X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, 
                                                          test_size=val_size / (100 - test_size), 
                                                          stratify=y_train_full, random_state=42)

        # LÆ°u dá»¯ liá»‡u vÃ o session_state Ä‘á»ƒ sá»­ dá»¥ng sau nÃ y
        st.session_state["X_train"] = X_train
        st.session_state["X_val"] = X_val
        st.session_state["X_test"] = X_test
        st.session_state["y_train"] = y_train
        st.session_state["y_val"] = y_val
        st.session_state["y_test"] = y_test

        # Táº¡o báº£ng hiá»ƒn thá»‹ sá»‘ lÆ°á»£ng máº«u cá»§a tá»«ng táº­p dá»¯ liá»‡u
        summary_df = pd.DataFrame({
            "Táº­p dá»¯ liá»‡u": ["Train", "Validation", "Test"],
            "Sá»‘ lÆ°á»£ng máº«u": [X_train.shape[0], X_val.shape[0], X_test.shape[0]]
        })

        st.success("âœ… **Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia thÃ nh cÃ´ng!**")
        st.table(summary_df)  # Hiá»ƒn thá»‹ báº£ng dá»¯ liá»‡u

def train():
    """Huáº¥n luyá»‡n mÃ´ hÃ¬nh Decision Tree hoáº·c SVM vÃ  lÆ°u trÃªn MLflow."""
    mlflow_input()
    # ğŸ“¥ Kiá»ƒm tra dá»¯ liá»‡u
    if not all(key in st.session_state for key in ["X_train", "y_train", "X_test", "y_test"]):
        st.error("âš ï¸ ChÆ°a cÃ³ dá»¯ liá»‡u! HÃ£y chia dá»¯ liá»‡u trÆ°á»›c.")
        return

    X_train, y_train = st.session_state["X_train"], st.session_state["y_train"]
    X_test, y_test = st.session_state["X_test"], st.session_state["y_test"]

    # ğŸŒŸ Chuáº©n hÃ³a dá»¯ liá»‡u
    X_train, X_test = X_train.reshape(-1, 28 * 28) / 255.0, X_test.reshape(-1, 28 * 28) / 255.0

    st.header("âš™ï¸ Chá»n mÃ´ hÃ¬nh & Huáº¥n luyá»‡n")

    # ğŸ“Œ Lá»±a chá»n mÃ´ hÃ¬nh
    model_choice = st.selectbox("Chá»n mÃ´ hÃ¬nh:", ["Decision Tree", "SVM"])
    
    if model_choice == "Decision Tree":
        criterion = st.selectbox("Criterion (HÃ m máº¥t mÃ¡t: Gini/Entropy) ", ["gini", "entropy"])
        max_depth = st.slider("max_depth (\(d\))", 1, 20, 5, help="Giá»›i háº¡n Ä‘á»™ sÃ¢u cá»§a cÃ¢y Ä‘á»ƒ trÃ¡nh overfitting.")
        model = DecisionTreeClassifier(criterion=criterion, max_depth=max_depth)
    else:
        C = st.slider("C (Há»‡ sá»‘ Ä‘iá»u chuáº©n \(C\))", 0.1, 10.0, 1.0)
        kernel = st.selectbox("Kernel (HÃ m nhÃ¢n \(K\))", ["linear", "rbf", "poly", "sigmoid"])
        model = SVC(C=C, kernel=kernel)

    # ğŸ“Œ Chá»n sá»‘ folds cho KFold Cross-Validation
    k_folds = st.slider("Sá»‘ folds (\(k\))", 2, 10, 5, help="Sá»‘ táº­p chia Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ mÃ´ hÃ¬nh.")

    # ğŸš€ Báº¯t Ä‘áº§u huáº¥n luyá»‡n
    if st.button("Huáº¥n luyá»‡n mÃ´ hÃ¬nh"):
        if "mlflow_url" not in st.session_state:
            st.session_state["mlflow_url"] = "https://dagshub.com/Snxtruc/HocMayVoiPython.mlflow"

        with mlflow.start_run():
            kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)
            cv_scores = []
            
            # Huáº¥n luyá»‡n trÃªn táº­p Cross-Validation
            for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):
                X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]
                y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]

                model.fit(X_train_fold, y_train_fold)
                val_pred = model.predict(X_val_fold)
                val_acc = accuracy_score(y_val_fold, val_pred)
                cv_scores.append(val_acc)
                mlflow.log_metric("cv_accuracy", val_acc, step=fold)

            cv_accuracy_mean = np.mean(cv_scores)
            cv_accuracy_std = np.std(cv_scores)

            # Hiá»ƒn thá»‹ káº¿t quáº£ Cross-Validation
            st.success(f"âœ… **Cross-Validation Accuracy:** {cv_accuracy_mean:.4f} Â± {cv_accuracy_std:.4f}")

            # Huáº¥n luyá»‡n trÃªn táº­p Test Set
            model.fit(X_train, y_train)
            y_pred = model.predict(X_test)
            test_acc = accuracy_score(y_test, y_pred)
            mlflow.log_metric("test_accuracy", test_acc)

            # Hiá»ƒn thá»‹ káº¿t quáº£ Test Set
            st.success(f"âœ… **Äá»™ chÃ­nh xÃ¡c trÃªn test set:** {test_acc:.4f}")

            # Ghi log lÃªn MLflow
            mlflow.log_param("model", model_choice)
            mlflow.log_param("k_folds", k_folds)
            if model_choice == "Decision Tree":
                mlflow.log_param("criterion", criterion)
                mlflow.log_param("max_depth", max_depth)
            elif model_choice == "SVM":
                mlflow.log_param("C", C)
                mlflow.log_param("kernel", kernel)

            mlflow.log_metric("cv_accuracy_mean", cv_accuracy_mean)
            mlflow.log_metric("cv_accuracy_std", cv_accuracy_std)
            mlflow.sklearn.log_model(model, model_choice.lower())

            # ğŸ“Œ LÆ°u mÃ´ hÃ¬nh vÃ o session_state
            if "models" not in st.session_state:
                st.session_state["models"] = []

            model_name = model_choice.lower().replace(" ", "_")
            if model_choice == "Decision Tree":
                model_name += f"_{criterion}_depth{max_depth}"
            elif model_choice == "SVM":
                model_name += f"_{kernel}"

            # Xá»­ lÃ½ trÃ¹ng láº·p tÃªn mÃ´ hÃ¬nh
            existing_names = {m["name"] for m in st.session_state["models"]}
            count = 1
            while model_name in existing_names:
                model_name = f"{model_name}_{count}"
                count += 1

            st.session_state["models"].append({"name": model_name, "model": model})
            st.write(f"ğŸ”¹ MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vá»›i tÃªn: **{model_name}**")
            st.write(f"ğŸ“‹ Tá»•ng sá»‘ mÃ´ hÃ¬nh hiá»‡n táº¡i: {len(st.session_state['models'])}")

            # Hiá»ƒn thá»‹ danh sÃ¡ch mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u
            model_names = [m["name"] for m in st.session_state["models"]]
            st.write("ğŸ“‹ Danh sÃ¡ch mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u:", ", ".join(model_names))

            st.success("ğŸ“Œ MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u trÃªn MLflow!")
            st.markdown(f"ğŸ”— [Truy cáº­p MLflow UI]({st.session_state['mlflow_url']})")


def mlflow_input():
    #st.title("ğŸš€ MLflow DAGsHub Tracking vá»›i Streamlit")
    DAGSHUB_USERNAME = "Snxtruc"  # Thay báº±ng username cá»§a báº¡n
    DAGSHUB_REPO_NAME = "HocMayPython"
    DAGSHUB_TOKEN = "ca4b78ae4dd9d511c1e0c333e3b709b2cd789a19"  # Thay báº±ng Access Token cá»§a báº¡n

    # Äáº·t URI MLflow Ä‘á»ƒ trá» Ä‘áº¿n DagsHub
    mlflow.set_tracking_uri(f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO_NAME}.mlflow")

    # Thiáº¿t láº­p authentication báº±ng Access Token
    os.environ["MLFLOW_TRACKING_USERNAME"] = DAGSHUB_USERNAME
    os.environ["MLFLOW_TRACKING_PASSWORD"] = DAGSHUB_TOKEN

    # Äáº·t thÃ­ nghiá»‡m MLflow
    mlflow.set_experiment("Classifications")   

    st.session_state['mlflow_url'] = f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO_NAME}.mlflow"


def load_model(path):
    try:
        return joblib.load(path)
    except FileNotFoundError:
        st.error(f"âš ï¸ KhÃ´ng tÃ¬m tháº¥y mÃ´ hÃ¬nh táº¡i `{path}`")
        st.stop()

# âœ… Xá»­ lÃ½ áº£nh tá»« canvas (chuáº©n 28x28 cho MNIST)
def preprocess_canvas_image(canvas_result):
    if canvas_result.image_data is not None:
        img = Image.fromarray(canvas_result.image_data[:, :, 0].astype(np.uint8))
        img = img.resize((28, 28)).convert("L")  # Resize vÃ  chuyá»ƒn thÃ nh grayscale
        img = np.array(img, dtype=np.float32) / 255.0  # Chuáº©n hÃ³a vá» [0, 1]
        return img.reshape(1, -1)  # Chuyá»ƒn thÃ nh vector 1D
    return None


def preprocess_canvas_image(canvas_result):
    if canvas_result.image_data is None:
        return None
    img = Image.fromarray((canvas_result.image_data[:, :, 0] * 255).astype(np.uint8))
    img = img.convert("L").resize((28, 28))  # Chuyá»ƒn sang áº£nh xÃ¡m 28x28
    img = np.array(img) / 255.0  # Chuáº©n hÃ³a
    return img.reshape(1, -1)


def display_mlflow_experiments():
    try:
        st.title("ğŸ” Quáº£n lÃ½ MLflow Experiments")

        # Káº¿t ná»‘i MlflowClient
        client = MlflowClient()

        # Láº¥y danh sÃ¡ch thÃ­ nghiá»‡m
        experiments = mlflow.search_experiments()
        
        if experiments:
            st.write("### ğŸ“Œ Danh sÃ¡ch ThÃ­ nghiá»‡m")
            experiment_data = [
                {"Experiment ID": exp.experiment_id, "Experiment Name": exp.name, "Artifact Location": exp.artifact_location}
                for exp in experiments
            ]
            st.data_editor(pd.DataFrame(experiment_data))
            
            # Chá»n thÃ­ nghiá»‡m
            selected_exp_id = st.selectbox("ğŸ—‚ Chá»n thÃ­ nghiá»‡m", sorted([exp.experiment_id for exp in experiments]))
            
            # Äá»•i tÃªn thÃ­ nghiá»‡m
            new_exp_name = st.text_input("âœï¸ Nháº­p tÃªn má»›i cho thÃ­ nghiá»‡m", "")
            if st.button("ğŸ’¾ Äá»•i tÃªn") and new_exp_name:
                client.rename_experiment(selected_exp_id, new_exp_name)
                st.success("âœ… Äá»•i tÃªn thÃ nh cÃ´ng! Vui lÃ²ng táº£i láº¡i trang.")
            
            # XÃ³a thÃ­ nghiá»‡m
            if st.button("ğŸ—‘ï¸ XÃ³a thÃ­ nghiá»‡m"):
                client.delete_experiment(selected_exp_id)
                st.success("âœ… XÃ³a thÃ­ nghiá»‡m thÃ nh cÃ´ng! Vui lÃ²ng táº£i láº¡i trang.")
            
            # Láº¥y danh sÃ¡ch runs trong thÃ­ nghiá»‡m Ä‘Ã£ chá»n
            runs = client.search_runs(experiment_ids=[selected_exp_id])
            if runs:
                st.write("### ğŸ“Œ Danh sÃ¡ch Run")
                
                # Bá»™ lá»c tÃ¬m kiáº¿m Run
                search_term = st.text_input("ğŸ” TÃ¬m kiáº¿m Run", "")
                
                # Bá»™ lá»c theo khoáº£ng thá»i gian
                start_date = st.date_input("ğŸ“… Chá»n ngÃ y báº¯t Ä‘áº§u", pd.to_datetime("2023-01-01"))
                end_date = st.date_input("ğŸ“… Chá»n ngÃ y káº¿t thÃºc", pd.to_datetime("today"))
                
                # Bá»™ lá»c theo tráº¡ng thÃ¡i Run
                status_filter = st.multiselect("ğŸ“Œ Lá»c theo tráº¡ng thÃ¡i", ["RUNNING", "FINISHED", "FAILED", "KILLED"], default=["RUNNING", "FINISHED"])
                
                # Hiá»ƒn thá»‹ danh sÃ¡ch Runs
                run_data = [
                    {
                        "Run ID": run.info.run_id,
                        "Run Name": run.data.tags.get("mlflow.runName", "Unnamed"),
                        "Start Time": pd.to_datetime(run.info.start_time, unit='ms'),
                        "End Time": pd.to_datetime(run.info.end_time, unit='ms') if run.info.end_time else None,
                        "Duration": (pd.to_datetime(run.info.end_time, unit='ms') - pd.to_datetime(run.info.start_time, unit='ms')).total_seconds() if run.info.end_time else None,
                        "Status": run.info.status,
                        "Source": run.data.tags.get("mlflow.source.name", "Unknown"),
                        "Metrics": run.data.metrics
                    }
                    for run in runs
                ]
                df_runs = pd.DataFrame(run_data).sort_values(by="Start Time", ascending=False)
                
                # Ãp dá»¥ng bá»™ lá»c
                df_runs = df_runs[(df_runs["Start Time"] >= pd.to_datetime(start_date)) & (df_runs["Start Time"] <= pd.to_datetime(end_date))]
                df_runs = df_runs[df_runs["Status"].isin(status_filter)]
                
                if search_term:
                    df_runs = df_runs[df_runs["Run Name"].str.contains(search_term, case=False, na=False)]
                
                # Bá»™ lá»c theo Metrics cá»¥ thá»ƒ
                metric_name = st.text_input("ğŸ“Š Nháº­p tÃªn Metric Ä‘á»ƒ lá»c", "accuracy")
                metric_value = st.number_input("ğŸ“ˆ GiÃ¡ trá»‹ tá»‘i thiá»ƒu cá»§a Metric", min_value=0.0, step=0.01, format="%.2f")
                
                def filter_by_metric(run):
                    return metric_name in run["Metrics"] and run["Metrics"][metric_name] >= metric_value
                
                df_runs = df_runs[df_runs.apply(filter_by_metric, axis=1)]
                
                st.data_editor(df_runs)
                
                run_options = {run["Run ID"]: f"{run['Run Name']} - {run['Run ID']}" for _, run in df_runs.iterrows()}
                        
                # Chá»n Run trong thÃ­ nghiá»‡m Ä‘á»ƒ Ä‘á»•i tÃªn hoáº·c xÃ³a
                runs = client.search_runs(experiment_ids=[selected_exp_id])
                if runs:
                    run_options = {run.info.run_id: f"{run.data.tags.get('mlflow.runName', 'Unnamed')} - {run.info.run_id}" for run in runs}
                    selected_run_id = st.selectbox("âœï¸ Chá»n Run Ä‘á»ƒ Ä‘á»•i tÃªn", list(run_options.keys()), format_func=lambda x: run_options[x])
                    new_run_name = st.text_input("ğŸ“› Nháº­p tÃªn má»›i cho Run", "")
                    if st.button("âœ… Cáº­p nháº­t tÃªn Run") and new_run_name:
                        client.set_tag(selected_run_id, "mlflow.runName", new_run_name)
                        st.success("âœ… Cáº­p nháº­t tÃªn Run thÃ nh cÃ´ng! Vui lÃ²ng táº£i láº¡i trang.")
                    
                    selected_run_id_delete = st.selectbox("ğŸ—‘ï¸ Chá»n Run Ä‘á»ƒ xÃ³a", list(run_options.keys()), format_func=lambda x: run_options[x])
                    if st.button("âŒ XÃ³a Run"):
                        client.delete_run(selected_run_id_delete)
                        st.success("âœ… XÃ³a Run thÃ nh cÃ´ng! Vui lÃ²ng táº£i láº¡i trang.")
                    

                # Chá»n Run Ä‘á»ƒ xem chi tiáº¿t
                selected_run_id = st.selectbox("ğŸ” Chá»n Run Ä‘á»ƒ xem chi tiáº¿t", list(run_options.keys()), format_func=lambda x: run_options[x])
                selected_run = client.get_run(selected_run_id)
                
                st.write("### ğŸ“‹ ThÃ´ng tin Run")
                st.write(f"**Run ID:** {selected_run_id}")
                st.write(f"**Run Name:** {selected_run.data.tags.get('mlflow.runName', 'Unnamed')}")
                st.write(f"**Start Time:** {pd.to_datetime(selected_run.info.start_time, unit='ms')}")
                st.write(f"**End Time:** {pd.to_datetime(selected_run.info.end_time, unit='ms') if selected_run.info.end_time else 'N/A'}")
                st.write(f"**Duration:** {(pd.to_datetime(selected_run.info.end_time, unit='ms') - pd.to_datetime(selected_run.info.start_time, unit='ms')).total_seconds() if selected_run.info.end_time else 'N/A'} seconds")
                st.write(f"**Status:** {selected_run.info.status}")
                st.write(f"**Source:** {selected_run.data.tags.get('mlflow.source.name', 'Unknown')}")
                
                # Hiá»ƒn thá»‹ Metrics
                st.write("### ğŸ“Š Metrics")
                metrics = selected_run.data.metrics
                if metrics:
                    df_metrics = pd.DataFrame(metrics.items(), columns=["Metric Name", "Value"])
                    st.data_editor(df_metrics)
                else:
                    st.write("ğŸ“­ KhÃ´ng cÃ³ Metrics nÃ o.")
                
                # Hiá»ƒn thá»‹ Artifacts
                artifact_uri = selected_run.info.artifact_uri
                st.write(f"**Artifact Location:** {artifact_uri}")
                
                st.write("### ğŸ“‚ Danh sÃ¡ch Artifacts")
                artifacts = client.list_artifacts(selected_run_id)
                if artifacts:
                    artifact_paths = [artifact.path for artifact in artifacts]
                    st.write(artifact_paths)
                    for artifact in artifacts:
                        if artifact.path.endswith(".png") or artifact.path.endswith(".jpg"):
                            st.image(f"{artifact_uri}/{artifact.path}", caption=artifact.path)
                        if artifact.path.endswith(".csv") or artifact.path.endswith(".txt"):
                            with open(f"{artifact_uri}/{artifact.path}", "r") as f:
                                st.download_button(label=f"ğŸ“¥ Táº£i {artifact.path}", data=f.read(), file_name=artifact.path)
                else:
                    st.write("ğŸ“­ KhÃ´ng cÃ³ artifacts nÃ o.")
                
                # Truy cáº­p MLflow UI
                st.write("### ğŸ”— Truy cáº­p MLflow UI")
                st.markdown("[Má»Ÿ MLflow UI](https://dagshub.com/Snxtruc/HocMayVoiPython.mlflow)")
            else:
                st.warning("âš ï¸ KhÃ´ng cÃ³ Run nÃ o trong thÃ­ nghiá»‡m nÃ y.")
        else:
            st.warning("âš ï¸ KhÃ´ng cÃ³ ThÃ­ nghiá»‡m nÃ o Ä‘Æ°á»£c tÃ¬m tháº¥y.")
    except Exception as e:
        st.error(f"âŒ Lá»—i khi láº¥y danh sÃ¡ch thÃ­ nghiá»‡m: {e}")

def du_doan():
    st.header("âœï¸ Dá»± Ä‘oÃ¡n sá»‘")
    
    # ğŸ”¹ Chá»n phÆ°Æ¡ng thá»©c dá»± Ä‘oÃ¡n
    mode = st.radio("Chá»n phÆ°Æ¡ng thá»©c dá»± Ä‘oÃ¡n:", ["Váº½ sá»‘", "Upload file test"])
    
    if mode == "Váº½ sá»‘":
        # âœï¸ Váº½ sá»‘
        st.subheader("ğŸ–Œï¸ Váº½ sá»‘ vÃ o khung dÆ°á»›i Ä‘Ã¢y:")
        canvas_result = st_canvas(
            fill_color="black",
            stroke_width=10,
            stroke_color="white",
            background_color="black",
            height=150,
            width=150,
            drawing_mode="freedraw",
            key="canvas"
        )
    
    elif mode == "Upload file test":
        # ğŸ”¹ Upload file test
        st.header("ğŸ“‚ Dá»± Ä‘oÃ¡n trÃªn táº­p test")
        uploaded_file = st.file_uploader("Táº£i táº­p test (CSV hoáº·c NPY):", type=["csv", "npy"])
        
        if uploaded_file is not None:
            if uploaded_file.name.endswith(".csv"):
                test_data = pd.read_csv(uploaded_file).values
            else:
                test_data = np.load(uploaded_file)
            
            st.write(f"ğŸ“Š Dá»¯ liá»‡u test cÃ³ {test_data.shape[0]} máº«u.")
    
    # ğŸ”¹ Danh sÃ¡ch mÃ´ hÃ¬nh cÃ³ sáºµn
    available_models = {
        "SVM Linear": "svm_mnist_linear.joblib",
        "SVM Poly": "svm_mnist_poly.joblib",
        "SVM Sigmoid": "svm_mnist_sigmoid.joblib",
        "SVM RBF": "svm_mnist_rbf.joblib",
    }
    
    # ğŸ“Œ Chá»n mÃ´ hÃ¬nh
    model_option = st.selectbox("ğŸ” Chá»n mÃ´ hÃ¬nh:", list(available_models.keys()))
    
    # Táº£i mÃ´ hÃ¬nh
    model = joblib.load(available_models[model_option])
    st.success(f"âœ… MÃ´ hÃ¬nh {model_option} Ä‘Ã£ Ä‘Æ°á»£c táº£i thÃ nh cÃ´ng!")
    
    if mode == "Váº½ sá»‘":
        if st.button("Dá»± Ä‘oÃ¡n sá»‘"):
            if canvas_result.image_data is not None:
                img = preprocess_canvas_image(canvas_result)
                st.image(Image.fromarray((img.reshape(28, 28) * 255).astype(np.uint8)), caption="áº¢nh sau xá»­ lÃ½", width=100)
                prediction = model.predict(img)
                probabilities = model.decision_function(img) if hasattr(model, 'decision_function') else model.predict_proba(img)
                confidence = np.max(probabilities) if probabilities is not None else "KhÃ´ng xÃ¡c Ä‘á»‹nh"
                st.subheader(f"ğŸ”¢ Káº¿t quáº£ dá»± Ä‘oÃ¡n: {prediction[0]} (Äá»™ tin cáº­y: {confidence:.2f})")
            else:
                st.error("âš ï¸ Vui lÃ²ng váº½ má»™t sá»‘ trÆ°á»›c khi dá»± Ä‘oÃ¡n!")
    
    elif mode == "Upload file test" and uploaded_file is not None:
        if st.button("Dá»± Ä‘oÃ¡n trÃªn táº­p test"):
            predictions = model.predict(test_data)
            probabilities = model.decision_function(test_data) if hasattr(model, 'decision_function') else model.predict_proba(test_data)
            confidences = np.max(probabilities, axis=1) if probabilities is not None else ["KhÃ´ng xÃ¡c Ä‘á»‹nh"] * len(predictions)
            
            st.write("ğŸ”¢ Káº¿t quáº£ dá»± Ä‘oÃ¡n:")
            for i in range(min(10, len(predictions))):
                st.write(f"Máº«u {i + 1}: {predictions[i]} (Äá»™ tin cáº­y: {confidences[i]:.2f})")
            
            fig, axes = plt.subplots(1, min(5, len(test_data)), figsize=(10, 2))
            for i, ax in enumerate(axes):
                ax.imshow(test_data[i].reshape(28, 28), cmap='gray')
                ax.set_title(f"{predictions[i]} ({confidences[i]:.2f})")
                ax.axis("off")
            st.pyplot(fig)




def Classification():
    # Thiáº¿t láº­p CSS Ä‘á»ƒ há»— trá»£ hiá»ƒn thá»‹ tabs vá»›i hiá»‡u á»©ng hover vÃ  thanh cuá»™n
    st.markdown(
        """
        <style>
        .stTabs [role="tablist"] {
            overflow-x: auto;
            white-space: nowrap;
            display: flex;
            scrollbar-width: thin;
            scrollbar-color: #888 #f0f0f0;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar {
            height: 6px;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar-thumb {
            background-color: #888;
            border-radius: 3px;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar-track {
            background: #f0f0f0;
        }
        .stTabs [role="tab"]:hover {
            background-color: #f0f0f0;
            transition: background-color 0.3s ease-in-out;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

    # TiÃªu Ä‘á» á»©ng dá»¥ng
    st.title("ğŸ–¥ï¸ MNIST Classification App")

    # Táº¡o cÃ¡c tab trong giao diá»‡n Streamlit
    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
        "ğŸ“– LÃ½ thuyáº¿t Decision Tree", 
        "ğŸ“– LÃ½ thuyáº¿t SVM", 
        "ğŸš€ Review database", 
        "ğŸ“¥ Táº£i dá»¯ liá»‡u", 
        "âš™ï¸ Huáº¥n luyá»‡n", 
        "Tracking mlflow",
        "ğŸ”® Dá»± Ä‘oÃ¡n"
    ])

    # Ná»™i dung cá»§a tá»«ng tab
    with tab1:
        ly_thuyet_Decision_tree()

    with tab2:
        ly_thuyet_SVM()
    
    with tab3:
        data()

    with tab4:
        up_load_db()
    
    with tab5:      
        chia_du_lieu()
        train()
    
    with tab6:
        display_mlflow_experiments()

    with tab7:
        du_doan()  # Gá»i hÃ m dá»± Ä‘oÃ¡n Ä‘á»ƒ xá»­ lÃ½ khi vÃ o tab Dá»± Ä‘oÃ¡n

def run(): 
    Classification()

if __name__ == "__main__":
    run()