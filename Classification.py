import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import openml
import joblib
import shutil
import pandas as pd
import time
import os
import mlflow
import humanize
from datetime import datetime
from sklearn import datasets
from sklearn.decomposition import PCA
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import cross_val_score, KFold
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from streamlit_drawable_canvas import st_canvas
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from streamlit_drawable_canvas import st_canvas
from PIL import Image, ImageOps
from mlflow.tracking import MlflowClient


def ly_thuyet_Decision_tree():
    st.header("üìñ L√Ω thuy·∫øt v·ªÅ Decision Tree") 
    st.markdown(" ### 1Ô∏è‚É£ Decision Tree l√† g√¨?")
    st.write("""
    Decision Tree (C√¢y quy·∫øt ƒë·ªãnh) l√† m·ªôt thu·∫≠t to√°n h·ªçc c√≥ gi√°m s√°t ƒë∆∞·ª£c s·ª≠ d·ª•ng trong **ph√¢n lo·∫°i (classification)** v√† **h·ªìi quy (regression)**.
    N√≥ ho·∫°t ƒë·ªông b·∫±ng c√°ch chia d·ªØ li·ªáu th√†nh c√°c nh√≥m nh·ªè h∆°n d·ª±a tr√™n c√°c ƒëi·ªÅu ki·ªán ƒë∆∞·ª£c thi·∫øt l·∫≠p t·∫°i c√°c **n√∫t (nodes)** c·ªßa c√¢y.
    """) 
    
    image_url = "https://machinelearningcoban.com/assets/34_id3/dt_ex1.png"
    article_url = "https://machinelearningcoban.com/2018/01/14/id3/"

    # Hi·ªÉn th·ªã ·∫£nh c√≥ th·ªÉ nh·∫•p v√†o, cƒÉn gi·ªØa v√† th√™m caption
    st.markdown(
        f"""
        <div style="text-align: center;">
            <a href="{article_url}" target="_blank">
                <img src="{image_url}" width="300">
            </a>
            <p style="font-size: 14px; color: gray;">V√≠ d·ª• v·ªÅ vi·ªác ra quy·∫øt ƒë·ªãnh d·ª±a tr√™n c√°c c√¢u h·ªèi.</p>
        </div>
        """,
        unsafe_allow_html=True
    ) 

    st.markdown(" ### 2Ô∏è‚É£ √Ω t∆∞·ªüng") 

    st.markdown(
    """
    ##### 2.1 V·∫•n ƒë·ªÅ c·∫ßn gi·∫£i quy·∫øt:  
    - Khi x√¢y d·ª±ng c√¢y quy·∫øt ƒë·ªãnh, ta c·∫ßn x√°c ƒë·ªãnh th·ª© t·ª± thu·ªôc t√≠nh ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ chia d·ªØ li·ªáu.  
    - V·ªõi b√†i to√°n c√≥ nhi·ªÅu thu·ªôc t√≠nh v√† m·ªói thu·ªôc t√≠nh c√≥ nhi·ªÅu gi√° tr·ªã, vi·ªác t√¨m gi·∫£i ph√°p t·ªëi ∆∞u l√† kh√¥ng kh·∫£ thi.  
    - Thay v√¨ t√¨m nghi·ªám t·ªëi ∆∞u to√†n c·ª•c, ta s·ª≠ d·ª•ng m·ªôt ph∆∞∆°ng ph√°p **tham lam (greedy)**:  
      ‚Üí Ch·ªçn thu·ªôc t√≠nh **t·ªët nh·∫•t** t·∫°i m·ªói b∆∞·ªõc d·ª±a tr√™n m·ªôt ti√™u ch√≠ n√†o ƒë√≥.
    """
    )   
    image_url = "https://www.mdpi.com/entropy/entropy-27-00035/article_deploy/html/images/entropy-27-00035-g001-550.jpg"
    article_url = "http://mdpi.com/1099-4300/27/1/35"

    # Hi·ªÉn th·ªã ·∫£nh c√≥ th·ªÉ nh·∫•p v√†o, cƒÉn gi·ªØa v√† th√™m caption
    st.markdown(
        f"""
        <div style="text-align: center;">
            <a href="{article_url}" target="_blank">
                <img src="{image_url}" width="300">
            </a>
            <p style="font-size: 14px; color: gray;"><i>Set of decision trees ùëÜ={{ùëáùëüùëíùëí1, ùëáùëüùëíùëí2}}</i></p>
        </div>
        """,
        unsafe_allow_html=True
    )   
    st.markdown(
    """
    ##### 2.2 Qu√° tr√¨nh chia nh·ªè d·ªØ li·ªáu:
    - V·ªõi m·ªói thu·ªôc t√≠nh ƒë∆∞·ª£c ch·ªçn, d·ªØ li·ªáu ƒë∆∞·ª£c chia th√†nh c√°c **child node** theo gi√° tr·ªã c·ªßa thu·ªôc t√≠nh ƒë√≥.
    - Sau ƒë√≥, ti·∫øp t·ª•c l·∫∑p l·∫°i qu√° tr√¨nh n√†y cho t·ª´ng **child node**.
    """
    )
    image_url = "https://cdn.analyticsvidhya.com/wp-content/uploads/2024/09/ns1.webp"
    article_url = "https://www.analyticsvidhya.com/blog/2020/06/4-ways-split-decision-tree/"

    st.markdown(
        f"""
        <div style="text-align: center;">
            <a href="{article_url}" target="_blank">
                <img src="{image_url}" width="300">
            </a>
            <p style="font-size: 14px; color: gray;"><i>V√≠ d·ª• qu√° tr√¨nh chia nh·ªè d·ªØ li·ªáu</i></p>
        </div>
        """,
        unsafe_allow_html=True
    )   
    st.markdown(
    """
    ##### 2.4 H√†m s·ªë Entropy: 
    - Entropy l√† m·ªôt kh√°i ni·ªám trong l√Ω thuy·∫øt th√¥ng tin, ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒëo **ƒë·ªô h·ªón lo·∫°n (impurity)** ho·∫∑c **ƒë·ªô kh√¥ng ch·∫Øc ch·∫Øn** c·ªßa m·ªôt t·∫≠p d·ªØ li·ªáu. 
    - Trong c√¢y quy·∫øt ƒë·ªãnh (Decision Tree), entropy gi√∫p ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng c·ªßa m·ªôt ph√©p chia d·ªØ li·ªáu.
    """
    )
    st.latex(r"H(p) = - \sum_{i=1}^{n} p_i \log(p_i)")
    st.markdown(
    """
    Trong ƒë√≥:
    - log c√≥ th·ªÉ l√† logarit t·ª± nhi√™n ho·∫∑c log c∆° s·ªë 2.
    - Quy ∆∞·ªõc: \\( 0 \log 0 = 0 \\).
    """
    )

    st.markdown(
    """
    ##### üîç √ù nghƒ©a c·ªßa Entropy trong ph√¢n ph·ªëi x√°c su·∫•t:
    """)

    st.markdown(
        """
        - N·∫øu **ph√¢n ph·ªëi tinh khi·∫øt** (ch·ªâ c√≥ m·ªôt gi√° tr·ªã c√≥ x√°c su·∫•t 1, c√≤n l·∫°i l√† 0):  
        ‚Üí **Entropy = 0**, t·ª©c **kh√¥ng c√≥ s·ª± kh√¥ng ch·∫Øc ch·∫Øn**.
        - N·∫øu **ph√¢n ph·ªëi v·∫©n ƒë·ª•c nh·∫•t** (c√°c gi√° tr·ªã c√≥ x√°c su·∫•t b·∫±ng nhau, v√≠ d·ª• p1 = p2 = 0.5)  
        ‚Üí **Entropy ƒë·∫°t gi√° tr·ªã cao nh·∫•t**, t·ª©c **ƒë·ªô kh√¥ng ch·∫Øc ch·∫Øn l·ªõn nh·∫•t**.
        """
    )
    image_url = "https://machinelearningcoban.com/assets/34_id3/entropy.png"
    article_url = "https://machinelearningcoban.com/2018/01/14/id3/"
    st.markdown(
        f"""
        <div style="text-align: center;">
            <a href="{article_url}" target="_blank">
                <img src="{image_url}" width="300">
            </a>
            <p style="font-size: 14px; color: gray;"><i>V√≠ d·ª• ƒê·ªì th·ªã c·ªßa h√†m entropy v·ªõi 
            n
            =
            2
            </i></p>
        </div>
        """,
        unsafe_allow_html=True
    )   

    st.markdown(" ### 3Ô∏è‚É£ Thu·∫≠t to√°n ID3")
    st.markdown("##### T√≠nh to√°n Entropy t·∫°i m·ªôt Node")
    st.markdown(
        """
        V·ªõi t·∫≠p d·ªØ li·ªáu **S** g·ªìm **N** ƒëi·ªÉm d·ªØ li·ªáu thu·ªôc **C** l·ªõp, entropy t·∫°i node ƒë∆∞·ª£c t√≠nh b·∫±ng:
        """
    )
    st.latex(r"H(S) = - \sum_{c=1}^{C} \frac{N_c}{N} \log \left(\frac{N_c}{N} \right)")
    st.markdown("Trong ƒë√≥, \\( N_c \\) l√† s·ªë ƒëi·ªÉm thu·ªôc class **c**.")

    st.markdown("##### Entropy sau khi ph√¢n chia theo thu·ªôc t√≠nh **x**")
    st.markdown(
        """
        Khi ch·ªçn thu·ªôc t√≠nh **x**, t·∫≠p **S** ƒë∆∞·ª£c chia th√†nh **K** child node \\( S_1, S_2, ..., S_K \\) 
        v·ªõi k√≠ch th∆∞·ªõc t∆∞∆°ng ·ª©ng \\( m_1, m_2, ..., m_K \\). Entropy t·ªïng c√≥ tr·ªçng s·ªë sau khi ph√¢n chia:
        """
    )
    st.latex(r"H(x,S) = \sum_{k=1}^{K} \frac{m_k}{N} H(S_k)")
    st.markdown("Vi·ªác l·∫•y tr·ªçng s·ªë l√† c·∫ßn thi·∫øt v√¨ m·ªói node c√≥ s·ªë l∆∞·ª£ng ƒëi·ªÉm d·ªØ li·ªáu kh√°c nhau.")

    st.markdown("##### Information Gain ‚Äì Ti√™u ch√≠ ch·ªçn thu·ªôc t√≠nh")
    st.markdown("ƒê·ªÉ x√°c ƒë·ªãnh thu·ªôc t√≠nh n√†o gi√∫p gi·∫£m entropy t·ªët nh·∫•t, ta t√≠nh **Information Gain**:")
    st.latex(r"G(x,S) = H(S) - H(x,S)")

    st.markdown("ID3 ch·ªçn thu·ªôc t√≠nh \\( x^* \\) sao cho **Information Gain** l·ªõn nh·∫•t:")
    st.latex(r"x^* = \arg\max_{x} G(x,S) = \arg\min_{x} H(x,S)")
    st.markdown("Nghƒ©a l√† ta ch·ªçn thu·ªôc t√≠nh gi√∫p entropy gi·∫£m nhi·ªÅu nh·∫•t sau khi ph√¢n chia.")

    st.markdown("##### Khi n√†o d·ª´ng ph√¢n chia?")
    st.markdown(
        """
        ID3 d·ª´ng ph√¢n chia khi:
        - ‚úÖ T·∫•t c·∫£ d·ªØ li·ªáu trong node thu·ªôc c√πng m·ªôt class.
        - ‚úÖ Kh√¥ng c√≤n thu·ªôc t√≠nh n√†o ƒë·ªÉ chia ti·∫øp.
        - ‚úÖ S·ªë l∆∞·ª£ng ƒëi·ªÉm d·ªØ li·ªáu trong node qu√° nh·ªè.
        """
    )

def ly_thuyet_SVM():
    st.header("üìñ L√Ω thuy·∫øt v·ªÅ SVM")
    st.markdown(" ### 1Ô∏è‚É£ SVM l√† g√¨?")
    st.write("""
    - Support Vector Machine (SVM) l√† m·ªôt thu·∫≠t to√°n h·ªçc c√≥ gi√°m s√°t d√πng cho **ph√¢n lo·∫°i** v√† h·ªìi quy.    
    - M·ª•c ti√™u c·ªßa SVM l√† t√¨m ra **si√™u ph·∫≥ng** (hyperplane) t·ªëi ∆∞u ƒë·ªÉ ph√¢n t√°ch d·ªØ li·ªáu thu·ªôc c√°c l·ªõp kh√°c nhau v·ªõi m·ªôt **kho·∫£ng c√°ch l·ªÅ** (margin) l·ªõn nh·∫•t.
        """
    )

    image_url = "https://neralnetwork.wordpress.com/wp-content/uploads/2018/01/svm1.png"
    article_url = "https://neralnetwork.wordpress.com/2018/05/11/thuat-toan-support-vector-machine-svm/"
    st.markdown(
        f"""
        <div style="text-align: center;">
            <a href="{article_url}" target="_blank">
                <img src="{image_url}" width="300">
            </a>
            <p style="font-size: 14px; color: gray;"><i>minh h·ªça v·ªÅ SVM
            </i></p>
        </div>
        """,
        unsafe_allow_html=True
    )   
    st.markdown(" ### 2Ô∏è‚É£ √ù t∆∞·ªüng c·ªßa SVM") 
    st.markdown(" ##### 2.1 T√¨m si√™u ph·∫≥ng ph√¢n t√°ch t·ªëi ∆∞u")
    st.write(
        "M·ªôt si√™u ph·∫≥ng (hyperplane) trong kh√¥ng gian ƒë·∫∑c tr∆∞ng c√≥ d·∫°ng:\n"
        "$w \cdot x + b = 0$\n"
        "Trong ƒë√≥:\n"
        "- $w$ l√† vector ph√°p tuy·∫øn c·ªßa si√™u ph·∫≥ng.\n"
        "- $x$ l√† ƒëi·ªÉm d·ªØ li·ªáu.\n"
        "- $b$ l√† h·ªá s·ªë ƒëi·ªÅu ch·ªânh ƒë·ªô d·ªãch chuy·ªÉn c·ªßa si√™u ph·∫≥ng.\n"
        "\n"
    )
    image_url = "https://www.researchgate.net/publication/244858164/figure/fig3/AS:670028080898057@1536758551648/An-example-of-the-optimal-separating-hyperplane-of-support-vector-machine-SVM-with-the.png"
    article_url = "https://www.researchgate.net/figure/An-example-of-the-optimal-separating-hyperplane-of-support-vector-machine-SVM-with-the_fig3_244858164"
    st.markdown(
        f"""
        <div style="text-align: center;">
            <a href="{article_url}" target="_blank">
                <img src="{image_url}" width="300">
            </a>
            <p style="font-size: 14px; color: gray;"><i>minh h·ªça qu√° tr√¨nh t√¨m si√™u ph·∫≥ng ph√¢n t√°ch t·ªëi ∆∞u
            </i></p>
        </div>
        """,
        unsafe_allow_html=True
    )   
    st.write("M·ª•c ti√™u c·ªßa SVM l√† t√¨m si√™u ph·∫≥ng c√≥ kho·∫£ng c√°ch l·ªõn nh·∫•t t·ªõi c√°c ƒëi·ªÉm g·∫ßn nh·∫•t thu·ªôc hai l·ªõp kh√°c nhau (c√°c support vectors).\n"
    "Kho·∫£ng c√°ch n√†y ƒë∆∞·ª£c g·ªçi l√† l·ªÅ (margin).")

    st.markdown(" ##### 2.2 T·ªëi ƒëa h√≥a l·ªÅ (Maximum Margin)")
    st.write(
        "L·ªÅ (margin) l√† kho·∫£ng c√°ch gi·ªØa si√™u ph·∫≥ng v√† c√°c ƒëi·ªÉm d·ªØ li·ªáu g·∫ßn nh·∫•t thu·ªôc hai l·ªõp.\n"
        "SVM c·ªë g·∫Øng t·ªëi ƒëa h√≥a l·ªÅ n√†y ƒë·ªÉ ƒë·∫£m b·∫£o m√¥ h√¨nh c√≥ kh·∫£ nƒÉng t·ªïng qu√°t h√≥a t·ªët nh·∫•t."
    )

    st.latex(r"""
    D = \frac{|w^T x_0 + b|}{||w||_2}
    """)

    st.markdown("##### Trong ƒë√≥:")
    st.markdown("- $w^T x_0$ l√† t√≠ch v√¥ h∆∞·ªõng gi·ªØa vector ph√°p tuy·∫øn c·ªßa hyperplane v√† ƒëi·ªÉm $x_0$.")
    st.markdown("- $||w||_2$ l√† ƒë·ªô d√†i (norm) c·ªßa vector ph√°p tuy·∫øn $w$, ƒë∆∞·ª£c t√≠nh b·∫±ng c√¥ng th·ª©c:")

    st.latex(r"""
    ||w||_2 = \sqrt{w_1^2 + w_2^2 + \dots + w_n^2}
    """)

    st.markdown("- D·∫•u $| \cdot |$ bi·ªÉu th·ªã gi√° tr·ªã tuy·ªát ƒë·ªëi, gi√∫p ƒë·∫£m b·∫£o kho·∫£ng c√°ch lu√¥n l√† gi√° tr·ªã kh√¥ng √¢m.")

    image_url = "https://www.researchgate.net/publication/226587707/figure/fig3/AS:669184333725696@1536557386160/Margin-maximization-principle-the-basic-idea-of-Support-Vector-Machine.ppm"
    article_url = "https://www.researchgate.net/figure/Margin-maximization-principle-the-basic-idea-of-Support-Vector-Machine_fig3_226587707"
    st.markdown(
        f"""
        <div style="text-align: center;">
            <a href="{article_url}" target="_blank">
                <img src="{image_url}" width="300">
            </a>
            <p style="font-size: 14px; color: gray;"><i>minh h·ªça t√¨m kho·∫£ng c√°ch t·ª´ ƒëi·ªÉm ƒë·∫øn si√™u ph·∫≥ng
            </i></p>
        </div>
        """,
        unsafe_allow_html=True
    )   

    st.markdown(" ##### 2.3 Khi d·ªØ li·ªáu kh√¥ng t√°ch ƒë∆∞·ª£c tuy·∫øn t√≠nh")
    st.write(
        "Trong tr∆∞·ªùng h·ª£p d·ªØ li·ªáu kh√¥ng th·ªÉ ph√¢n t√°ch b·∫±ng m·ªôt ƒë∆∞·ªùng th·∫≥ng (t·ª©c l√† kh√¥ng tuy·∫øn t√≠nh), \n"
        "SVM s·ª≠ d·ª•ng h√†m kernel (kernel trick) ƒë·ªÉ √°nh x·∫° d·ªØ li·ªáu sang kh√¥ng gian b·∫≠c cao h∆°n, n∆°i ch√∫ng c√≥ th·ªÉ ph√¢n t√°ch tuy·∫øn t√≠nh."
    )

    st.markdown(" ##### C√°c kernel ph·ªï bi·∫øn:")
    st.markdown("- **Linear Kernel**: S·ª≠ d·ª•ng khi d·ªØ li·ªáu c√≥ th·ªÉ ph√¢n t√°ch tuy·∫øn t√≠nh.")
    st.markdown("- **Polynomial Kernel**: √Ånh x·∫° d·ªØ li·ªáu sang kh√¥ng gian b·∫≠c cao h∆°n.")
    st.markdown("- **RBF (Radial Basis Function) Kernel**: T·ªët cho d·ªØ li·ªáu phi tuy·∫øn t√≠nh.")
    st.markdown("- **Sigmoid Kernel**: M√¥ ph·ªèng nh∆∞ m·∫°ng neural.")

    st.markdown(" ##### 2.4 V·ªã tr√≠ t∆∞∆°ng ƒë·ªëi v·ªõi m·ªôt si√™u ph·∫≥ng ")
    st.markdown(
    """
    **N·∫øu** $w^T x + b > 0$ **:**
    - ƒêi·ªÉm $x$ n·∫±m ·ªü **ph√≠a d∆∞∆°ng** c·ªßa si√™u ph·∫≥ng.
    - Trong h√¨nh, c√°c ƒëi·ªÉm thu·ªôc l·ªõp d∆∞∆°ng (d·∫•u "+") n·∫±m ·ªü v√πng n√†y.
    
    **N·∫øu** $w^T x + b < 0$ **:**
    - ƒêi·ªÉm $x$ n·∫±m ·ªü **ph√≠a √¢m** c·ªßa si√™u ph·∫≥ng.
    - Trong h√¨nh, c√°c ƒëi·ªÉm thu·ªôc l·ªõp √¢m (d·∫•u "-") n·∫±m ·ªü v√πng n√†y.
    
    **N·∫øu** $w^T x + b = 0$ **:**
    - ƒêi·ªÉm $x$ n·∫±m **tr√™n si√™u ph·∫≥ng ph√¢n t√°ch**.
    - Trong SVM, si√™u ph·∫≥ng n√†y l√† ƒë∆∞·ªùng quy·∫øt ƒë·ªãnh, ph√¢n chia d·ªØ li·ªáu th√†nh hai l·ªõp kh√°c nhau.
    
    H√¨nh b√™n d∆∞·ªõi minh h·ªça c√°ch si√™u ph·∫≥ng ph√¢n chia d·ªØ li·ªáu.
    """
    )
    image_url = "https://machinelearningcoban.com/assets/19_svm/svm2.png"
    article_url = "https://machinelearningcoban.com/2017/04/09/smv/"
    st.markdown(
        f"""
        <div style="text-align: center;">
            <a href="{article_url}" target="_blank">
                <img src="{image_url}" width="500">
            </a>
            <p style="font-size: 14px; color: gray;"><i>
            </i></p>
        </div>
        """,
        unsafe_allow_html=True
    )  

def data():
    st.title("T·ªïng quan v·ªÅ t·∫≠p d·ªØ li·ªáu MNIST")

    st.header("1. Gi·ªõi thi·ªáu")
    st.write("T·∫≠p d·ªØ li·ªáu MNIST (Modified National Institute of Standards and Technology) l√† m·ªôt trong nh·ªØng t·∫≠p d·ªØ li·ªáu ph·ªï bi·∫øn nh·∫•t trong lƒ©nh v·ª±c Machine Learning v√† Computer Vision, th∆∞·ªùng ƒë∆∞·ª£c d√πng ƒë·ªÉ hu·∫•n luy·ªán v√† ki·ªÉm th·ª≠ c√°c m√¥ h√¨nh ph√¢n lo·∫°i ch·ªØ s·ªë vi·∫øt tay.") 

    st.image("https://datasets.activeloop.ai/wp-content/uploads/2019/12/MNIST-handwritten-digits-dataset-visualized-by-Activeloop.webp", use_container_width=True)

    st.subheader("N·ªôi dung")
    st.write("- 70.000 ·∫£nh grayscale (ƒëen tr·∫Øng) c·ªßa c√°c ch·ªØ s·ªë vi·∫øt tay t·ª´ 0 ƒë·∫øn 9.")
    st.write("- K√≠ch th∆∞·ªõc ·∫£nh: 28x28 pixel.")
    st.write("- ƒê·ªãnh d·∫°ng: M·ªói ·∫£nh ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·∫±ng m·ªôt ma tr·∫≠n 28x28 c√≥ gi√° tr·ªã pixel t·ª´ 0 (ƒëen) ƒë·∫øn 255 (tr·∫Øng).")
    st.write("- Nh√£n: M·ªôt s·ªë nguy√™n t·ª´ 0 ƒë·∫øn 9 t∆∞∆°ng ·ª©ng v·ªõi ch·ªØ s·ªë trong ·∫£nh.")

    st.header("2. Ngu·ªìn g·ªëc v√† √Ω nghƒ©a")
    st.write("- ƒê∆∞·ª£c t·∫°o ra t·ª´ b·ªô d·ªØ li·ªáu ch·ªØ s·ªë vi·∫øt tay g·ªëc c·ªßa NIST, do LeCun, Cortes v√† Burges chu·∫©n b·ªã.")
    st.write("- D√πng l√†m benchmark cho c√°c thu·∫≠t to√°n nh·∫≠n di·ªán h√¨nh ·∫£nh, ƒë·∫∑c bi·ªát l√† m·∫°ng n∆°-ron nh√¢n t·∫°o (ANN) v√† m·∫°ng n∆°-ron t√≠ch ch·∫≠p (CNN).")
    st.write("- R·∫•t h·ªØu √≠ch cho vi·ªác ki·ªÉm th·ª≠ m√¥ h√¨nh tr√™n d·ªØ li·ªáu h√¨nh ·∫£nh th·ª±c t·∫ø nh∆∞ng ƒë∆°n gi·∫£n.")

    st.header("3. Ph√¢n chia t·∫≠p d·ªØ li·ªáu")
    st.write("- T·∫≠p hu·∫•n luy·ªán: 60.000 ·∫£nh.")
    st.write("- T·∫≠p ki·ªÉm th·ª≠: 10.000 ·∫£nh.")
    st.write("- M·ªói t·∫≠p c√≥ ph√¢n b·ªë ƒë·ªìng ƒë·ªÅu v·ªÅ s·ªë l∆∞·ª£ng ch·ªØ s·ªë t·ª´ 0 ƒë·∫øn 9.")

    st.header("4. ·ª®ng d·ª•ng")
    st.write("- Hu·∫•n luy·ªán v√† ƒë√°nh gi√° c√°c thu·∫≠t to√°n nh·∫≠n di·ªán ch·ªØ s·ªë vi·∫øt tay.")
    st.write("- Ki·ªÉm th·ª≠ v√† so s√°nh hi·ªáu su·∫•t c·ªßa c√°c m√¥ h√¨nh h·ªçc s√¢u (Deep Learning).")
    st.write("- L√†m b√†i t·∫≠p th·ª±c h√†nh v·ªÅ x·ª≠ l√Ω ·∫£nh, tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng, m√¥ h√¨nh ph√¢n lo·∫°i.")
    st.write("- Cung c·∫•p m·ªôt baseline ƒë∆°n gi·∫£n cho c√°c b√†i to√°n li√™n quan ƒë·∫øn Computer Vision.")

    st.header("5. Ph∆∞∆°ng ph√°p ti·∫øp c·∫≠n ph·ªï bi·∫øn")
    st.write("- Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng truy·ªÅn th·ªëng: PCA, HOG, SIFT...")
    st.write("- Machine Learning: KNN, SVM, Random Forest, Logistic Regression...")
    st.write("- Deep Learning: MLP, CNN (LeNet-5, AlexNet, ResNet...), RNN")

    st.caption("·ª®ng d·ª•ng hi·ªÉn th·ªã th√¥ng tin v·ªÅ t·∫≠p d·ªØ li·ªáu MNIST b·∫±ng Streamlit üöÄ")
    

def up_load_db():
    # Ti√™u ƒë·ªÅ
    st.header("üì• T·∫£i D·ªØ Li·ªáu")

    # Ki·ªÉm tra xem d·ªØ li·ªáu ƒë√£ t·∫£i ch∆∞a
    if "data" in st.session_state and st.session_state.data is not None:
        st.warning("üî∏ **D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c t·∫£i l√™n r·ªìi!** B·∫°n c√≥ th·ªÉ ti·∫øp t·ª•c v·ªõi c√°c b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω v√† chia d·ªØ li·ªáu.")
    else:
        # Ch·ªçn ngu·ªìn d·ªØ li·ªáu
        option = st.radio("Ch·ªçn ngu·ªìn d·ªØ li·ªáu:", ["T·∫£i t·ª´ OpenML", "Upload d·ªØ li·ªáu"], key="data_source_radio")

        # Bi·∫øn ƒë·ªÉ l∆∞u tr·ªØ d·ªØ li·ªáu
        if "data" not in st.session_state:
            st.session_state.data = None

        # N·∫øu ch·ªçn t·∫£i t·ª´ OpenML
        if option == "T·∫£i t·ª´ OpenML":
            st.markdown("#### üìÇ T·∫£i d·ªØ li·ªáu MNIST t·ª´ OpenML")
            if st.button("T·∫£i d·ªØ li·ªáu MNIST", key="download_mnist_button"):
                st.write("üîÑ ƒêang t·∫£i d·ªØ li·ªáu MNIST t·ª´ OpenML...")

                progress_bar = st.progress(0)
                progress_text = st.empty()
                
                for percent_complete in range(100):
                    time.sleep(0.05 + (27 / 100))  # Th√™m 27 gi√¢y v√†o ti·∫øn tr√¨nh t·∫£i
                    progress_bar.progress(percent_complete + 1)
                    progress_text.text(f"‚è≥ ƒêang t·∫£i... {percent_complete + 1}%")
                
                # T·∫£i d·ªØ li·ªáu MNIST t·ª´ file .npy
                X = np.load("X.npy")
                y = np.load("y.npy")

                st.success("‚úÖ D·ªØ li·ªáu MNIST ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!")
                st.session_state.data = (X, y)  # L∆∞u d·ªØ li·ªáu v√†o session_state
                progress_bar.empty()
                progress_text.empty()

        # N·∫øu ch·ªçn upload d·ªØ li·ªáu t·ª´ m√°y
        else:
            st.markdown("#### üì§ Upload d·ªØ li·ªáu c·ªßa b·∫°n")

            uploaded_file = st.file_uploader("Ch·ªçn m·ªôt file ·∫£nh", type=["png", "jpg", "jpeg"], key="file_upload")

            if uploaded_file is not None:
                image = Image.open(uploaded_file)
                st.image(image, caption="·∫¢nh ƒë√£ t·∫£i l√™n", use_column_width=True)

                if image.size != (28, 28):
                    st.error("‚ùå ·∫¢nh kh√¥ng ƒë√∫ng k√≠ch th∆∞·ªõc 28x28 pixel. Vui l√≤ng t·∫£i l·∫°i ·∫£nh ƒë√∫ng ƒë·ªãnh d·∫°ng.")
                else:
                    st.success("‚úÖ ·∫¢nh h·ª£p l·ªá!")
                    image = image.convert('L')
                    image_array = np.array(image).reshape(1, 28, 28, 1)
                    st.session_state.data = image_array

    # Ki·ªÉm tra n·∫øu d·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c t·∫£i
    if st.session_state.data is not None:
        st.markdown("#### ‚úÖ D·ªØ li·ªáu ƒë√£ s·∫µn s√†ng!")
        
        if isinstance(st.session_state.data, tuple):
            X, y = st.session_state.data
            st.markdown("##### üîÑ Ti·∫øn h√†nh ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu MNIST")

            preprocess_option = st.selectbox("Ch·ªçn ph∆∞∆°ng ph√°p ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu:", 
                                            ["Chu·∫©n h√≥a d·ªØ li·ªáu (Normalization)", "Chu·∫©n h√≥a d·ªØ li·ªáu (Standardization)", "X·ª≠ l√Ω d·ªØ li·ªáu missing", "Kh√¥ng ti·ªÅn x·ª≠ l√Ω"], key="preprocess_mnist")

            X_reshaped = X.reshape(X.shape[0], -1)
            
            st.markdown("### ·∫¢nh ch∆∞a ti·ªÅn x·ª≠ l√Ω")
            fig, axes = plt.subplots(1, 5, figsize=(10, 2))
            for i in range(5):
                axes[i].imshow(X[i].reshape(28, 28), cmap='gray')
                axes[i].set_title(f"Label: {y[i]}")
                axes[i].axis('off')
            st.pyplot(fig)
            
            st.markdown("### K·∫øt qu·∫£ sau khi ti·ªÅn x·ª≠ l√Ω")
            fig, axes = plt.subplots(1, 5, figsize=(10, 2))
            progress_bar = st.progress(0)
            progress_text = st.empty()
            
            for percent_complete in range(100):
                time.sleep(0.02 + (27 / 100))  # Th√™m 27 gi√¢y v√†o ti·∫øn tr√¨nh ti·ªÅn x·ª≠ l√Ω
                progress_bar.progress(percent_complete + 1)
                progress_text.text(f"‚è≥ ƒêang x·ª≠ l√Ω... {percent_complete + 1}%")
            
            if preprocess_option == "Chu·∫©n h√≥a d·ªØ li·ªáu (Normalization)":
                X_normalized = MinMaxScaler().fit_transform(X_reshaped)
                for i in range(5):
                    axes[i].imshow(X_normalized[i].reshape(28, 28), cmap='gray')
                    axes[i].set_title(f"Label: {y[i]}")
                    axes[i].axis('off')
                st.success("‚úÖ ƒê√£ chu·∫©n h√≥a d·ªØ li·ªáu!")
            
            elif preprocess_option == "Chu·∫©n h√≥a d·ªØ li·ªáu (Standardization)":
                X_standardized = StandardScaler().fit_transform(X_reshaped)
                for i in range(5):
                    axes[i].imshow(X_standardized[i].reshape(28, 28), cmap='gray')
                    axes[i].set_title(f"Label: {y[i]}")
                    axes[i].axis('off')
                st.success("‚úÖ ƒê√£ chu·∫©n h√≥a d·ªØ li·ªáu!")
            
            elif preprocess_option == "X·ª≠ l√Ω d·ªØ li·ªáu missing":
                imputer = SimpleImputer(strategy='mean')
                X_imputed = imputer.fit_transform(X_reshaped)
                for i in range(5):
                    axes[i].imshow(X_imputed[i].reshape(28, 28), cmap='gray')
                    axes[i].set_title(f"Label: {y[i]}")
                    axes[i].axis('off')
                st.success("‚úÖ ƒê√£ x·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu!")
            else:
                for i in range(5):
                    axes[i].imshow(X[i].reshape(28, 28), cmap='gray')
                    axes[i].set_title(f"Label: {y[i]}")
                    axes[i].axis('off')
                st.success("‚úÖ Kh√¥ng th·ª±c hi·ªán ti·ªÅn x·ª≠ l√Ω!")
            
            progress_bar.empty()
            progress_text.empty()
            st.pyplot(fig)
    
    else:
        st.warning("üî∏ Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc khi ti·∫øp t·ª•c l√†m vi·ªác.")


def chia_du_lieu():
    st.title("üìå Chia d·ªØ li·ªáu Train/Test")

    # ƒê·ªçc d·ªØ li·ªáu
    X = np.load("X.npy")
    y = np.load("y.npy")
    total_samples = X.shape[0]

    
    # N·∫øu ch∆∞a c√≥ c·ªù "data_split_done", ƒë·∫∑t m·∫∑c ƒë·ªãnh l√† False
    if "data_split_done" not in st.session_state:
        st.session_state.data_split_done = False  

    # Thanh k√©o ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ train
    num_samples = st.slider("üìå Ch·ªçn s·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ train:", 1000, total_samples, 10000)
    
    # Thanh k√©o ch·ªçn t·ª∑ l·ªá Train/Test
    test_size = st.slider("üìå Ch·ªçn % d·ªØ li·ªáu Test", 10, 50, 20)
    remaining_size = 100 - test_size
    val_size = st.slider("üìå Ch·ªçn % d·ªØ li·ªáu Validation (trong ph·∫ßn Train)", 0, 50, 15)
    st.write(f"üìå **T·ª∑ l·ªá ph√¢n chia:** Test={test_size}%, Validation={val_size}%, Train={remaining_size - val_size}%")

    if st.button("‚úÖ X√°c nh·∫≠n & L∆∞u") and not st.session_state.data_split_done:
        st.session_state.data_split_done = True  # ƒê√°nh d·∫•u ƒë√£ chia d·ªØ li·ªáu
        
        # Chia d·ªØ li·ªáu theo t·ª∑ l·ªá ƒë√£ ch·ªçn
        X_selected, _, y_selected, _ = train_test_split(
            X, y, train_size=num_samples, stratify=y, random_state=42
        )

        # Chia train/test
        stratify_option = y_selected if len(np.unique(y_selected)) > 1 else None
        X_train_full, X_test, y_train_full, y_test = train_test_split(
            X_selected, y_selected, test_size=test_size/100, stratify=stratify_option, random_state=42
        )

        # Chia train/val
        stratify_option = y_train_full if len(np.unique(y_train_full)) > 1 else None
        X_train, X_val, y_train, y_val = train_test_split(
            X_train_full, y_train_full, test_size=val_size / (100 - test_size),
            stratify=stratify_option, random_state=42
        )

        # L∆∞u d·ªØ li·ªáu v√†o session_state
        st.session_state.total_samples= num_samples
        st.session_state.X_train = X_train
        st.session_state.X_val = X_val
        st.session_state.X_test = X_test
        st.session_state.y_train = y_train
        st.session_state.y_val = y_val
        st.session_state.y_test = y_test
        st.session_state.test_size = X_test.shape[0]
        st.session_state.val_size = X_val.shape[0]
        st.session_state.train_size = X_train.shape[0]

        # Hi·ªÉn th·ªã th√¥ng tin chia d·ªØ li·ªáu
        summary_df = pd.DataFrame({
            "T·∫≠p d·ªØ li·ªáu": ["Train", "Validation", "Test"],
            "S·ªë l∆∞·ª£ng m·∫´u": [X_train.shape[0], X_val.shape[0], X_test.shape[0]]
        })
        st.success("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia th√†nh c√¥ng!")
        st.table(summary_df)

    elif st.session_state.data_split_done:
        st.info("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia, kh√¥ng c·∫ßn ch·∫°y l·∫°i.")



def train():
    """Hu·∫•n luy·ªán m√¥ h√¨nh Decision Tree ho·∫∑c SVM v√† l∆∞u tr√™n MLflow v·ªõi thanh ti·∫øn tr√¨nh hi·ªÉn th·ªã %."""
    mlflow_input()

    # üì• Ki·ªÉm tra d·ªØ li·ªáu
    if not all(key in st.session_state for key in ["X_train", "y_train", "X_test", "y_test"]):
        st.error("‚ö†Ô∏è Ch∆∞a c√≥ d·ªØ li·ªáu! H√£y chia d·ªØ li·ªáu tr∆∞·ªõc.")
        return

    X_train, y_train = st.session_state["X_train"], st.session_state["y_train"]
    X_test, y_test = st.session_state["X_test"], st.session_state["y_test"]

    # üåü Chu·∫©n h√≥a d·ªØ li·ªáu
    X_train, X_test = X_train.reshape(-1, 28 * 28) / 255.0, X_test.reshape(-1, 28 * 28) / 255.0

    st.header("‚öôÔ∏è Ch·ªçn m√¥ h√¨nh & Hu·∫•n luy·ªán")

    # üìå ƒê·∫∑t t√™n th√≠ nghi·ªám
    experiment_name = st.text_input("üìå ƒê·∫∑t t√™n th√≠ nghi·ªám:", "default_experiment", 
                                    help="T√™n c·ªßa th√≠ nghi·ªám ƒë·ªÉ d·ªÖ d√†ng qu·∫£n l√Ω tr√™n MLflow.")

    # üìå L·ª±a ch·ªçn m√¥ h√¨nh
    model_choice = st.selectbox("Ch·ªçn m√¥ h√¨nh:", ["Decision Tree", "SVM"])
    
    if model_choice == "Decision Tree":
        criterion = st.selectbox("Criterion (H√†m m·∫•t m√°t: Gini/Entropy) ", ["gini", "entropy"])
        max_depth = st.slider("max_depth", 1, 20, 5, help="Gi·ªõi h·∫°n ƒë·ªô s√¢u c·ªßa c√¢y ƒë·ªÉ tr√°nh overfitting.")
        model = DecisionTreeClassifier(criterion=criterion, max_depth=max_depth)
    else:
        C = st.slider("C (H·ªá s·ªë ƒëi·ªÅu chu·∫©n)", 0.1, 10.0, 1.0)
        kernel = st.selectbox("Kernel (H√†m nh√¢n)", ["linear", "rbf", "poly", "sigmoid"])
        model = SVC(C=C, kernel=kernel)

    # üìå Ch·ªçn s·ªë folds cho KFold Cross-Validation
    k_folds = st.slider("S·ªë folds", 2, 10, 5, help="S·ªë t·∫≠p chia ƒë·ªÉ ƒë√°nh gi√° m√¥ h√¨nh.")

    # üöÄ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán
    if st.button("Hu·∫•n luy·ªán m√¥ h√¨nh"):
        with st.spinner("üîÑ ƒêang hu·∫•n luy·ªán m√¥ h√¨nh..."):
            progress_bar = st.progress(0)
            percent_text = st.empty()  # Ch·ªó hi·ªÉn th·ªã %

            with mlflow.start_run(run_name=experiment_name):
                kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)
                cv_scores = []

                # V√≤ng l·∫∑p Cross-Validation
                for fold, (train_idx, val_idx) in enumerate(kf.split(X_train)):
                    X_train_fold, X_val_fold = X_train[train_idx], X_train[val_idx]
                    y_train_fold, y_val_fold = y_train[train_idx], y_train[val_idx]

                    model.fit(X_train_fold, y_train_fold)
                    val_pred = model.predict(X_val_fold)
                    val_acc = accuracy_score(y_val_fold, val_pred)
                    cv_scores.append(val_acc)
                    mlflow.log_metric("cv_accuracy", val_acc, step=fold)

                    # C·∫≠p nh·∫≠t thanh tr·∫°ng th√°i (b·ªè qua hi·ªÉn th·ªã t·ª´ng fold)
                    percent_done = int(((fold + 1) / k_folds) * 70)
                    progress_bar.progress(percent_done)
                    percent_text.write(f"**Ti·∫øn ƒë·ªô: {percent_done}%**")

                    time.sleep(1)  

                # K·∫øt qu·∫£ CV
                cv_accuracy_mean = np.mean(cv_scores)
                cv_accuracy_std = np.std(cv_scores)
                st.success(f"‚úÖ **Cross-Validation Accuracy:** {cv_accuracy_mean:.4f} ¬± {cv_accuracy_std:.4f}")

                # Hu·∫•n luy·ªán tr√™n to√†n b·ªô t·∫≠p train
                model.fit(X_train, y_train)

                # C·∫≠p nh·∫≠t ti·∫øn tr√¨nh (85%)
                progress_bar.progress(85)
                percent_text.write("**Ti·∫øn ƒë·ªô: 85%**")

                # D·ª± ƒëo√°n tr√™n test set
                y_pred = model.predict(X_test)
                test_acc = accuracy_score(y_test, y_pred)
                mlflow.log_metric("test_accuracy", test_acc)
                st.success(f"‚úÖ **ƒê·ªô ch√≠nh x√°c tr√™n test set:** {test_acc:.4f}")

                # Delay th√™m 20s tr∆∞·ªõc khi ho√†n th√†nh
                for i in range(1, 21):
                    progress_percent = 85 + (i // 2)
                    progress_bar.progress(progress_percent)
                    percent_text.write(f"**Ti·∫øn ƒë·ªô: {progress_percent}%**")
                    time.sleep(1)

                # Ho√†n th√†nh ti·∫øn tr√¨nh
                progress_bar.progress(100)
                percent_text.write("‚úÖ **Ti·∫øn ƒë·ªô: 100% - Ho√†n th√†nh!**")

                # Log tham s·ªë v√†o MLflow
                mlflow.log_param("experiment_name", experiment_name)
                mlflow.log_param("model", model_choice)
                mlflow.log_param("k_folds", k_folds)
                if model_choice == "Decision Tree":
                    mlflow.log_param("criterion", criterion)
                    mlflow.log_param("max_depth", max_depth)
                else:
                    mlflow.log_param("C", C)
                    mlflow.log_param("kernel", kernel)

                mlflow.log_metric("cv_accuracy_mean", cv_accuracy_mean)
                mlflow.log_metric("cv_accuracy_std", cv_accuracy_std)
                mlflow.sklearn.log_model(model, model_choice.lower())

                st.success(f"‚úÖ ƒê√£ log d·ªØ li·ªáu cho **{experiment_name}**!")
                st.markdown(f"üîó [Truy c·∫≠p MLflow UI]({st.session_state['mlflow_url']})")


def mlflow_input():
    #st.title("üöÄ MLflow DAGsHub Tracking v·ªõi Streamlit")
    DAGSHUB_USERNAME = "Snxtruc"  # Thay b·∫±ng username c·ªßa b·∫°n
    DAGSHUB_REPO_NAME = "HocMayPython"
    DAGSHUB_TOKEN = "ca4b78ae4dd9d511c1e0c333e3b709b2cd789a19"  # Thay b·∫±ng Access Token c·ªßa b·∫°n

    # ƒê·∫∑t URI MLflow ƒë·ªÉ tr·ªè ƒë·∫øn DagsHub
    mlflow.set_tracking_uri(f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO_NAME}.mlflow")

    # Thi·∫øt l·∫≠p authentication b·∫±ng Access Token
    os.environ["MLFLOW_TRACKING_USERNAME"] = DAGSHUB_USERNAME
    os.environ["MLFLOW_TRACKING_PASSWORD"] = DAGSHUB_TOKEN

    # ƒê·∫∑t th√≠ nghi·ªám MLflow
    mlflow.set_experiment("Classifications")   

    st.session_state['mlflow_url'] = f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO_NAME}.mlflow"


def load_model(path):
    try:
        return joblib.load(path)
    except FileNotFoundError:
        st.error(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y m√¥ h√¨nh t·∫°i `{path}`")
        st.stop()

# ‚úÖ X·ª≠ l√Ω ·∫£nh t·ª´ canvas (chu·∫©n 28x28 cho MNIST)
def preprocess_canvas_image(canvas_result):
    if canvas_result.image_data is not None:
        img = Image.fromarray(canvas_result.image_data[:, :, 0].astype(np.uint8))
        img = img.resize((28, 28)).convert("L")  # Resize v√† chuy·ªÉn th√†nh grayscale
        img = np.array(img, dtype=np.float32) / 255.0  # Chu·∫©n h√≥a v·ªÅ [0, 1]
        return img.reshape(1, -1)  # Chuy·ªÉn th√†nh vector 1D
    return None


def preprocess_canvas_image(canvas_result):
    if canvas_result.image_data is None:
        return None
    img = Image.fromarray((canvas_result.image_data[:, :, 0] * 255).astype(np.uint8))
    img = img.convert("L").resize((28, 28))  # Chuy·ªÉn sang ·∫£nh x√°m 28x28
    img = np.array(img) / 255.0  # Chu·∫©n h√≥a
    return img.reshape(1, -1)


def format_time_relative(timestamp_ms):
    """Chuy·ªÉn timestamp sang d·∫°ng 'X minutes ago'."""
    if timestamp_ms:
        created_at_dt = datetime.fromtimestamp(timestamp_ms / 1000)
        return humanize.naturaltime(datetime.now() - created_at_dt)
    return "N/A"

def display_mlflow_experiments():
    """Hi·ªÉn th·ªã danh s√°ch Runs trong MLflow."""
    st.title("üìä MLflow Experiment Viewer")

    # K·∫øt n·ªëi MLflow (T·ª± ƒë·ªông g·ªçi mlflow_input)
    mlflow_input()

    experiment_name = "Classifications"
    experiments = mlflow.search_experiments()
    selected_experiment = next((exp for exp in experiments if exp.name == experiment_name), None)

    if not selected_experiment:
        st.error(f"‚ùå Experiment '{experiment_name}' kh√¥ng t·ªìn t·∫°i!")
        return

    st.subheader(f"üìå Experiment: {experiment_name}")
    st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
    st.write(f"**Tr·∫°ng th√°i:** {'Active' if selected_experiment.lifecycle_stage == 'active' else 'Deleted'}")
    st.write(f"**V·ªã tr√≠ l∆∞u tr·ªØ:** {selected_experiment.artifact_location}")

    # L·∫•y danh s√°ch Runs
    runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])

    if runs.empty:
        st.warning("‚ö† Kh√¥ng c√≥ runs n√†o trong experiment n√†y.")
        return

    # X·ª≠ l√Ω d·ªØ li·ªáu runs ƒë·ªÉ hi·ªÉn th·ªã
    run_info = []
    for _, run in runs.iterrows():
        run_id = run["run_id"]
        run_data = mlflow.get_run(run_id)
        run_tags = run_data.data.tags
        run_name = run_tags.get("mlflow.runName", f"Run {run_id[:8]}")  # L·∫•y t√™n t·ª´ tags n·∫øu c√≥
        created_time = format_time_relative(run_data.info.start_time)
        duration = run_data.info.end_time - run_data.info.start_time if run_data.info.end_time else "ƒêang ch·∫°y"
        source = run_tags.get("mlflow.source.name", "Unknown")

        run_info.append({
            "Run Name": run_name,
            "Run ID": run_id,
            "Created": created_time,
            "Duration": duration,
            "Source": source
        })

    # S·∫Øp x·∫øp run theo th·ªùi gian ch·∫°y (m·ªõi nh·∫•t tr∆∞·ªõc)
    run_info_df = pd.DataFrame(run_info)
    run_info_df = run_info_df.sort_values(by="Created", ascending=False)

    # Hi·ªÉn th·ªã danh s√°ch Runs trong b·∫£ng
    st.write("### üèÉ‚Äç‚ôÇÔ∏è Danh s√°ch Runs:")
    st.dataframe(run_info_df, use_container_width=True)

    # Ch·ªçn Run t·ª´ dropdown
    run_names = run_info_df["Run Name"].tolist()
    selected_run_name = st.selectbox("üîç Ch·ªçn m·ªôt Run ƒë·ªÉ xem chi ti·∫øt:", run_names)

    # L·∫•y Run ID t∆∞∆°ng ·ª©ng
    selected_run_id = run_info_df.loc[run_info_df["Run Name"] == selected_run_name, "Run ID"].values[0]

    # L·∫•y th√¥ng tin Run
    selected_run = mlflow.get_run(selected_run_id)

    # --- üìù ƒê·ªîI T√äN RUN ---
    st.write("### ‚úèÔ∏è ƒê·ªïi t√™n Run")
    new_run_name = st.text_input("Nh·∫≠p t√™n m·ªõi:", selected_run_name)
    if st.button("üíæ L∆∞u t√™n m·ªõi"):
        try:
            mlflow.set_tag(selected_run_id, "mlflow.runName", new_run_name)
            st.success(f"‚úÖ ƒê√£ ƒë·ªïi t√™n th√†nh **{new_run_name}**. H√£y t·∫£i l·∫°i trang ƒë·ªÉ th·∫•y thay ƒë·ªïi!")
        except Exception as e:
            st.error(f"‚ùå L·ªói khi ƒë·ªïi t√™n: {e}")

    # --- üóëÔ∏è X√ìA RUN ---
    st.write("### ‚ùå X√≥a Run")
    if st.button("üóëÔ∏è X√≥a Run n√†y"):
        try:
            mlflow.delete_run(selected_run_id)
            st.success(f"‚úÖ ƒê√£ x√≥a run **{selected_run_name}**! H√£y t·∫£i l·∫°i trang ƒë·ªÉ c·∫≠p nh·∫≠t danh s√°ch.")
        except Exception as e:
            st.error(f"‚ùå L·ªói khi x√≥a run: {e}")

    # --- HI·ªÇN TH·ªä CHI TI·∫æT RUN ---
    if selected_run:
        st.subheader(f"üìå Th√¥ng tin Run: {selected_run_name}")
        st.write(f"**Run ID:** {selected_run_id}")
        st.write(f"**Tr·∫°ng th√°i:** {selected_run.info.status}")
        
        start_time_ms = selected_run.info.start_time  # Th·ªùi gian l∆∞u d∆∞·ªõi d·∫°ng milliseconds
        if start_time_ms:
            start_time = datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S")
        else:
            start_time = "Kh√¥ng c√≥ th√¥ng tin"
        
        st.write(f"**Th·ªùi gian ch·∫°y:** {start_time}")

        # Hi·ªÉn th·ªã th√¥ng s·ªë ƒë√£ log
        params = selected_run.data.params
        metrics = selected_run.data.metrics

        if params:
            st.write("### ‚öôÔ∏è Parameters:")
            st.json(params)

        if metrics:
            st.write("### üìä Metrics:")
            st.json(metrics)

        # Hi·ªÉn th·ªã model artifact (n·∫øu c√≥)
        model_artifact_path = f"{st.session_state['mlflow_url']}/{selected_experiment.experiment_id}/{selected_run_id}/artifacts/model"
        st.write("### üìÇ Model Artifact:")
        st.write(f"üì• [T·∫£i m√¥ h√¨nh]({model_artifact_path})")

    else:
        st.warning("‚ö† Kh√¥ng t√¨m th·∫•y th√¥ng tin cho run n√†y.")


def du_doan():
    st.header("‚úçÔ∏è D·ª± ƒëo√°n s·ªë")
    
    # üîπ Ch·ªçn ph∆∞∆°ng th·ª©c d·ª± ƒëo√°n
    mode = st.radio("Ch·ªçn ph∆∞∆°ng th·ª©c d·ª± ƒëo√°n:", ["V·∫Ω s·ªë", "Upload file test"])
    
    if mode == "V·∫Ω s·ªë":
        # ‚úçÔ∏è V·∫Ω s·ªë
        st.subheader("üñåÔ∏è V·∫Ω s·ªë v√†o khung d∆∞·ªõi ƒë√¢y:")
        canvas_result = st_canvas(
            fill_color="black",
            stroke_width=10,
            stroke_color="white",
            background_color="black",
            height=150,
            width=150,
            drawing_mode="freedraw",
            key="canvas"
        )
    
    elif mode == "Upload file test":
        # üîπ Upload file test
        st.header("üìÇ D·ª± ƒëo√°n tr√™n t·∫≠p test")
        uploaded_file = st.file_uploader("T·∫£i t·∫≠p test (CSV ho·∫∑c NPY):", type=["csv", "npy"])
        
        if uploaded_file is not None:
            if uploaded_file.name.endswith(".csv"):
                test_data = pd.read_csv(uploaded_file).values
            else:
                test_data = np.load(uploaded_file)
            
            st.write(f"üìä D·ªØ li·ªáu test c√≥ {test_data.shape[0]} m·∫´u.")
    
    # üîπ Danh s√°ch m√¥ h√¨nh c√≥ s·∫µn
    available_models = {
        "SVM Linear": "svm_mnist_linear.joblib",
        "SVM Poly": "svm_mnist_poly.joblib",
        "SVM Sigmoid": "svm_mnist_sigmoid.joblib",
        "SVM RBF": "svm_mnist_rbf.joblib",
    }
    
    # üìå Ch·ªçn m√¥ h√¨nh
    model_option = st.selectbox("üîç Ch·ªçn m√¥ h√¨nh:", list(available_models.keys()))
    
    # T·∫£i m√¥ h√¨nh
    model = joblib.load(available_models[model_option])
    st.success(f"‚úÖ M√¥ h√¨nh {model_option} ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng!")
    
    if mode == "V·∫Ω s·ªë":
        if st.button("D·ª± ƒëo√°n s·ªë"):
            if canvas_result.image_data is not None:
                img = preprocess_canvas_image(canvas_result)
                st.image(Image.fromarray((img.reshape(28, 28) * 255).astype(np.uint8)), caption="·∫¢nh sau x·ª≠ l√Ω", width=100)
                prediction = model.predict(img)
                probabilities = model.decision_function(img) if hasattr(model, 'decision_function') else model.predict_proba(img)
                confidence = np.max(probabilities) if probabilities is not None else "Kh√¥ng x√°c ƒë·ªãnh"
                st.subheader(f"üî¢ K·∫øt qu·∫£ d·ª± ƒëo√°n: {prediction[0]} (ƒê·ªô tin c·∫≠y: {confidence:.2f})")
            else:
                st.error("‚ö†Ô∏è Vui l√≤ng v·∫Ω m·ªôt s·ªë tr∆∞·ªõc khi d·ª± ƒëo√°n!")
    
    elif mode == "Upload file test" and uploaded_file is not None:
        if st.button("D·ª± ƒëo√°n tr√™n t·∫≠p test"):
            predictions = model.predict(test_data)
            probabilities = model.decision_function(test_data) if hasattr(model, 'decision_function') else model.predict_proba(test_data)
            confidences = np.max(probabilities, axis=1) if probabilities is not None else ["Kh√¥ng x√°c ƒë·ªãnh"] * len(predictions)
            
            st.write("üî¢ K·∫øt qu·∫£ d·ª± ƒëo√°n:")
            for i in range(min(10, len(predictions))):
                st.write(f"M·∫´u {i + 1}: {predictions[i]} (ƒê·ªô tin c·∫≠y: {confidences[i]:.2f})")
            
            fig, axes = plt.subplots(1, min(5, len(test_data)), figsize=(10, 2))
            for i, ax in enumerate(axes):
                ax.imshow(test_data[i].reshape(28, 28), cmap='gray')
                ax.set_title(f"{predictions[i]} ({confidences[i]:.2f})")
                ax.axis("off")
            st.pyplot(fig)




def Classification():
    # Thi·∫øt l·∫≠p CSS ƒë·ªÉ h·ªó tr·ª£ hi·ªÉn th·ªã tabs v·ªõi hi·ªáu ·ª©ng hover v√† thanh cu·ªôn
    st.markdown(
        """
        <style>
        .stTabs [role="tablist"] {
            overflow-x: auto;
            white-space: nowrap;
            display: flex;
            scrollbar-width: thin;
            scrollbar-color: #888 #f0f0f0;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar {
            height: 6px;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar-thumb {
            background-color: #888;
            border-radius: 3px;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar-track {
            background: #f0f0f0;
        }
        .stTabs [role="tab"]:hover {
            background-color: #f0f0f0;
            transition: background-color 0.3s ease-in-out;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

    # Ti√™u ƒë·ªÅ ·ª©ng d·ª•ng
    st.title("üñ•Ô∏è MNIST Classification App")

    # T·∫°o c√°c tab trong giao di·ªán Streamlit
    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
        "üìñ L√Ω thuy·∫øt Decision Tree", 
        "üìñ L√Ω thuy·∫øt SVM", 
        "üöÄ Review database", 
        "üì• T·∫£i d·ªØ li·ªáu", 
        "‚öôÔ∏è Hu·∫•n luy·ªán", 
        "Tracking mlflow",
        "üîÆ D·ª± ƒëo√°n"
    ])

    # N·ªôi dung c·ªßa t·ª´ng tab
    with tab1:
        ly_thuyet_Decision_tree()

    with tab2:
        ly_thuyet_SVM()
    
    with tab3:
        data()

    with tab4:
        up_load_db()
    
    with tab5:      
        chia_du_lieu()
        train()
    
    with tab6:
        display_mlflow_experiments()

    with tab7:
        du_doan()  # G·ªçi h√†m d·ª± ƒëo√°n ƒë·ªÉ x·ª≠ l√Ω khi v√†o tab D·ª± ƒëo√°n

def run(): 
    Classification()

if __name__ == "__main__":
    run()
