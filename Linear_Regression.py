import mlflow
import os
import time
import numpy as np
import pandas as pd
from math import sqrt
from sklearn.datasets import make_regression
import joblib
import datetime
from scipy.stats import zscore
from mlflow.tracking import MlflowClient 
from sklearn.preprocessing import LabelEncoder, PolynomialFeatures
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split, KFold
from sklearn.preprocessing import StandardScaler 
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import SGDRegressor
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import PolynomialFeatures
from sklearn.model_selection import cross_val_score
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.metrics import mean_squared_error, r2_score, accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns

import streamlit as st

DAGSHUB_USERNAME = "Snxtruc"  
DAGSHUB_REPO_NAME = "HocMayVoiPython"
DAGSHUB_TOKEN = "ca4b78ae4dd9d511c1e0c333e3b709b2cd789a19"

def ly_thuyet_mlinear(): 
    # Ti√™u ƒë·ªÅ ·ª©ng d·ª•ng v·ªõi icon
    st.markdown(" ## üìà H·ªìi quy tuy·∫øn t√≠nh ƒëa bi·∫øn (Multiple Linear Regression - MLR)")

    # Hi·ªÉn th·ªã n·ªôi dung l√Ω thuy·∫øt
    st.markdown("""
    ### 1. üìå Kh√°i ni·ªám
    H·ªìi quy tuy·∫øn t√≠nh ƒëa bi·∫øn l√† m√¥ h√¨nh m·ªü r·ªông c·ªßa h·ªìi quy tuy·∫øn t√≠nh ƒë∆°n bi·∫øn, d√πng ƒë·ªÉ m√¥ t·∫£ m·ªëi quan h·ªá gi·ªØa m·ªôt bi·∫øn ph·ª• thu·ªôc (output) v√† nhi·ªÅu bi·∫øn ƒë·ªôc l·∫≠p (input).

    M√¥ h√¨nh t·ªïng qu√°t c·ªßa h·ªìi quy tuy·∫øn t√≠nh ƒëa bi·∫øn c√≥ d·∫°ng:
    """)

    st.latex(r"""
    y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + ... + \beta_n x_n + \epsilon
    """)

    st.markdown("""
    üîπ **Trong ƒë√≥:**
    - $y$ l√† bi·∫øn ph·ª• thu·ªôc (gi√° tr·ªã c·∫ßn d·ª± ƒëo√°n),
    - $x_1, x_2, ..., x_n$ l√† c√°c bi·∫øn ƒë·ªôc l·∫≠p (c√°c y·∫øu t·ªë ·∫£nh h∆∞·ªüng ƒë·∫øn $y$),
    - $\beta_0$ l√† h·ªá s·ªë ch·∫∑n (intercept),
    - $\beta_1, \beta_2, ..., \beta_n$ l√† c√°c h·ªá s·ªë h·ªìi quy,
    - $\epsilon$ l√† sai s·ªë (error term).
    """)

    st.markdown("""
    ### 2. ‚úÖ Gi·∫£ ƒë·ªãnh c·ªßa m√¥ h√¨nh MLR
    M√¥ h√¨nh h·ªìi quy tuy·∫øn t√≠nh ƒëa bi·∫øn c·∫ßn th·ªèa m√£n c√°c gi·∫£ ƒë·ªãnh sau:
    1. üìà **Tuy·∫øn t√≠nh**: M·ªëi quan h·ªá gi·ªØa bi·∫øn ph·ª• thu·ªôc v√† bi·∫øn ƒë·ªôc l·∫≠p l√† tuy·∫øn t√≠nh.
    2. üö´ **Kh√¥ng c√≥ ƒëa c·ªông tuy·∫øn**: C√°c bi·∫øn ƒë·ªôc l·∫≠p kh√¥ng ƒë∆∞·ª£c ph·ª• thu·ªôc tuy·∫øn t√≠nh m·∫°nh v·ªõi nhau.
    3. üîÑ **ƒê·ªôc l·∫≠p**: C√°c quan s√°t ph·∫£i ƒë·ªôc l·∫≠p v·ªõi nhau.
    4. üéØ **Ph√¢n ph·ªëi chu·∫©n c·ªßa sai s·ªë**: Sai s·ªë c√≥ ph√¢n ph·ªëi chu·∫©n v·ªõi trung b√¨nh b·∫±ng 0.
    5. ‚öñÔ∏è **Ph∆∞∆°ng sai kh√¥ng ƒë·ªïi**: Ph∆∞∆°ng sai c·ªßa sai s·ªë kh√¥ng thay ƒë·ªïi theo bi·∫øn ƒë·ªôc l·∫≠p.

    ### 3. üî¢ ∆Ø·ªõc l∆∞·ª£ng tham s·ªë b·∫±ng OLS
    C√°c h·ªá s·ªë h·ªìi quy $\beta$ ƒë∆∞·ª£c ∆∞·ªõc l∆∞·ª£ng b·∫±ng ph∆∞∆°ng ph√°p **B√¨nh ph∆∞∆°ng t·ªëi thi·ªÉu th√¥ng th∆∞·ªùng (OLS)**:
    """)

    st.latex(r"""
    \beta = (X^T X)^{-1} X^T Y
    """)

    st.markdown("""
    üìå **Trong ƒë√≥:**
    - üìä $X$ l√† ma tr·∫≠n d·ªØ li·ªáu c·ªßa bi·∫øn ƒë·ªôc l·∫≠p,
    - üéØ $Y$ l√† vector gi√° tr·ªã th·ª±c c·ªßa bi·∫øn ph·ª• thu·ªôc.

    ### 4. üöÄ ·ª®ng d·ª•ng c·ªßa MLR
    H·ªìi quy tuy·∫øn t√≠nh ƒëa bi·∫øn ƒë∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i trong:
    - üí∞ D·ª± b√°o doanh thu d·ª±a tr√™n chi ti√™u qu·∫£ng c√°o, gi√° b√°n, c√°c y·∫øu t·ªë kinh t·∫ø.
    - üè° D·ª± ƒëo√°n gi√° nh√† d·ª±a tr√™n di·ªán t√≠ch, v·ªã tr√≠, s·ªë ph√≤ng, v.v.
    - üìâ Ph√¢n t√≠ch d·ªØ li·ªáu t√†i ch√≠nh, nghi√™n c·ª©u khoa h·ªçc.
    """)

    # Hi·ªÉn th·ªã ti√™u ƒë·ªÅ
    st.title("üìå H·ªìi quy ƒëa th·ª©c (Polynomial Regression)")

    # Hi·ªÉn th·ªã ƒë·ªãnh nghƒ©a
    st.markdown("""
    ### üîπ 1. ƒê·ªãnh nghƒ©a
    H·ªìi quy ƒëa th·ª©c l√† m·ªôt m·ªü r·ªông c·ªßa h·ªìi quy tuy·∫øn t√≠nh, trong ƒë√≥ m·ªëi quan h·ªá gi·ªØa bi·∫øn ƒë·∫ßu v√†o (X) v√† bi·∫øn m·ª•c ti√™u (y) ƒë∆∞·ª£c m√¥ h√¨nh h√≥a d∆∞·ªõi d·∫°ng m·ªôt ph∆∞∆°ng tr√¨nh ƒëa th·ª©c b·∫≠c d:
    """)

    st.latex(r"""
    y = w_0 + w_1 x + w_2 x^2 + ... + w_d x^d + \epsilon
    """)

    st.markdown("""
    Trong ƒë√≥:
    - \( y \) l√† bi·∫øn m·ª•c ti√™u.
    - \( x \) l√† bi·∫øn ƒë·ªôc l·∫≠p (ƒë·∫ßu v√†o).
    - \( w_0, w_1, ..., w_d \) l√† c√°c h·ªá s·ªë h·ªìi quy (c·∫ßn t√¨m).
    - \( d \) l√† **b·∫≠c c·ªßa ƒëa th·ª©c** (degree).
    - \( \epsilon \) l√† nhi·ªÖu (noise).

    Khi \( d = 1 \), m√¥ h√¨nh tr·ªü th√†nh **h·ªìi quy tuy·∫øn t√≠nh**.
    """)


## ----------------------------------- UPLOAD_DB ------------------------------
def up_load_db():
    st.header("Ph√¢n t√≠ch v√† x·ª≠ l√Ω d·ªØ li·ªáu")
    
    # üì• T·∫£i d·ªØ li·ªáu
    with st.expander("üì• T·∫£i d·ªØ li·ªáu", expanded=True):
        uploaded_file = st.file_uploader("T·∫£i file CSV (Titanic dataset)", type=["csv"])
        if uploaded_file is not None:
            st.session_state.df = pd.read_csv(uploaded_file)
            st.write("D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c t·∫£i l√™n:")
            st.write(st.session_state.df.head(10))
            st.session_state.data_loaded = True

    # üîç Ki·ªÉm tra d·ªØ li·ªáu
    with st.expander("üîç Ki·ªÉm tra d·ªØ li·ªáu"):
        if st.session_state.get("data_loaded", False):
            df = st.session_state.df

            # T√≠nh s·ªë l∆∞·ª£ng gi√° tr·ªã thi·∫øu
            missing_values = df.isnull().sum()

            # X√°c ƒë·ªãnh outliers b·∫±ng Z-score
            outlier_count = {
                col: (abs(zscore(df[col], nan_policy='omit')) > 3).sum()
                for col in df.select_dtypes(include=['number']).columns
            }

            # T·∫°o b√°o c√°o l·ªói
            error_report = pd.DataFrame({
                "C·ªôt": df.columns,
                "Gi√° tr·ªã thi·∫øu": missing_values.values,
                "Outlier": [outlier_count.get(col, 0) for col in df.columns]
            })

            # Hi·ªÉn th·ªã b·∫£ng b√°o c√°o v·ªõi chi·ªÅu r·ªông t·ªëi ƒëa
            st.write("**Gi√° tr·ªã thi·∫øu v√† Outlier:**")
            st.table(error_report)
        else:
            st.warning("Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc.")

    # ‚öôÔ∏è X·ª≠ l√Ω d·ªØ li·ªáu
    with st.expander("‚öôÔ∏è X·ª≠ l√Ω d·ªØ li·ªáu"):
        if st.session_state.get("data_loaded", False):
            df = st.session_state.df.copy()

            # Lo·∫°i b·ªè c·ªôt
            dropped_cols = st.multiselect("Ch·ªçn c·ªôt c·∫ßn lo·∫°i b·ªè:", df.columns.tolist(), default=["PassengerId", "Name", "Ticket", "Cabin"])
            df.drop(columns=dropped_cols, errors='ignore', inplace=True)
            st.write(f"ƒê√£ lo·∫°i b·ªè c√°c c·ªôt: {', '.join(dropped_cols)}")

            # ƒêi·ªÅn gi√° tr·ªã thi·∫øu
            st.write("ƒêi·ªÅn gi√° tr·ªã thi·∫øu:")
            fill_missing_cols = st.multiselect("Ch·ªçn c·ªôt ƒë·ªÉ ƒëi·ªÅn gi√° tr·ªã thi·∫øu:", df.columns.tolist())
            for col in fill_missing_cols:
                if df[col].isnull().any():
                    method = st.selectbox(f"Ph∆∞∆°ng ph√°p ƒëi·ªÅn cho c·ªôt {col}:", 
                                          options=["Median", "Mean", "Lo·∫°i b·ªè"], 
                                          key=f"fill_{col}")
                    if df[col].dtype in ['float64', 'int64']:
                        if method == "Trung v·ªã (median)":
                            df[col].fillna(df[col].median(), inplace=True)
                        elif method == "Trung b√¨nh (mean)":
                            df[col].fillna(df[col].mean(), inplace=True)
                        elif method == "Lo·∫°i b·ªè":
                            df.dropna(subset=[col], inplace=True)
                    else:
                        if method == "Mode":
                            df[col].fillna(df[col].mode()[0], inplace=True)
                        elif method == "Lo·∫°i b·ªè":
                            df.dropna(subset=[col], inplace=True)

            # M√£ h√≥a bi·∫øn ph√¢n lo·∫°i
            st.write("M√£ h√≥a c√°c bi·∫øn ph√¢n lo·∫°i:")
            categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
            cols_to_encode = st.multiselect("Ch·ªçn c·ªôt ƒë·ªÉ m√£ h√≥a:", categorical_cols)
            for col in cols_to_encode:
                df[col] = df[col].astype('category').cat.codes
                st.write(f"ƒê√£ m√£ h√≥a c·ªôt {col}.")

            # Chu·∫©n h√≥a d·ªØ li·ªáu s·ªë
            st.write("Chu·∫©n h√≥a d·ªØ li·ªáu s·ªë:")
            numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns.tolist()
            if "Survived" in numeric_cols:
                numeric_cols.remove("Survived")  # Kh√¥ng chu·∫©n h√≥a c·ªôt nh√£n

            if numeric_cols:  # Ki·ªÉm tra n·∫øu c√≥ c·ªôt s·ªë ƒë·ªÉ chu·∫©n h√≥a
                norm_method = st.selectbox("Ch·ªçn ph∆∞∆°ng ph√°p chu·∫©n h√≥a:", ["Min-Max Scaling", "Standard Scaling"], key="norm_method")
                if norm_method == "Min-Max Scaling":
                    scaler = MinMaxScaler()
                else:
                    scaler = StandardScaler()

                df[numeric_cols] = scaler.fit_transform(df[numeric_cols])
                st.write(f"ƒê√£ chu·∫©n h√≥a c√°c c·ªôt s·ªë: {', '.join(numeric_cols)}")

            # C·∫≠p nh·∫≠t l·∫°i d·ªØ li·ªáu
            st.session_state.df = df
            st.session_state.data_processed = True

            # Hi·ªÉn th·ªã k·∫øt qu·∫£ sau x·ª≠ l√Ω
            st.success("D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω!")
            st.write(df.head(10))
        else:
            st.warning("Vui l√≤ng t·∫£i d·ªØ li·ªáu tr∆∞·ªõc.")


## -----------------------------------  LOGIN ACCOUNT MLFLOW  ------------------------------


def mlflow_input():
    """Thi·∫øt l·∫≠p k·∫øt n·ªëi v·ªõi MLflow tr√™n DagsHub."""
    DAGSHUB_USERNAME = "Snxtruc"
    DAGSHUB_REPO_NAME = "HocMayPython"
    DAGSHUB_TOKEN = "ca4b78ae4dd9d511c1e0c333e3b709b2cd789a19"  # Thay b·∫±ng token th·∫≠t

    # ƒê·∫∑t URI c·ªßa MLflow tr·ªè ƒë·∫øn DagsHub
    mlflow.set_tracking_uri(f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO_NAME}.mlflow")

    # Thi·∫øt l·∫≠p authentication b·∫±ng c√°ch ƒë·∫∑t bi·∫øn m√¥i tr∆∞·ªùng
    import os
    os.environ["MLFLOW_TRACKING_USERNAME"] = DAGSHUB_USERNAME
    os.environ["MLFLOW_TRACKING_PASSWORD"] = DAGSHUB_TOKEN

    # ƒê·∫∑t th√≠ nghi·ªám
    mlflow.set_experiment("Linear Regressions")

    # L∆∞u link MLflow v√†o session_state ƒë·ªÉ d√πng sau
    st.session_state['mlflow_url'] = f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO_NAME}.mlflow"


## ----------------------------------- SPLIT SIZE DATASET ------------------------------
def chia_du_lieu(): 
    st.markdown("## üìå Chia d·ªØ li·ªáu Train/Validation/Test")
    st.write("""
    ### üìå Chia t·∫≠p d·ªØ li·ªáu
    D·ªØ li·ªáu ƒë∆∞·ª£c chia th√†nh ba ph·∫ßn ƒë·ªÉ ƒë·∫£m b·∫£o m√¥ h√¨nh t·ªïng qu√°t t·ªët:
    - **70%**: ƒë·ªÉ train m√¥ h√¨nh.
    - **15%**: ƒë·ªÉ validation, d√πng ƒë·ªÉ ƒëi·ªÅu ch·ªânh tham s·ªë.
    - **15%**: ƒë·ªÉ test, ƒë√°nh gi√° hi·ªáu su·∫•t th·ª±c t·∫ø.
    """)

    if "df" not in st.session_state:
        st.error("‚ùå D·ªØ li·ªáu ch∆∞a ƒë∆∞·ª£c t·∫£i l√™n!")
        st.stop()
        
    df = st.session_state.df  # L·∫•y d·ªØ li·ªáu t·ª´ session_state

    st.subheader("üìä Chia d·ªØ li·ªáu Train - Validation - Test")  
    test_size = st.slider("üìå Ch·ªçn % d·ªØ li·ªáu Test", 10, 50, 20)
    val_size = st.slider("üìå Ch·ªçn % d·ªØ li·ªáu Validation", 0, 50, 15)

    remaining_size = 100 - test_size
    st.write(f"üìå **T·ª∑ l·ªá ph√¢n chia:** Test={test_size}%, Validation={val_size}%, Train={remaining_size - val_size}%")

    if st.button("‚úÖ X√°c nh·∫≠n Chia"):
        progress_bar = st.progress(0)
        progress_text = st.empty()  # Placeholder ƒë·ªÉ hi·ªÉn th·ªã % ti·∫øn tr√¨nh
        
        st.write(f"‚è≥ ƒêang chia d·ªØ li·ªáu...")  

        # B∆∞·ªõc 1: Chia t·∫≠p Test
        progress_bar.progress(30)
        progress_text.text("üîÑ Ti·∫øn tr√¨nh: 30% - ƒêang chia t·∫≠p Test...")
        time.sleep(0.5)
        train_full, test = train_test_split(df, test_size=test_size/100, random_state=42)
        
        # B∆∞·ªõc 2: Chia t·∫≠p Train v√† Validation
        progress_bar.progress(70)
        progress_text.text("üîÑ Ti·∫øn tr√¨nh: 70% - ƒêang chia t·∫≠p Train v√† Validation...")
        time.sleep(0.5)
        train, val = train_test_split(train_full, test_size=val_size / (100 - test_size), random_state=42)

        # L∆∞u v√†o session_state
        st.session_state.train = train
        st.session_state.test = test
        st.session_state.val = val

        # Hi·ªÉn th·ªã th√¥ng tin s·ªë l∆∞·ª£ng m·∫´u
        summary_df = pd.DataFrame({
            "T·∫≠p d·ªØ li·ªáu": ["Train", "Validation", "Test"],
            "S·ªë l∆∞·ª£ng m·∫´u": [train.shape[0], val.shape[0], test.shape[0]]
        })
        st.table(summary_df)

        # Ho√†n th√†nh
        progress_bar.progress(100)
        progress_text.text("‚úÖ Ti·∫øn tr√¨nh: 100% - Ho√†n th√†nh chia d·ªØ li·ªáu!")
        st.success("‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia th√†nh c√¥ng!")


def train_polynomial_regression(X_train, y_train, degree=2, learning_rate=0.001, n_iterations=500):
    """Hu·∫•n luy·ªán h·ªìi quy ƒëa th·ª©c **kh√¥ng c√≥ t∆∞∆°ng t√°c** b·∫±ng Gradient Descent."""

    # Chuy·ªÉn d·ªØ li·ªáu sang NumPy array n·∫øu l√† pandas DataFrame/Series
    X_train = X_train.to_numpy() if isinstance(X_train, pd.DataFrame) else X_train
    y_train = y_train.to_numpy().reshape(-1, 1) if isinstance(y_train, (pd.Series, pd.DataFrame)) else y_train.reshape(-1, 1)

        # T·∫°o ƒë·∫∑c tr∆∞ng ƒëa th·ª©c **ch·ªâ th√™m b·∫≠c cao, kh√¥ng c√≥ t∆∞∆°ng t√°c**
    X_poly = np.hstack([X_train] + [X_train**d for d in range(2, degree + 1)])
    st.write(f"K√≠ch th∆∞·ªõc ma tr·∫≠n X_poly: {X_poly[1]}")
        
        # Chu·∫©n h√≥a d·ªØ li·ªáu ƒë·ªÉ tr√°nh tr√†n s·ªë
    scaler = StandardScaler()
    X_poly = scaler.fit_transform(X_poly)

        # L·∫•y s·ªë l∆∞·ª£ng m·∫´u (m) v√† s·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng (n)
    m, n = X_poly.shape
    print(f"S·ªë l∆∞·ª£ng m·∫´u (m): {m}, S·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng (n): {n}")

        # Th√™m c·ªôt bias (x0 = 1)
    X_b = np.c_[np.ones((m, 1)), X_poly]
    print(f"K√≠ch th∆∞·ªõc ma tr·∫≠n X_b: {X_b.shape}")

        # Kh·ªüi t·∫°o tr·ªçng s·ªë ng·∫´u nhi√™n nh·ªè
    w = np.random.randn(X_b.shape[1], 1) * 0.01  
    print(f"Tr·ªçng s·ªë ban ƒë·∫ßu: {w.flatten()}")

        # Gradient Descent
    for iteration in range(n_iterations):
        gradients = (2/m) * X_b.T.dot(X_b.dot(w) - y_train)

            # Ki·ªÉm tra n·∫øu gradient c√≥ gi√° tr·ªã NaN
        if np.isnan(gradients).any():
            raise ValueError("Gradient ch·ª©a gi√° tr·ªã NaN! H√£y ki·ªÉm tra l·∫°i d·ªØ li·ªáu ho·∫∑c learning rate.")

        w -= learning_rate * gradients

        print("‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t!")
        print(f"Tr·ªçng s·ªë cu·ªëi c√πng: {w.flatten()}")
        
    return w

def train_multiple_linear_regression(X_train, y_train, learning_rate=0.001, n_iterations=200):
        """Hu·∫•n luy·ªán h·ªìi quy tuy·∫øn t√≠nh b·ªôi b·∫±ng Gradient Descent."""
        
        # Chuy·ªÉn ƒë·ªïi X_train, y_train sang NumPy array ƒë·ªÉ tr√°nh l·ªói
        X_train = X_train.to_numpy() if isinstance(X_train, pd.DataFrame) else X_train
        y_train = y_train.to_numpy().reshape(-1, 1) if isinstance(y_train, (pd.Series, pd.DataFrame)) else y_train.reshape(-1, 1)

        # Ki·ªÉm tra NaN ho·∫∑c Inf
        if np.isnan(X_train).any() or np.isnan(y_train).any():
            raise ValueError("D·ªØ li·ªáu ƒë·∫ßu v√†o ch·ª©a gi√° tr·ªã NaN!")
        if np.isinf(X_train).any() or np.isinf(y_train).any():
            raise ValueError("D·ªØ li·ªáu ƒë·∫ßu v√†o ch·ª©a gi√° tr·ªã v√¥ c√πng (Inf)!")

        # Chu·∫©n h√≥a d·ªØ li·ªáu ƒë·ªÉ tr√°nh tr√†n s·ªë
        scaler = StandardScaler()
        X_train = scaler.fit_transform(X_train)

        # L·∫•y s·ªë l∆∞·ª£ng m·∫´u (m) v√† s·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng (n)
        m, n = X_train.shape
        #st.write(f"S·ªë l∆∞·ª£ng m·∫´u (m): {m}, S·ªë l∆∞·ª£ng ƒë·∫∑c tr∆∞ng (n): {n}")

        # Th√™m c·ªôt bias (x0 = 1) v√†o X_train
        X_b = np.c_[np.ones((m, 1)), X_train]
        #st.write(f"K√≠ch th∆∞·ªõc ma tr·∫≠n X_b: {X_b.shape}")

        # Kh·ªüi t·∫°o tr·ªçng s·ªë ng·∫´u nhi√™n nh·ªè
        w = np.random.randn(X_b.shape[1], 1) * 0.01  
        #st.write(f"Tr·ªçng s·ªë ban ƒë·∫ßu: {w.flatten()}")

        # Gradient Descent
        for iteration in range(n_iterations):
            gradients = (2/m) * X_b.T.dot(X_b.dot(w) - y_train)

            # Ki·ªÉm tra xem gradients c√≥ NaN kh√¥ng
            # st.write(gradients)
            if np.isnan(gradients).any():
                raise ValueError("Gradient ch·ª©a gi√° tr·ªã NaN! H√£y ki·ªÉm tra l·∫°i d·ªØ li·ªáu ho·∫∑c learning rate.")

            w -= learning_rate * gradients

        return w

def train_and_log_model():
    """Giao di·ªán Streamlit ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh h·ªìi quy v√† log k·∫øt qu·∫£ l√™n MLflow."""
    
    st.title("üìà Hu·∫•n luy·ªán m√¥ h√¨nh H·ªìi quy")

    # Thi·∫øt l·∫≠p k·∫øt n·ªëi v·ªõi MLflow
    mlflow_input()

    # Ch·ªçn lo·∫°i m√¥ h√¨nh
    model_type = st.selectbox("üîç Ch·ªçn m√¥ h√¨nh:", ["H·ªìi quy tuy·∫øn t√≠nh b·ªôi", "H·ªìi quy ƒëa th·ª©c"])
    
    # N·∫øu ch·ªçn h·ªìi quy ƒëa th·ª©c, cho ph√©p ch·ªçn b·∫≠c c·ªßa ƒëa th·ª©c
    degree = 2
    if model_type == "H·ªìi quy ƒëa th·ª©c":
        degree = st.slider("üéö Ch·ªçn b·∫≠c c·ªßa ƒëa th·ª©c:", min_value=2, max_value=5, value=2)
    
    # Ch·ªçn hyperparameters
    learning_rate = st.number_input("‚ö° Learning rate:", min_value=0.0001, max_value=0.1, value=0.001, step=0.0001, format="%.4f")
    n_iterations = st.number_input("üîÑ S·ªë l·∫ßn l·∫∑p:", min_value=100, max_value=1000, value=200, step=50)
    n_splits = st.number_input("üìä S·ªë folds cho KFold Cross-Validation:", min_value=2, max_value=10, value=5, step=1)
    
    # N√∫t ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh
    if st.button("üöÄ Hu·∫•n luy·ªán m√¥ h√¨nh"):
        progress_bar = st.progress(0)
        progress_text = st.empty()

        st.write("üîÑ ƒêang hu·∫•n luy·ªán m√¥ h√¨nh...")

        # T·∫°o d·ªØ li·ªáu gi·∫£ l·∫≠p ƒë·ªÉ hu·∫•n luy·ªán
        X, y = make_regression(n_samples=100, n_features=2, noise=0.1)

        kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)
        mse_scores, rmse_scores, r2_scores = [], [], []
        
        with mlflow.start_run() as run:
            for fold_idx, (train_index, test_index) in enumerate(kf.split(X)):
                X_train, X_test = X[train_index], X[test_index]
                y_train, y_test = y[train_index], y[test_index]
                
                # Chu·∫©n h√≥a d·ªØ li·ªáu
                scaler = StandardScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_test_scaled = scaler.transform(X_test)

                # Ch·ªçn m√¥ h√¨nh
                if model_type == "H·ªìi quy ƒëa th·ª©c":
                    model = train_polynomial_regression(X_train_scaled, y_train, degree, learning_rate, n_iterations)
                else:
                    model = train_multiple_linear_regression(X_train_scaled, y_train, learning_rate, n_iterations)

                # Th√™m bias v√†o X_test
                if model_type == "H·ªìi quy ƒëa th·ª©c":
                    X_test_poly = np.hstack([X_test_scaled] + [X_test_scaled**d for d in range(2, degree + 1)])
                    X_b_test = np.c_[np.ones((X_test.shape[0], 1)), X_test_poly]
                else:
                    X_b_test = np.c_[np.ones((X_test.shape[0], 1)), X_test_scaled]

                # D·ª± ƒëo√°n gi√° tr·ªã
                y_pred = X_b_test.dot(model)

                # T√≠nh metrics
                mse = mean_squared_error(y_test, y_pred)
                rmse = sqrt(mse)
                r2 = r2_score(y_test, y_pred)
                
                mse_scores.append(mse)
                rmse_scores.append(rmse)
                r2_scores.append(r2)

                # C·∫≠p nh·∫≠t ti·∫øn tr√¨nh
                progress = int(((fold_idx + 1) / n_splits) * 100)
                progress_bar.progress(progress)
                progress_text.text(f"üîÑ Ti·∫øn tr√¨nh: {progress}% - Hu·∫•n luy·ªán Fold {fold_idx + 1}/{n_splits}")

                time.sleep(0.5)  # Gi·∫£ l·∫≠p th·ªùi gian ch·ªù hu·∫•n luy·ªán

            # Log gi√° tr·ªã trung b√¨nh c·ªßa c√°c metrics l√™n MLflow
            mlflow.log_metrics({
                "MSE": np.mean(mse_scores),
                "RMSE": np.mean(rmse_scores),
                "R2_score": np.mean(r2_scores)
            })

            # L∆∞u m√¥ h√¨nh
            model_dir = "saved_models"
            os.makedirs(model_dir, exist_ok=True)
            model_filename = f"{model_dir}/{model_type.replace(' ', '_').lower()}_model.pkl"
            joblib.dump(model, model_filename)

            # Log m√¥ h√¨nh l√™n MLflow
            mlflow.log_artifact(model_filename)

            # L·∫•y link MLflow
            run_id = run.info.run_id
            mlflow_run_url = f"{st.session_state['mlflow_url']}/#/experiments/0/runs/{run_id}"
            
            # ‚úÖ Hi·ªÉn th·ªã k·∫øt qu·∫£ tr√™n Streamlit
            st.subheader("üìä K·∫øt qu·∫£ hu·∫•n luy·ªán m√¥ h√¨nh")
            st.write(f"‚úÖ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: `{model_filename}`")
            st.markdown(f"üîó **T·∫£i m√¥ h√¨nh:** [Download {model_filename}](./{model_filename})")
            st.markdown(f"üîó **MLflow Tracking:** [Xem k·∫øt qu·∫£ tr√™n MLflow]({mlflow_run_url})")
            
            progress_bar.progress(100)
            progress_text.text("‚úÖ Ti·∫øn tr√¨nh: 100% - Ho√†n th√†nh hu·∫•n luy·ªán!")
            st.success("‚úÖ Hu·∫•n luy·ªán v√† logging ho√†n t·∫•t!")


##------------------------------------ TRACKING MLFLOW -------------------------------
def format_time_relative(timestamp_ms):
    """Chuy·ªÉn timestamp milliseconds th√†nh th·ªùi gian d·ªÖ ƒë·ªçc."""
    if timestamp_ms is None:
        return "N/A"
    dt = datetime.datetime.fromtimestamp(timestamp_ms / 1000)
    return dt.strftime("%Y-%m-%d %H:%M:%S")

def display_mlflow_experiments():
    """Hi·ªÉn th·ªã danh s√°ch Runs trong MLflow v·ªõi thanh tr·∫°ng th√°i ti·∫øn tr√¨nh."""
    st.title("üìä MLflow Experiment Viewer")

    # L·∫•y danh s√°ch th√≠ nghi·ªám
    experiment_name = "Linear Regressions"
    experiments = mlflow.search_experiments()
    selected_experiment = next((exp for exp in experiments if exp.name == experiment_name), None)

    if not selected_experiment:
        st.error(f"‚ùå Experiment '{experiment_name}' kh√¥ng t·ªìn t·∫°i!")
        return

    st.subheader(f"üìå Experiment: {experiment_name}")
    st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
    st.write(f"**Tr·∫°ng th√°i:** {'Active' if selected_experiment.lifecycle_stage == 'active' else 'Deleted'}")
    st.write(f"**V·ªã tr√≠ l∆∞u tr·ªØ:** {selected_experiment.artifact_location}")

    # --- üèÉ‚Äç‚ôÇÔ∏è L·∫•y danh s√°ch Runs v·ªõi thanh tr·∫°ng th√°i ---
    st.write("### üîÑ ƒêang t·∫£i danh s√°ch Runs...")
    runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])

    if runs.empty:
        st.warning("‚ö† Kh√¥ng c√≥ runs n√†o trong experiment n√†y.")
        return

    total_runs = len(runs)
    run_info = []
    
    progress_bar = st.progress(0)  # Thanh ti·∫øn tr√¨nh

    for i, (_, run) in enumerate(runs.iterrows()):
        run_id = run["run_id"]
        run_data = mlflow.get_run(run_id)
        run_tags = run_data.data.tags
        run_name = run_tags.get("mlflow.runName", f"Run {run_id[:8]}")  # T√™n Run
        created_time = format_time_relative(run_data.info.start_time)
        duration = (run_data.info.end_time - run_data.info.start_time) / 1000 if run_data.info.end_time else "ƒêang ch·∫°y"
        source = run_tags.get("mlflow.source.name", "Unknown")

        run_info.append({
            "Run Name": run_name,
            "Run ID": run_id,
            "Created": created_time,
            "Duration (s)": duration if isinstance(duration, str) else f"{duration:.1f}s",
            "Source": source
        })

        # C·∫≠p nh·∫≠t thanh ti·∫øn tr√¨nh
        progress_bar.progress(int((i + 1) / total_runs * 100))

    progress_bar.empty()  # X√≥a thanh ti·∫øn tr√¨nh khi ho√†n th√†nh

    # S·∫Øp x·∫øp v√† hi·ªÉn th·ªã b·∫£ng danh s√°ch Runs
    run_info_df = pd.DataFrame(run_info).sort_values(by="Created", ascending=False)
    st.write("### üèÉ‚Äç‚ôÇÔ∏è Danh s√°ch Runs:")
    st.dataframe(run_info_df, use_container_width=True)

    # Ch·ªçn Run t·ª´ dropdown
    run_names = run_info_df["Run Name"].tolist()
    selected_run_name = st.selectbox("üîç Ch·ªçn m·ªôt Run ƒë·ªÉ xem chi ti·∫øt:", run_names)

    # L·∫•y Run ID t∆∞∆°ng ·ª©ng
    selected_run_id = run_info_df.loc[run_info_df["Run Name"] == selected_run_name, "Run ID"].values[0]
    selected_run = mlflow.get_run(selected_run_id)

    # --- üìù ƒê·ªîI T√äN RUN ---
    st.write("### ‚úèÔ∏è ƒê·ªïi t√™n Run")
    new_run_name = st.text_input("Nh·∫≠p t√™n m·ªõi:", selected_run_name)
    if st.button("üíæ L∆∞u t√™n m·ªõi"):
        try:
            mlflow.set_tag(selected_run_id, "mlflow.runName", new_run_name)
            st.success(f"‚úÖ ƒê√£ ƒë·ªïi t√™n th√†nh **{new_run_name}**. H√£y t·∫£i l·∫°i trang ƒë·ªÉ th·∫•y thay ƒë·ªïi!")
        except Exception as e:
            st.error(f"‚ùå L·ªói khi ƒë·ªïi t√™n: {e}")

    # --- üóëÔ∏è X√ìA RUN ---
    st.write("### ‚ùå X√≥a Run")
    if st.button("üóëÔ∏è X√≥a Run n√†y"):
        try:
            mlflow.delete_run(selected_run_id)
            st.success(f"‚úÖ ƒê√£ x√≥a run **{selected_run_name}**! H√£y t·∫£i l·∫°i trang ƒë·ªÉ c·∫≠p nh·∫≠t danh s√°ch.")
        except Exception as e:
            st.error(f"‚ùå L·ªói khi x√≥a run: {e}")

    # --- HI·ªÇN TH·ªä CHI TI·∫æT RUN ---
    if selected_run:
        st.subheader(f"üìå Th√¥ng tin Run: {selected_run_name}")
        st.write(f"**Run ID:** {selected_run_id}")
        st.write(f"**Tr·∫°ng th√°i:** {selected_run.info.status}")

        start_time_ms = selected_run.info.start_time
        start_time = datetime.datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S") if start_time_ms else "Kh√¥ng c√≥ th√¥ng tin"
        st.write(f"**Th·ªùi gian ch·∫°y:** {start_time}")

        # Hi·ªÉn th·ªã th√¥ng s·ªë ƒë√£ log
        params = selected_run.data.params
        metrics = selected_run.data.metrics

        if params:
            st.write("### ‚öôÔ∏è Parameters:")
            st.json(params)

        if metrics:
            st.write("### üìä Metrics:")
            st.json(metrics)

        # Hi·ªÉn th·ªã model artifact (n·∫øu c√≥)
        model_artifact_path = f"{st.session_state['mlflow_url']}/{selected_experiment.experiment_id}/{selected_run_id}/artifacts/model"
        st.write("### üìÇ Model Artifact:")
        st.write(f"üì• [T·∫£i m√¥ h√¨nh]({model_artifact_path})")
    else:
        st.warning("‚ö† Kh√¥ng t√¨m th·∫•y th√¥ng tin cho run n√†y.")

def predict_survival():
    df = pd.read_csv("data1.csv")
    features = ["Pclass", "Sex", "Age", "SibSp", "Parch", "Fare", "Embarked"]
    df = df[features + ["Survived"]]

    # X·ª≠ l√Ω d·ªØ li·ªáu thi·∫øu
    imputer = SimpleImputer(strategy="median")
    df["Age"] = imputer.fit_transform(df[["Age"]])
    df["Embarked"].fillna(df["Embarked"].mode()[0], inplace=True)

    # Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu d·∫°ng ch·ªØ th√†nh s·ªë
    label_encoders = {}
    for col in ["Sex", "Embarked"]:
        le = LabelEncoder()
        df[col] = le.fit_transform(df[col])
        label_encoders[col] = le

    # Hu·∫•n luy·ªán m√¥ h√¨nh Polynomial Regression b·∫≠c 2
    X = df[features]
    y = df["Survived"]
    poly = PolynomialFeatures(degree=2)
    X_poly = poly.fit_transform(X)
    model = LinearRegression()
    model.fit(X_poly, y)

    # Giao di·ªán Streamlit
    st.title("D·ª± ƒëo√°n kh·∫£ nƒÉng s·ªëng s√≥t tr√™n Titanic")

    pclass = st.selectbox("H·∫°ng v√© (Pclass)", [1, 2, 3])
    sex = st.selectbox("Gi·ªõi t√≠nh", ["male", "female"])
    age = st.number_input("Tu·ªïi", min_value=0, max_value=100, value=30)
    sibsp = st.number_input("S·ªë anh ch·ªã em / v·ª£ ch·ªìng ƒëi c√πng (SibSp)", min_value=0, max_value=10, value=0)
    parch = st.number_input("S·ªë cha m·∫π / con c√°i ƒëi c√πng (Parch)", min_value=0, max_value=10, value=0)
    fare = st.number_input("Gi√° v√© (Fare)", min_value=0.0, max_value=600.0, value=30.0)
    embarked = st.selectbox("C·∫£ng ƒëi (Embarked)", ["C", "Q", "S"])

    if st.button("D·ª± ƒëo√°n"):
        input_data = pd.DataFrame([[pclass, sex, age, sibsp, parch, fare, embarked]], columns=features)
        input_data["Sex"] = label_encoders["Sex"].transform([sex])[0]
        input_data["Embarked"] = label_encoders["Embarked"].transform([embarked])[0]
        
        input_data_poly = poly.transform(input_data)
        prediction = model.predict(input_data_poly)[0]
        survival = "S·ªëng s√≥t" if prediction >= 0.5 else "Kh√¥ng s·ªëng s√≥t"
        
        st.success(f"D·ª± ƒëo√°n: {survival}")
        if prediction >= 0.5:
            st.write("Quy·∫øt ƒë·ªãnh cu·ªëi c√πng: H√†nh kh√°ch n√†y c√≥ kh·∫£ nƒÉng s·ªëng s√≥t.")
        else:
            st.write("Quy·∫øt ƒë·ªãnh cu·ªëi c√πng: H√†nh kh√°ch n√†y kh√¥ng c√≥ kh·∫£ nƒÉng s·ªëng s√≥t.")
        
        # Ki·ªÉm tra xem h√†nh kh√°ch n√†y c√≥ trong t·∫≠p d·ªØ li·ªáu g·ªëc kh√¥ng
        matched = df[
            (df["Pclass"] == pclass) &
            (df["Sex"] == label_encoders["Sex"].transform([sex])[0]) &
            (df["Age"] == age) &
            (df["SibSp"] == sibsp) &
            (df["Parch"] == parch) &
            (df["Fare"] == fare) &
            (df["Embarked"] == label_encoders["Embarked"].transform([embarked])[0])
        ]
        
        if not matched.empty:
            actual_survival = "S·ªëng s√≥t" if matched["Survived"].values[0] == 1 else "Kh√¥ng s·ªëng s√≥t"
            st.info(f"Th√¥ng tin tr√πng kh·ªõp trong t·∫≠p d·ªØ li·ªáu! Th·ª±c t·∫ø: {actual_survival}")
        else:
            st.info("H√†nh kh√°ch n√†y kh√¥ng c√≥ trong t·∫≠p d·ªØ li·ªáu g·ªëc.")



def mt_Regression():
  
    # Thi·∫øt l·∫≠p CSS ƒë·ªÉ h·ªó tr·ª£ hi·ªÉn th·ªã tabs v·ªõi hi·ªáu ·ª©ng hover v√† thanh cu·ªôn
    st.markdown(
        """
        <style>
        .stTabs [role="tablist"] {
            overflow-x: auto;
            white-space: nowrap;
            display: flex;
            scrollbar-width: thin;
            scrollbar-color: #888 #f0f0f0;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar {
            height: 6px;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar-thumb {
            background-color: #888;
            border-radius: 3px;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar-track {
            background: #f0f0f0;
        }
        .stTabs [role="tab"]:hover {
            background-color: #f0f0f0;
            transition: background-color 0.3s ease-in-out;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

    st.title("üñäÔ∏è Multiple & Polynomial Regression App")

    # Ensure the tab names are properly separated
    tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "üìò L√Ω thuy·∫øt MLR & Polynomial Regression", 
    "üì• T·∫£i & ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu",  
    "üîÄ Chia d·ªØ li·ªáu", 
    "ü§ñ Hu·∫•n luy·ªán m√¥ h√¨nh", 
    "üîç Th√¥ng tin hu·∫•n luy·ªán",
    "üß† D·ª± ƒëo√°n"
    ])

    with tab1: 
        ly_thuyet_mlinear() 
    with tab2: 
        up_load_db() 
    with tab3: 
        chia_du_lieu() 
    with tab4:
        train_and_log_model() 
    with tab5:
        display_mlflow_experiments() 
    with tab6: 
        predict_survival()

def run():
    mt_Regression()

if __name__ == "__main__": 
    run()

