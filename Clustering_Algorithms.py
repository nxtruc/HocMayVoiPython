import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image
import openml
import os
import mlflow
import time
import shutil
import humanize
from datetime import datetime
from scipy.stats import mode
from scipy import stats
from mlflow.tracking import MlflowClient
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score
from sklearn.datasets import make_blobs
from sklearn.metrics import silhouette_score
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
# Táº£i dá»¯ liá»‡u MNIST tá»« OpenML


import streamlit as st

def ly_thuyet_kmeans():
    st.header("ğŸ“– LÃ½ thuyáº¿t vá» K-Means")
    st.markdown(" ### 1ï¸âƒ£ K-Means lÃ  gÃ¬?")
    st.write("K-means lÃ  má»™t thuáº­t toÃ¡n **há»c khÃ´ng giÃ¡m sÃ¡t** dÃ¹ng Ä‘á»ƒ phÃ¢n cá»¥m dá»¯ liá»‡u thÃ nh k cá»¥m dá»±a trÃªn khoáº£ng cÃ¡ch Euclid.")
    st.markdown(" ##### ğŸ¯ Má»¥c tiÃªu cá»§a thuáº­t toÃ¡n K-Means")

    st.write("""
    Thuáº­t toÃ¡n **K-Means** cÃ³ má»¥c tiÃªu chÃ­nh lÃ  **tÃ¬m cÃ¡c cá»¥m tá»‘i Æ°u** trong táº­p dá»¯ liá»‡u báº±ng cÃ¡ch **tá»‘i thiá»ƒu hÃ³a tá»•ng bÃ¬nh phÆ°Æ¡ng khoáº£ng cÃ¡ch** tá»« cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u Ä‘áº¿n tÃ¢m cá»¥m cá»§a chÃºng.
    """)

    st.markdown(" ##### HÃ m má»¥c tiÃªu (Objective Function)")
    st.write("K-Means cá»‘ gáº¯ng tá»‘i thiá»ƒu hÃ³a tá»•ng phÆ°Æ¡ng sai trong cá»¥m, Ä‘Æ°á»£c biá»ƒu diá»…n báº±ng cÃ´ng thá»©c:")

    st.latex(r"""
    J = \sum_{k=1}^{K} \sum_{x_i \in C_k} || x_i - \mu_k ||^2
    """)

    st.write("""
    Trong Ä‘Ã³:
    - \\( K \\): Sá»‘ lÆ°á»£ng cá»¥m.
    - \\( C_k \\): Táº­p há»£p cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u thuá»™c cá»¥m thá»© \\( k \\).
    - \\( x_i \\): Äiá»ƒm dá»¯ liá»‡u trong cá»¥m \\( C_k \\).
    - \\( \mu_k \\): TÃ¢m cá»¥m cá»§a \\( C_k \\).
    - \\( || x_i - \mu_k ||^2 \\): Khoáº£ng cÃ¡ch Euclidean bÃ¬nh phÆ°Æ¡ng giá»¯a Ä‘iá»ƒm \\( x_i \\) vÃ  tÃ¢m cá»¥m \\( \mu_k \\).
    """)

    st.markdown(" ### 2ï¸âƒ£ Ã½ tÆ°á»Ÿng") 
    st.markdown(
    """
    - Chia táº­p dá»¯ liá»‡u thÃ nh ğ¾K cá»¥m (clusters), vá»›i má»—i cá»¥m cÃ³ má»™t tÃ¢m cá»¥m (centroid).
    - Dá»¯ liá»‡u Ä‘Æ°á»£c gÃ¡n vÃ o cá»¥m cÃ³ tÃ¢m cá»¥m gáº§n nÃ³ nháº¥t.
    - Cáº­p nháº­t tÃ¢m cá»¥m báº±ng cÃ¡ch tÃ­nh trung bÃ¬nh cÃ¡c Ä‘iá»ƒm thuá»™c cá»¥m.
    - Láº·p láº¡i cho Ä‘áº¿n khi khÃ´ng cÃ³ sá»± thay Ä‘á»•i Ä‘Ã¡ng ká»ƒ trong cá»¥m.
    """    
    )
    image_url = "https://miro.medium.com/v2/resize:fit:720/format:webp/1*fz-rjYPPRlGEMdTI-RLbDg.png" 
    article_url = "https://meghachhabria10.medium.com/k-means-clustering-algorithm-its-use-cases-13dfc0020b23"
    st.markdown(
        f"""
        <div style="text-align: center;">
            <a href="{article_url}" target="_blank">
                <img src="{image_url}" width="500">
            </a>
            <p style="font-size: 14px; color: gray;"></p>
        </div>
        """,
        unsafe_allow_html=True
    ) 
    st.markdown(" ### 3ï¸âƒ£ Thuáº­t toÃ¡n K-Means") 
    st.markdown(
    """
    - 1.Chá»n sá»‘ cá»¥m ğ¾ (Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh trÆ°á»›c).
    - 2.Khá»Ÿi táº¡o ğ¾ tÃ¢m cá»¥m (chá»n ngáº«u nhiÃªn hoáº·c theo K-Means++ Ä‘á»ƒ tá»‘t hÆ¡n).
    - 3.GÃ¡n dá»¯ liá»‡u vÃ o cá»¥m: Má»—i Ä‘iá»ƒm dá»¯ liá»‡u Ä‘Æ°á»£c gÃ¡n vÃ o cá»¥m cÃ³ tÃ¢m cá»¥m gáº§n nháº¥t
    """
    )
    st.latex(r"""d(p, q) = \sqrt{\sum_{i=1}^{n} (p_i - q_i)^2}""")
    st.markdown(
    """
    - 4.Cáº­p nháº­t tÃ¢m cá»¥m: TÃ­nh láº¡i tÃ¢m cá»¥m báº±ng cÃ¡ch láº¥y trung bÃ¬nh cÃ¡c Ä‘iá»ƒm trong má»—i cá»¥m.
    """
    )
    st.latex(r"""\mu_k = \frac{1}{N_k} \sum_{i=1}^{N_k} x_i""")
    st.markdown(
    """
    - 5.Láº·p láº¡i cÃ¡c bÆ°á»›c 3 & 4 cho Ä‘áº¿n khi cÃ¡c tÃ¢m cá»¥m khÃ´ng thay Ä‘á»•i nhiá»u ná»¯a hoáº·c Ä‘áº¡t Ä‘áº¿n sá»‘ láº§n láº·p tá»‘i Ä‘a.
    """
    )
    image_url = "https://machinelearningcoban.com/assets/kmeans/kmeans11.gif"
    article_url = "https://machinelearningcoban.com/2017/01/01/kmeans/"
    st.markdown(
        f"""
        <div style="text-align: center;">
            <a href="{article_url}" target="_blank">
                <img src="{image_url}" width="500">
            </a>
            <p style="font-size: 14px; color: gray;">Minh há»a thuáº­t toÃ¡n K-Means</p>
        </div>
        """,
        unsafe_allow_html=True
    ) 
    st.markdown(" ###  4ï¸âƒ£ ÄÃ¡nh giÃ¡ thuáº­t toÃ¡n K-Means")
    st.markdown(" ##### ğŸ“Œ Elbow Method")
    st.write("""
    - TÃ­nh tá»•ng khoáº£ng cÃ¡ch ná»™i cá»¥m WCSS (Within-Cluster Sum of Squares) cho cÃ¡c giÃ¡ trá»‹ k khÃ¡c nhau.
    - Äiá»ƒm "khuá»·u tay" (elbow point) lÃ  giÃ¡ trá»‹ k tá»‘i Æ°u, táº¡i Ä‘Ã³ viá»‡c tÄƒng thÃªm cá»¥m khÃ´ng lÃ m giáº£m Ä‘Ã¡ng ká»ƒ WCSS.
    """)
    st.latex(r"""
    WCSS = \sum_{i=1}^{k} \sum_{x \in C_i} \|x - \mu_i\|^2
    """)
    image_url = "https://miro.medium.com/v2/resize:fit:720/format:webp/0*aY163H0kOrBO46S-.png"
    article_url = "https://medium.com/@zalarushirajsinh07/the-elbow-method-finding-the-optimal-number-of-clusters-d297f5aeb189"
    st.markdown(
        f"""
        <div style="text-align: center;">
            <a href="{article_url}" target="_blank">
                <img src="{image_url}" width="500">
            </a>
            <p style="font-size: 14px; color: gray;"></p>
        </div>
        """,
        unsafe_allow_html=True
    ) 

    st.markdown(" ##### ğŸ“Œ Silhouette Score")
    st.write("""
    - So sÃ¡nh má»©c Ä‘á»™ gáº§n gÅ©i giá»¯a cÃ¡c Ä‘iá»ƒm trong cá»¥m vá»›i cÃ¡c Ä‘iá»ƒm á»Ÿ cá»¥m khÃ¡c.
    """)
    st.latex(r"""
    s(i) = \frac{b(i) - a(i)}{\max(a(i), b(i))}
    """)
    st.write("""
    - \\( a(i) \\): Khoáº£ng cÃ¡ch trung bÃ¬nh tá»« Ä‘iá»ƒm i Ä‘áº¿n cÃ¡c Ä‘iá»ƒm trong cÃ¹ng cá»¥m.
    - \\( b(i) \\): Khoáº£ng cÃ¡ch trung bÃ¬nh tá»« Ä‘iá»ƒm i Ä‘áº¿n cÃ¡c Ä‘iá»ƒm trong cá»¥m gáº§n nháº¥t.
    """)
    image_url = "https://miro.medium.com/v2/resize:fit:720/format:webp/1*pw0s5xkiyVxD4f2XqrPmuQ.png"
    article_url = "https://medium.com/@ayse_nur_safak/the-silhouette-score-finding-the-optimal-number-of-clusters-using-k-means-clustering-9af3be119848"
    st.markdown(
        f"""
        <div style="text-align: center;">
            <a href="{article_url}" target="_blank">
                <img src="{image_url}" width="400">
            </a>
            <p style="font-size: 14px; color: gray;"></p>
        </div>
        """,
        unsafe_allow_html=True
    ) 
    st.markdown(" ##### ğŸ“Œ Gap Statistic")
    st.write("""
    - So sÃ¡nh hiá»‡u quáº£ phÃ¢n cá»¥m trÃªn dá»¯ liá»‡u thá»±c vá»›i dá»¯ liá»‡u ngáº«u nhiÃªn (khÃ´ng cÃ³ cáº¥u trÃºc).
    """)
    st.latex(r"""
    Gap(k) = \mathbb{E}[\log(W_k^{random})] - \log(W_k^{data})
    """)
    st.write("""
    - \\( W_k^{random} \\): WCSS trÃªn random data.
    - \\( W_k^{data} \\): WCSS trÃªn actual data.
    """)
    image_url = "https://media.geeksforgeeks.org/wp-content/uploads/20241227193645905364/Gap-Statistics-vs-Number-of-Clusters-.png"
    article_url = "https://www.geeksforgeeks.org/gap-statistics-for-optimal-number-of-cluster/"
    st.markdown(
        f"""
        <div style="text-align: center;">
            <a href="{article_url}" target="_blank">
                <img src="{image_url}" width="400">
            </a>
            <p style="font-size: 14px; color: gray;"></p>
        </div>
        """,
        unsafe_allow_html=True
    ) 

def ly_thuyet_dbscans():
   st.header("ğŸ“– LÃ½ thuyáº¿t vá» DBSCAN")
   st.markdown(" ### 1ï¸âƒ£ DBSCAN lÃ  gÃ¬?")
   st.markdown(
   """
   - DBSCAN lÃ  má»™t thuáº­t toÃ¡n phÃ¢n cá»¥m dá»±a trÃªn máº­t Ä‘á»™, Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ tÃ¬m cÃ¡c cá»¥m dá»¯ liá»‡u cÃ³ hÃ¬nh dáº¡ng báº¥t ká»³ vÃ  phÃ¡t hiá»‡n cÃ¡c Ä‘iá»ƒm nhiá»…u (noise).
   - KhÃ´ng yÃªu cáº§u biáº¿t trÆ°á»›c sá»‘ cá»¥m.
   """
   )
   st.markdown(" ##### ğŸ¯ Má»¥c tiÃªu cá»§a thuáº­t toÃ¡n DBSCAN ")
   st.write("1. **PhÃ¡t hiá»‡n cá»¥m cÃ³ hÃ¬nh dáº¡ng báº¥t ká»³:** KhÃ´ng giá»‘ng nhÆ° K-Means (yÃªu cáº§u cá»¥m cÃ³ dáº¡ng hÃ¬nh cáº§u), DBSCAN cÃ³ thá»ƒ tÃ¬m ra cÃ¡c cá»¥m cÃ³ hÃ¬nh dáº¡ng báº¥t ká»³, ká»ƒ cáº£ dáº¡ng phi tuyáº¿n tÃ­nh.")
   st.write("2. **KhÃ´ng cáº§n chá»‰ Ä‘á»‹nh sá»‘ cá»¥m trÆ°á»›c:** KhÃ´ng giá»‘ng K-Means, DBSCAN tá»± Ä‘á»™ng tÃ¬m ra sá»‘ lÆ°á»£ng cá»¥m dá»±a trÃªn máº­t Ä‘á»™ Ä‘iá»ƒm dá»¯ liá»‡u mÃ  khÃ´ng cáº§n tham sá»‘ ğ‘˜")
   st.write("3. **XÃ¡c Ä‘á»‹nh Ä‘iá»ƒm nhiá»…u (outliers):** CÃ¡c Ä‘iá»ƒm khÃ´ng thuá»™c cá»¥m nÃ o Ä‘Æ°á»£c xÃ¡c Ä‘á»‹nh lÃ  nhiá»…u, giÃºp lÃ m sáº¡ch dá»¯ liá»‡u.")
   st.markdown(" ##### ğŸ¯ Giáº£i thÃ­ch thuáº­t toÃ¡n DBSCAN: Epsilon, MinPts vÃ  PhÃ¢n loáº¡i Ä‘iá»ƒm ")
   st.write(" 1. Epsilon (Îµ)  BÃ¡n kÃ­nh Ä‘á»ƒ xÃ¡c Ä‘á»‹nh khu vá»±c lÃ¢n cáº­n cá»§a má»™t Ä‘iá»ƒm.")
   st.write(" 2. MinPts Sá»‘ lÆ°á»£ng Ä‘iá»ƒm tá»‘i thiá»ƒu cáº§n thiáº¿t Ä‘á»ƒ má»™t khu vá»±c Ä‘Æ°á»£c coi lÃ  Ä‘á»§ máº­t Ä‘á»™.")
   st.markdown("###### 3. Loáº¡i Ä‘iá»ƒm trong DBSCAN:")
   st.write("- **Core Point**: Äiá»ƒm cÃ³ Ã­t nháº¥t MinPts Ä‘iá»ƒm khÃ¡c náº±m trong khoáº£ng \\( \epsilon \\).")
   st.write("- **Border Point**: Äiá»ƒm khÃ´ng pháº£i lÃ  Core Point nhÆ°ng náº±m trong vÃ¹ng lÃ¢n cáº­n cá»§a má»™t Core Point.")
   st.write("- **Noise**: Äiá»ƒm khÃ´ng thuá»™c Core Point hoáº·c Border Point.")
   image_url = "https://media.datacamp.com/cms/google/ad_4nxczbbrn-drkfpsiiqf1zayyt5xnqiwgpz0qocpnt6au5mintqlk4r1mxlognyzyxxmewlx35vcn53cbwm6iun4hh5i-aokth6fyqhovv1dlill6myhah4hzizcpb-bmv-g8vbiwawgudq8_gkuhqb8yiwja.jpeg"
   article_url = "https://www.datacamp.com/tutorial/dbscan-clustering-algorithm"
   st.markdown(
        f"""
        <div style="text-align: center;">
            <a href="{article_url}" target="_blank">
                <img src="{image_url}" width="300">
            </a>
            <p style="font-size: 14px; color: gray;"></p>
        </div>
        """,
        unsafe_allow_html=True
    )   
   st.markdown(" ### 3ï¸âƒ£ Thuáº­t toÃ¡n DBSCAN")
   st.write("1. Chá»n má»™t Ä‘iá»ƒm chÆ°a Ä‘Æ°á»£c thÄƒm")
   st.write("2. Kiá»ƒm tra xem cÃ³ Ã­t nháº¥t MinPts Ä‘iá»ƒm trong vÃ¹ng \( \\varepsilon \) cá»§a nÃ³ hay khÃ´ng:")
   st.write("- âœ… **Náº¿u cÃ³**: Äiá»ƒm Ä‘Ã³ lÃ  **Core Point**, vÃ  má»™t cá»¥m má»›i báº¯t Ä‘áº§u.")
   st.write("- âŒ **Náº¿u khÃ´ng**: Äiá»ƒm Ä‘Ã³ lÃ  **Noise** (nhiá»…u), nhÆ°ng sau nÃ y cÃ³ thá»ƒ trá»Ÿ thÃ nh **Border Point** náº¿u thuá»™c vÃ¹ng lÃ¢n cáº­n cá»§a má»™t **Core Point**.")
   st.write("3. Náº¿u Ä‘iá»ƒm lÃ  Core Point, má»Ÿ rá»™ng cá»¥m báº±ng cÃ¡ch tÃ¬m táº¥t cáº£ cÃ¡c Ä‘iá»ƒm lÃ¢n cáº­n thá»a mÃ£n Ä‘iá»u kiá»‡n.")
   st.write("4. Láº·p láº¡i cho Ä‘áº¿n khi khÃ´ng cÃ²n Ä‘iá»ƒm nÃ o cÃ³ thá»ƒ Ä‘Æ°á»£c thÃªm vÃ o cá»¥m.")
   st.write("5. Chuyá»ƒn sang Ä‘iá»ƒm chÆ°a Ä‘Æ°á»£c thÄƒm tiáº¿p theo vÃ  láº·p láº¡i quÃ¡ trÃ¬nh.")
   image_url = "https://media.geeksforgeeks.org/wp-content/uploads/20190418023034/781ff66c-b380-4a78-af25-80507ed6ff26.jpeg"
   article_url = "https://www.geeksforgeeks.org/dbscan-clustering-in-ml-density-based-clustering/"
   st.markdown(
        f"""
        <div style="text-align: center;">
            <a href="{article_url}" target="_blank">
                <img src="{image_url}" width="300">
            </a>
            <p style="font-size: 14px; color: gray;"></p>
        </div>
        """,
        unsafe_allow_html=True
    )   

   



def data(): 
    st.title("ğŸ“š Táº­p Dá»¯ Liá»‡u MNIST")
    
    st.markdown("""
    Táº­p dá»¯ liá»‡u **MNIST (Modified National Institute of Standards and Technology)** lÃ  má»™t trong nhá»¯ng bá»™ dá»¯ liá»‡u ná»•i báº­t vÃ  phá»• biáº¿n nháº¥t trong lÄ©nh vá»±c há»c mÃ¡y vÃ  nháº­n dáº¡ng hÃ¬nh áº£nh. ÄÃ¢y lÃ  táº­p dá»¯ liá»‡u bao gá»“m cÃ¡c hÃ¬nh áº£nh cá»§a cÃ¡c chá»¯ sá»‘ viáº¿t tay tá»« 0 Ä‘áº¿n 9, Ä‘Æ°á»£c thu tháº­p Ä‘á»ƒ thá»­ nghiá»‡m cÃ¡c thuáº­t toÃ¡n phÃ¢n loáº¡i vÃ  nháº­n dáº¡ng máº«u.
    
    ![Mnist-dataset](https://datasets.activeloop.ai/wp-content/uploads/2019/12/MNIST-handwritten-digits-dataset-visualized-by-Activeloop.webp)
                               

    ## 1. Tá»•ng Quan vá» MNIST:
    MNIST gá»“m hai pháº§n chÃ­nh:
    
    - **Dá»¯ liá»‡u huáº¥n luyá»‡n (Training Set)**: Gá»“m 60.000 hÃ¬nh áº£nh.
    - **Dá»¯ liá»‡u kiá»ƒm tra (Test Set)**: Gá»“m 10.000 hÃ¬nh áº£nh.
    
    Má»—i hÃ¬nh áº£nh trong bá»™ dá»¯ liá»‡u cÃ³ kÃ­ch thÆ°á»›c lÃ  28x28 pixel vÃ  biá»ƒu diá»…n má»™t trong 10 chá»¯ sá»‘ (0 Ä‘áº¿n 9). Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chuáº©n hÃ³a, vá»›i cÃ¡c hÃ¬nh áº£nh Ä‘Æ°á»£c cÄƒn chá»‰nh vÃ  cÃ³ ná»n tráº¯ng, giÃºp viá»‡c xá»­ lÃ½ trá»Ÿ nÃªn Ä‘Æ¡n giáº£n hÆ¡n.
    
    ## 2. Má»¥c TiÃªu Sá»­ Dá»¥ng Táº­p Dá»¯ Liá»‡u MNIST:
    MNIST chá»§ yáº¿u Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ huáº¥n luyá»‡n vÃ  kiá»ƒm tra cÃ¡c thuáº­t toÃ¡n phÃ¢n loáº¡i. CÃ¡c má»¥c tiÃªu chÃ­nh khi lÃ m viá»‡c vá»›i MNIST bao gá»“m:
    
    - **PhÃ¢n loáº¡i chá»¯ sá»‘ viáº¿t tay**: Dá»± Ä‘oÃ¡n chá»¯ sá»‘ tÆ°Æ¡ng á»©ng vá»›i má»—i hÃ¬nh áº£nh.
    - **Kiá»ƒm thá»­ mÃ´ hÃ¬nh há»c mÃ¡y**: ÄÆ°á»£c sá»­ dá»¥ng Ä‘á»ƒ kiá»ƒm tra hiá»‡u quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y, tá»« cÃ¡c thuáº­t toÃ¡n cá»• Ä‘iá»ƒn nhÆ° K-Nearest Neighbors (KNN), Support Vector Machines (SVM) Ä‘áº¿n cÃ¡c mÃ´ hÃ¬nh há»c sÃ¢u nhÆ° máº¡ng nÆ¡-ron tÃ­ch cháº­p (CNN).
    - **Tiá»n xá»­ lÃ½ vÃ  há»c mÃ¡y cÆ¡ báº£n**: ÄÃ¢y lÃ  má»™t bá»™ dá»¯ liá»‡u tuyá»‡t vá»i Ä‘á»ƒ hiá»ƒu rÃµ cÃ¡c quy trÃ¬nh tiá»n xá»­ lÃ½ dá»¯ liá»‡u vÃ  cÃ¡ch thá»©c hoáº¡t Ä‘á»™ng cá»§a cÃ¡c mÃ´ hÃ¬nh phÃ¢n loáº¡i.
    
    ## 3. Cáº¥u TrÃºc Dá»¯ Liá»‡u MNIST:
    Má»—i hÃ¬nh áº£nh trong bá»™ dá»¯ liá»‡u MNIST cÃ³ kÃ­ch thÆ°á»›c 28x28 pixel, tá»©c lÃ  má»—i hÃ¬nh áº£nh sáº½ cÃ³ 784 giÃ¡ trá»‹ sá»‘ nguyÃªn, tÆ°Æ¡ng á»©ng vá»›i Ä‘á»™ sÃ¡ng cá»§a tá»«ng pixel. Táº¥t cáº£ cÃ¡c giÃ¡ trá»‹ nÃ y sáº½ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh. Dá»¯ liá»‡u nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng cho cÃ¡c tÃ¡c vá»¥ nhÆ°:
    
    - **PhÃ¢n loáº¡i hÃ¬nh áº£nh**: CÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y cÃ³ thá»ƒ há»c cÃ¡ch phÃ¢n loáº¡i cÃ¡c hÃ¬nh áº£nh thÃ nh cÃ¡c nhÃ³m chá»¯ sá»‘ tá»« 0 Ä‘áº¿n 9.
    - **Tiá»n xá»­ lÃ½ hÃ¬nh áº£nh**: Viá»‡c chuáº©n hÃ³a dá»¯ liá»‡u vÃ  Ã¡p dá»¥ng cÃ¡c ká»¹ thuáº­t tiá»n xá»­ lÃ½ giÃºp cáº£i thiá»‡n hiá»‡u quáº£ cá»§a mÃ´ hÃ¬nh.
    
    ## 4. á»¨ng Dá»¥ng Cá»§a Táº­p Dá»¯ Liá»‡u MNIST:
    - **Nháº­n dáº¡ng chá»¯ viáº¿t tay**: ÄÃ¢y lÃ  á»©ng dá»¥ng phá»• biáº¿n nháº¥t cá»§a MNIST.
    - **Há»c sÃ¢u vÃ  phÃ¢n loáº¡i hÃ¬nh áº£nh**: CÃ¡c mÃ´ hÃ¬nh há»c sÃ¢u, Ä‘áº·c biá»‡t lÃ  máº¡ng nÆ¡-ron tÃ­ch cháº­p, Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i bá»™ dá»¯ liá»‡u nÃ y Ä‘á»ƒ phÃ¢n loáº¡i chá»¯ sá»‘.
    """)


def up_load_db():
    st.header("ğŸ“¥ Táº£i Dá»¯ Liá»‡u")
    
    if "data" in st.session_state and st.session_state.data is not None:
        st.warning("ğŸ”¸ **Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c táº£i lÃªn rá»“i!** Báº¡n cÃ³ thá»ƒ tiáº¿p tá»¥c vá»›i cÃ¡c bÆ°á»›c tiá»n xá»­ lÃ½ vÃ  chia dá»¯ liá»‡u.")
    else:
        option = st.radio("Chá»n nguá»“n dá»¯ liá»‡u:", ["Táº£i tá»« OpenML", "Upload dá»¯ liá»‡u"], key="data_source_radio")
        
        if "data" not in st.session_state:
            st.session_state.data = None
        
        if option == "Táº£i tá»« OpenML":
            st.markdown("#### ğŸ“‚ Táº£i dá»¯ liá»‡u MNIST tá»« OpenML")
            if st.button("Táº£i dá»¯ liá»‡u MNIST", key="download_mnist_button"):
                with st.status("ğŸ”„ Äang táº£i dá»¯ liá»‡u MNIST tá»« OpenML...", expanded=True) as status:
                    progress_bar = st.progress(0)
                    for percent_complete in range(0, 101, 20):
                        time.sleep(0.5)
                        progress_bar.progress(percent_complete)
                        status.update(label=f"ğŸ”„ Äang táº£i... ({percent_complete}%)")
                    
                    X = np.load("X.npy")
                    y = np.load("y.npy")
                    
                    status.update(label="âœ… Táº£i dá»¯ liá»‡u thÃ nh cÃ´ng!", state="complete")
                    
                    st.session_state.data = (X, y)
        
        else:
            st.markdown("#### ğŸ“¤ Upload dá»¯ liá»‡u cá»§a báº¡n")
            uploaded_file = st.file_uploader("Chá»n má»™t file áº£nh", type=["png", "jpg", "jpeg"], key="file_upload")
            
            if uploaded_file is not None:
                with st.status("ğŸ”„ Äang xá»­ lÃ½ áº£nh...", expanded=True) as status:
                    progress_bar = st.progress(0)
                    for percent_complete in range(0, 101, 25):
                        time.sleep(0.3)
                        progress_bar.progress(percent_complete)
                        status.update(label=f"ğŸ”„ Äang xá»­ lÃ½... ({percent_complete}%)")
                    
                    image = Image.open(uploaded_file)
                    st.image(image, caption="áº¢nh Ä‘Ã£ táº£i lÃªn", use_column_width=True)
                    
                    if image.size != (28, 28):
                        status.update(label="âŒ áº¢nh khÃ´ng Ä‘Ãºng kÃ­ch thÆ°á»›c 28x28 pixel.", state="error")
                    else:
                        status.update(label="âœ… áº¢nh há»£p lá»‡!", state="complete")
                        image = image.convert('L')
                        image_array = np.array(image).reshape(1, -1)
                        st.session_state.data = image_array
    
    if st.session_state.data is not None:
        st.markdown("#### âœ… Dá»¯ liá»‡u Ä‘Ã£ sáºµn sÃ ng!")
        
        if isinstance(st.session_state.data, tuple):
            X, y = st.session_state.data
            st.markdown("##### ğŸ”„ Tiáº¿n hÃ nh tiá»n xá»­ lÃ½ dá»¯ liá»‡u MNIST")
            preprocess_option = st.selectbox("Chá»n phÆ°Æ¡ng phÃ¡p tiá»n xá»­ lÃ½ dá»¯ liá»‡u:", 
                                            ["Chuáº©n hÃ³a dá»¯ liá»‡u (Standardization)", "Giáº£m chiá»u (PCA)", "KhÃ´ng tiá»n xá»­ lÃ½"], 
                                            key="preprocess_mnist")
            if preprocess_option == "Chuáº©n hÃ³a dá»¯ liá»‡u (Standardization)":
                X_reshaped = X.reshape(X.shape[0], -1)
                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(X_reshaped)
                st.write("ğŸ“Š **Dá»¯ liá»‡u sau khi chuáº©n hÃ³a**:")
                st.write(pd.DataFrame(X_scaled).head())
            elif preprocess_option == "Giáº£m chiá»u (PCA)":
                pca = PCA(n_components=50)
                X_pca = pca.fit_transform(X.reshape(X.shape[0], -1))
                st.write("ğŸ“Š **Dá»¯ liá»‡u sau khi giáº£m chiá»u (PCA)**:")
                st.write(pd.DataFrame(X_pca).head())
            else:
                st.write("ğŸ“Š **Dá»¯ liá»‡u khÃ´ng cÃ³ tiá»n xá»­ lÃ½**.")
        
        elif isinstance(st.session_state.data, np.ndarray):
            st.markdown("#### ğŸ‘ï¸ Tiáº¿n hÃ nh tiá»n xá»­ lÃ½ áº£nh")
            preprocess_option_image = st.selectbox("Chá»n phÆ°Æ¡ng phÃ¡p tiá»n xá»­ lÃ½ áº£nh:",
                                                   ["Chuáº©n hÃ³a áº£nh", "KhÃ´ng tiá»n xá»­ lÃ½"], 
                                                   key="preprocess_image")
            if preprocess_option_image == "Chuáº©n hÃ³a áº£nh":
                image_scaled = st.session_state.data / 255.0
                st.write("ğŸ“Š **áº¢nh sau khi chuáº©n hÃ³a**:")
                st.image(image_scaled.reshape(28, 28), caption="áº¢nh sau khi chuáº©n hÃ³a", use_column_width=True)
            else:
                st.write("ğŸ“Š **áº¢nh khÃ´ng cÃ³ tiá»n xá»­ lÃ½**.")
    else:
        st.warning("ğŸ”¸ Vui lÃ²ng táº£i dá»¯ liá»‡u trÆ°á»›c khi tiáº¿p tá»¥c lÃ m viá»‡c.")
    
    st.markdown("""
    ğŸ”¹ **LÆ°u Ã½:**
    - á»¨ng dá»¥ng chá»‰ sá»­ dá»¥ng dá»¯ liá»‡u áº£nh dáº¡ng **28x28 pixel (grayscale)**.
    - Dá»¯ liá»‡u pháº£i cÃ³ cá»™t **'label'** chá»©a nhÃ£n (sá»‘ tá»« 0 Ä‘áº¿n 9) khi táº£i tá»« OpenML.
    - Náº¿u dá»¯ liá»‡u cá»§a báº¡n khÃ´ng Ä‘Ãºng Ä‘á»‹nh dáº¡ng, vui lÃ²ng sá»­ dá»¥ng dá»¯ liá»‡u MNIST tá»« OpenML.
    """)


def chia_du_lieu():
    st.title("ğŸ“Œ Chia dá»¯ liá»‡u Train/Test")

    # Äá»c dá»¯ liá»‡u
    Xmt = np.load("X.npy")
    ymt = np.load("y.npy")
    X = Xmt.reshape(Xmt.shape[0], -1)  # Giá»¯ nguyÃªn Ä‘á»‹nh dáº¡ng dá»¯ liá»‡u
    y = ymt.reshape(-1)  

    total_samples = X.shape[0]

    # Thanh kÃ©o chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train
    num_samples = st.slider("Chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train:", min_value=1000, max_value=total_samples, value=10000)

    # Thanh kÃ©o chá»n tá»· lá»‡ Train/Test
    test_size = st.slider("Chá»n tá»· lá»‡ test:", min_value=0.1, max_value=0.5, value=0.2)

    if st.button("âœ… XÃ¡c nháº­n & LÆ°u"):
        progress_bar = st.progress(0)
        status_text = st.empty()

        # Cáº­p nháº­t tiáº¿n trÃ¬nh
        progress_stages = [(10, "ğŸ”„ Äang chá»n sá»‘ lÆ°á»£ng áº£nh..."),
                           (50, "ğŸ”„ Äang chia dá»¯ liá»‡u Train/Test..."),
                           (80, "ğŸ”„ Äang lÆ°u dá»¯ liá»‡u vÃ o session..."),
                           (100, "âœ… HoÃ n táº¥t!")]

        for progress, message in progress_stages:
            progress_bar.progress(progress)
            status_text.text(f"{message} ({progress}%)")
            time.sleep(0.5)  # Táº¡o Ä‘á»™ trá»… Ä‘á»ƒ hiá»ƒn thá»‹ tiáº¿n trÃ¬nh rÃµ rÃ ng hÆ¡n

        X_selected, y_selected = X[:num_samples], y[:num_samples]
        X_train, X_test, y_train, y_test = train_test_split(X_selected, y_selected, test_size=test_size, random_state=42)

        # LÆ°u vÃ o session_state Ä‘á»ƒ sá»­ dá»¥ng sau
        st.session_state["X_train"] = X_train
        st.session_state["y_train"] = y_train
        st.session_state["X_test"] = X_test
        st.session_state["y_test"] = y_test

        st.success(f"ğŸ”¹ Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia: Train ({len(X_train)}), Test ({len(X_test)})")

    if "X_train" in st.session_state:
        st.write("ğŸ“Œ Dá»¯ liá»‡u train/test Ä‘Ã£ sáºµn sÃ ng Ä‘á»ƒ sá»­ dá»¥ng!")

###Thiet lap dagshub
def mlflow_input():
    #st.title("ğŸš€ MLflow DAGsHub Tracking vá»›i Streamlit")
    DAGSHUB_USERNAME = "Snxtruc"  # Thay báº±ng username cá»§a báº¡n
    DAGSHUB_REPO_NAME = "HocMayPython"
    DAGSHUB_TOKEN = "ca4b78ae4dd9d511c1e0c333e3b709b2cd789a19"  # Thay báº±ng Access Token cá»§a báº¡n

    # Äáº·t URI MLflow Ä‘á»ƒ trá» Ä‘áº¿n DagsHub
    mlflow.set_tracking_uri(f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO_NAME}.mlflow")

    # Thiáº¿t láº­p authentication báº±ng Access Token
    os.environ["MLFLOW_TRACKING_USERNAME"] = DAGSHUB_USERNAME
    os.environ["MLFLOW_TRACKING_PASSWORD"] = DAGSHUB_TOKEN

    # Äáº·t thÃ­ nghiá»‡m MLflow
    mlflow.set_experiment("Clustering Algorithms")   

    st.session_state['mlflow_url'] = f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO_NAME}.mlflow"

def train():
    st.header("âš™ï¸ Chá»n mÃ´ hÃ¬nh & Huáº¥n luyá»‡n")

    if "X_train" not in st.session_state:
        st.warning("âš ï¸ Vui lÃ²ng chia dá»¯ liá»‡u trÆ°á»›c khi train!")
        return

    X_train = st.session_state["X_train"]
    y_train = st.session_state["y_train"]
    X_train_norm = (X_train / 255.0).reshape(X_train.shape[0], -1)

    model_choice = st.selectbox("Chá»n mÃ´ hÃ¬nh:", ["K-Means", "DBSCAN"])
    
    run_name = st.text_input("ğŸ”¹ Nháº­p tÃªn Run:", "Default_Run").strip()

    if model_choice == "K-Means":
        st.markdown("ğŸ”¹ **K-Means**")
        n_clusters = st.slider("ğŸ”¢ Chá»n sá»‘ cá»¥m (K):", 2, 20, 10)
        pca = PCA(n_components=2)
        X_train_pca = pca.fit_transform(X_train_norm)
        model = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)

    elif model_choice == "DBSCAN":
        st.markdown("ğŸ› ï¸ **DBSCAN**")
        eps = st.slider("ğŸ“ BÃ¡n kÃ­nh lÃ¢n cáº­n (eps):", 0.1, 10.0, 0.5)
        min_samples = st.slider("ğŸ‘¥ Sá»‘ Ä‘iá»ƒm tá»‘i thiá»ƒu trong cá»¥m:", 2, 20, 5)
        pca = PCA(n_components=2)
        X_train_pca = pca.fit_transform(X_train_norm)
        model = DBSCAN(eps=eps, min_samples=min_samples)

    mlflow_input()
    if st.button("ğŸš€ Huáº¥n luyá»‡n mÃ´ hÃ¬nh"):
        progress_bar = st.progress(0)
        status_text = st.empty()

        with mlflow.start_run(run_name=run_name):
            total_delay = 10  # Tá»•ng thá»i gian delay thÃªm
            steps = 10  # Chia thÃ nh 10 bÆ°á»›c
            step_delay = total_delay / steps

            for percent_complete in range(0, 101, 10):  
                time.sleep(step_delay)  
                progress_bar.progress(percent_complete)
                status_text.text(f"ğŸ”„ Huáº¥n luyá»‡n: {percent_complete}%")

            model.fit(X_train_pca)
            progress_bar.progress(100)
            status_text.text("âœ… Huáº¥n luyá»‡n hoÃ n táº¥t!")
            st.success(f"âœ… Huáº¥n luyá»‡n thÃ nh cÃ´ng! (Run: `{run_name}`)")

            labels = model.labels_

            if model_choice == "K-Means":
                label_mapping = {}
                for i in range(n_clusters):
                    mask = labels == i
                    if np.sum(mask) > 0:
                        most_common_label = stats.mode(y_train[mask], keepdims=True).mode[0]
                        label_mapping[i] = most_common_label

                predicted_labels = np.array([label_mapping[label] for label in labels])
                accuracy_train = np.mean(predicted_labels == y_train)
                st.write(f"ğŸ¯ **Äá»™ chÃ­nh xÃ¡c trÃªn táº­p train:** `{accuracy_train * 100:.2f}%`")

                mlflow.log_param("model", "K-Means")
                mlflow.log_param("n_clusters", n_clusters)
                mlflow.log_metric("accuracy_train", accuracy_train)
                mlflow.sklearn.log_model(model, "kmeans_model")

            elif model_choice == "DBSCAN":
                unique_clusters = set(labels) - {-1}
                n_clusters_found = len(unique_clusters)
                noise_ratio = np.sum(labels == -1) / len(labels)
                st.write(f"ğŸ” **Sá»‘ cá»¥m tÃ¬m tháº¥y:** `{n_clusters_found}`")
                st.write(f"ğŸš¨ **Tá»‰ lá»‡ nhiá»…u:** `{noise_ratio * 100:.2f}%`")

                mlflow.log_param("model", "DBSCAN")
                mlflow.log_param("eps", eps)
                mlflow.log_param("min_samples", min_samples)
                mlflow.log_metric("n_clusters_found", n_clusters_found)
                mlflow.log_metric("noise_ratio", noise_ratio)
                mlflow.sklearn.log_model(model, "dbscan_model")

            if "models" not in st.session_state:
                st.session_state["models"] = []

            st.session_state["models"].append({"name": run_name, "model": model})
            st.write(f"ğŸ”¹ **MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vá»›i tÃªn:** `{run_name}`")
            st.write(f"ğŸ“‹ **Danh sÃ¡ch cÃ¡c mÃ´ hÃ¬nh:** {[m['name'] for m in st.session_state['models']]}")
            mlflow.end_run()
            st.success("âœ… ÄÃ£ log dá»¯ liá»‡u!")
            st.markdown(f"### ğŸ”— [Truy cáº­p MLflow]({st.session_state['mlflow_url']})")

def du_doan():
    st.header("Demo Dá»± Ä‘oÃ¡n Cá»¥m")

    # Kiá»ƒm tra xem mÃ´ hÃ¬nh phÃ¢n cá»¥m vÃ  nhÃ£n Ä‘Ã£ cÃ³ chÆ°a
    if 'cluster_model' in st.session_state and 'cluster_labels' in st.session_state:
        # Táº£i lÃªn áº£nh hoáº·c file CSV
        uploaded_image = st.file_uploader("Upload áº£nh chá»¯ sá»‘ (28x28, grayscale) hoáº·c file CSV", type=["png", "jpg", "csv"])
        true_label = st.text_input("Nháº­p nhÃ£n tháº­t (náº¿u cÃ³):")
        
        if uploaded_image is not None:
            if uploaded_image.name.endswith('.csv'):
                # Äá»c file CSV vÃ  tiá»n xá»­ lÃ½
                df = pd.read_csv(uploaded_image)
                # Giáº£ sá»­ dá»¯ liá»‡u CSV cÃ³ cá»™t tÃªn 'features' chá»©a dá»¯ liá»‡u Ä‘áº·c trÆ°ng áº£nh 28x28
                # Náº¿u file CSV cÃ³ cáº¥u trÃºc khÃ¡c, báº¡n cáº§n Ä‘iá»u chá»‰nh pháº§n nÃ y cho phÃ¹ há»£p
                img_array = df['features'].values.flatten() / 255.0  # Tiá»n xá»­ lÃ½ náº¿u cáº§n
            else:
                # Äá»c áº£nh vÃ  tiá»n xá»­ lÃ½
                img = Image.open(uploaded_image).convert('L').resize((28, 28))
                img_array = np.array(img).flatten() / 255.0  # Tiá»n xá»­ lÃ½ áº£nh Ä‘á»ƒ Ä‘Æ°a vá» dáº¡ng (1, 28*28)

            if st.button("Dá»± Ä‘oÃ¡n cá»¥m"):
                model = st.session_state['cluster_model']
                if isinstance(model, KMeans):
                    # Dá»± Ä‘oÃ¡n cá»¥m vá»›i KMeans
                    predicted_cluster = model.predict([img_array])[0]
                elif isinstance(model, DBSCAN):
                    # DBSCAN khÃ´ng cÃ³ phÆ°Æ¡ng thá»©c predict() nÃªn cáº§n tÃ­nh toÃ¡n khoáº£ng cÃ¡ch
                    # TÃ­nh toÃ¡n khoáº£ng cÃ¡ch vá»›i cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c phÃ¢n cá»¥m
                    distances = np.linalg.norm(model.components_ - img_array, axis=1)
                    predicted_cluster = model.labels_[np.argmin(distances)]  # Dá»± Ä‘oÃ¡n cá»¥m vá»›i DBSCAN

                # Láº¥y nhÃ£n phÃ¢n cá»¥m tá»« session_state
                cluster_labels = st.session_state['cluster_labels']
                st.write(f"**Dá»± Ä‘oÃ¡n cá»¥m:** {predicted_cluster} - NhÃ£n phÃ¢n cá»¥m: {cluster_labels[predicted_cluster]}")

                # Ãnh xáº¡ cá»¥m thÃ nh chá»¯ sá»‘ náº¿u cÃ³
                if 'cluster_mapping' in st.session_state:
                    mapped_digit = st.session_state['cluster_mapping'].get(predicted_cluster, "N/A")
                    st.write(f"**MÃ£ hÃ³a thÃ nh chá»¯ sá»‘:** {mapped_digit}")
                    
                    if true_label:
                        if str(mapped_digit) == str(true_label):
                            st.success("Dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c!")
                        else:
                            st.error("Dá»± Ä‘oÃ¡n chÆ°a chÃ­nh xÃ¡c!")

                # Hiá»ƒn thá»‹ áº£nh hoáº·c dá»¯ liá»‡u tá»« file CSV
                if uploaded_image.name.endswith('.csv'):
                    st.write("Dá»¯ liá»‡u tá»« file CSV Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng cho dá»± Ä‘oÃ¡n.")
                else:
                    st.image(img, caption="áº¢nh Ä‘Ã£ upload", use_container_width=True)
    else:
        st.info("Vui lÃ²ng thá»±c hiá»‡n phÃ¢n cá»¥m vÃ  huáº¥n luyá»‡n mÃ´ hÃ¬nh trÆ°á»›c.")

def format_time_relative(timestamp_ms):
    """Chuyá»ƒn timestamp milliseconds thÃ nh thá»i gian dá»… Ä‘á»c."""
    if timestamp_ms is None:
        return "N/A"
    dt = datetime.fromtimestamp(timestamp_ms / 1000)
    return dt.strftime("%Y-%m-%d %H:%M:%S")

def display_mlflow_experiments():
    """Hiá»ƒn thá»‹ danh sÃ¡ch Runs trong MLflow."""
    st.title("ğŸ“Š MLflow Experiment Viewer")

    mlflow_input()

    experiment_name = "Clustering Algorithms"
    experiments = mlflow.search_experiments()
    selected_experiment = next((exp for exp in experiments if exp.name == experiment_name), None)

    if not selected_experiment:
        st.error(f"âŒ Experiment '{experiment_name}' khÃ´ng tá»“n táº¡i!")
        return

    st.subheader(f"ğŸ“Œ Experiment: {experiment_name}")
    st.write(f"**Experiment ID:** {selected_experiment.experiment_id}")
    st.write(f"**Tráº¡ng thÃ¡i:** {'Active' if selected_experiment.lifecycle_stage == 'active' else 'Deleted'}")
    st.write(f"**Vá»‹ trÃ­ lÆ°u trá»¯:** {selected_experiment.artifact_location}")

    # Láº¥y danh sÃ¡ch Runs
    runs = mlflow.search_runs(experiment_ids=[selected_experiment.experiment_id])

    if runs.empty:
        st.warning("âš  KhÃ´ng cÃ³ runs nÃ o trong experiment nÃ y.")
        return

    # Xá»­ lÃ½ dá»¯ liá»‡u runs Ä‘á»ƒ hiá»ƒn thá»‹
    run_info = []
    for _, run in runs.iterrows():
        run_id = run["run_id"]
        run_data = mlflow.get_run(run_id)
        run_tags = run_data.data.tags
        run_name = run_tags.get("mlflow.runName", f"Run {run_id[:8]}")  # Láº¥y tÃªn tá»« tags náº¿u cÃ³
        created_time = format_time_relative(run_data.info.start_time)
        duration = (run_data.info.end_time - run_data.info.start_time) / 1000 if run_data.info.end_time else "Äang cháº¡y"
        source = run_tags.get("mlflow.source.name", "Unknown")

        run_info.append({
            "Run Name": run_name,
            "Run ID": run_id,
            "Created": created_time,
            "Duration (s)": duration if isinstance(duration, str) else f"{duration:.1f}s",
            "Source": source
        })

    # Sáº¯p xáº¿p run theo thá»i gian cháº¡y (má»›i nháº¥t trÆ°á»›c)
    run_info_df = pd.DataFrame(run_info)
    run_info_df = run_info_df.sort_values(by="Created", ascending=False)

    # Hiá»ƒn thá»‹ danh sÃ¡ch Runs trong báº£ng
    st.write("### ğŸƒâ€â™‚ï¸ Danh sÃ¡ch Runs:")
    st.dataframe(run_info_df, use_container_width=True)

    # Chá»n Run tá»« dropdown
    run_names = run_info_df["Run Name"].tolist()
    selected_run_name = st.selectbox("ğŸ” Chá»n má»™t Run Ä‘á»ƒ xem chi tiáº¿t:", run_names)

    # Láº¥y Run ID tÆ°Æ¡ng á»©ng
    selected_run_id = run_info_df.loc[run_info_df["Run Name"] == selected_run_name, "Run ID"].values[0]

    # Láº¥y thÃ´ng tin Run
    selected_run = mlflow.get_run(selected_run_id)

    # --- ğŸ“ Äá»”I TÃŠN RUN ---
    st.write("### âœï¸ Äá»•i tÃªn Run")
    new_run_name = st.text_input("Nháº­p tÃªn má»›i:", selected_run_name)
    if st.button("ğŸ’¾ LÆ°u tÃªn má»›i"):
        try:
            mlflow.set_tag(selected_run_id, "mlflow.runName", new_run_name)
            st.success(f"âœ… ÄÃ£ Ä‘á»•i tÃªn thÃ nh **{new_run_name}**. HÃ£y táº£i láº¡i trang Ä‘á»ƒ tháº¥y thay Ä‘á»•i!")
        except Exception as e:
            st.error(f"âŒ Lá»—i khi Ä‘á»•i tÃªn: {e}")

    # --- ğŸ—‘ï¸ XÃ“A RUN ---
    st.write("### âŒ XÃ³a Run")
    if st.button("ğŸ—‘ï¸ XÃ³a Run nÃ y"):
        try:
            mlflow.delete_run(selected_run_id)
            st.success(f"âœ… ÄÃ£ xÃ³a run **{selected_run_name}**! HÃ£y táº£i láº¡i trang Ä‘á»ƒ cáº­p nháº­t danh sÃ¡ch.")
        except Exception as e:
            st.error(f"âŒ Lá»—i khi xÃ³a run: {e}")

    # --- HIá»‚N THá»Š CHI TIáº¾T RUN ---
    if selected_run:
        st.subheader(f"ğŸ“Œ ThÃ´ng tin Run: {selected_run_name}")
        st.write(f"**Run ID:** {selected_run_id}")
        st.write(f"**Tráº¡ng thÃ¡i:** {selected_run.info.status}")

        start_time_ms = selected_run.info.start_time
        if start_time_ms:
            start_time = datetime.fromtimestamp(start_time_ms / 1000).strftime("%Y-%m-%d %H:%M:%S")
        else:
            start_time = "KhÃ´ng cÃ³ thÃ´ng tin"

        st.write(f"**Thá»i gian cháº¡y:** {start_time}")

        # Hiá»ƒn thá»‹ thÃ´ng sá»‘ Ä‘Ã£ log
        params = selected_run.data.params
        metrics = selected_run.data.metrics

        if params:
            st.write("### âš™ï¸ Parameters:")
            st.json(params)

        if metrics:
            st.write("### ğŸ“Š Metrics:")
            st.json(metrics)

        # Hiá»ƒn thá»‹ model artifact (náº¿u cÃ³)
        model_artifact_path = f"{st.session_state['mlflow_url']}/{selected_experiment.experiment_id}/{selected_run_id}/artifacts/model"
        st.write("### ğŸ“‚ Model Artifact:")
        st.write(f"ğŸ“¥ [Táº£i mÃ´ hÃ¬nh]({model_artifact_path})")

    else:
        st.warning("âš  KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin cho run nÃ y.")


def ClusteringAlgorithms():
  
    # Thiáº¿t láº­p CSS Ä‘á»ƒ há»— trá»£ hiá»ƒn thá»‹ tabs vá»›i hiá»‡u á»©ng hover vÃ  thanh cuá»™n
    st.markdown(
        """
        <style>
        .stTabs [role="tablist"] {
            overflow-x: auto;
            white-space: nowrap;
            display: flex;
            scrollbar-width: thin;
            scrollbar-color: #888 #f0f0f0;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar {
            height: 6px;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar-thumb {
            background-color: #888;
            border-radius: 3px;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar-track {
            background: #f0f0f0;
        }
        .stTabs [role="tab"]:hover {
            background-color: #f0f0f0;
            transition: background-color 0.3s ease-in-out;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

    st.title("ğŸ–Šï¸ MNIST Clusterings App")

    # Ensure the tab names are properly separated
    tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8 = st.tabs([
    "ğŸ“˜ LÃ½ thuyáº¿t K-MEANS", 
    "ğŸ“˜ LÃ½ thuyáº¿t DBSCANS", 
    "ğŸ“˜ Data", 
    "ğŸ“¥ Táº£i dá»¯ liá»‡u", 
    "ğŸ”€ Chia dá»¯ liá»‡u", 
    "ğŸ¤– PhÃ¢n cá»¥m", 
    "ğŸ” ThÃ´ng tin phÃ¢n cá»¥m"
    ])


    with tab1:
        ly_thuyet_kmeans()

    with tab2:
        ly_thuyet_dbscans()
    
    with tab3:
        data()
        
    with tab4:
       up_load_db()
        
    with tab5:
        chia_du_lieu()
    
    with tab6: 
        train()

    with tab7: 
        display_mlflow_experiments() 

def run():
    ClusteringAlgorithms()

if __name__ == "__main__":
    run()
