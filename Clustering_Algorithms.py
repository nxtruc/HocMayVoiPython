import streamlit as st
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image
import openml
import os
import mlflow
import shutil
from scipy.stats import mode
from scipy import stats
from mlflow.tracking import MlflowClient
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans, DBSCAN
from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score
from sklearn.datasets import make_blobs
from sklearn.metrics import silhouette_score
from sklearn.preprocessing import StandardScaler
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
# Táº£i dá»¯ liá»‡u MNIST tá»« OpenML


import streamlit as st

def ly_thuyet_kmeans():
    st.title("ğŸ“Š LÃ½ thuyáº¿t vá» K-means")

    # ChÃ¨n Ä‘Æ°á»ng link áº£nh trÆ°á»›c pháº§n Má»¥c tiÃªu cá»§a K-means
    st.markdown("""
    

    **K-means** lÃ  thuáº­t toÃ¡n phÃ¢n cá»¥m phá»• biáº¿n trong há»c mÃ¡y khÃ´ng giÃ¡m sÃ¡t (unsupervised learning). Thuáº­t toÃ¡n nÃ y nhÃ³m cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u thÃ nh cÃ¡c cá»¥m sao cho cÃ¡c Ä‘iá»ƒm trong cÃ¹ng má»™t cá»¥m cÃ³ sá»± tÆ°Æ¡ng Ä‘á»“ng cao, vÃ  cÃ¡c cá»¥m cÃ³ sá»± khÃ¡c biá»‡t lá»›n. Má»™t trong nhá»¯ng Ä‘iá»ƒm ná»•i báº­t cá»§a K-means lÃ  ngÆ°á»i dÃ¹ng khÃ´ng cáº§n pháº£i biáº¿t trÆ°á»›c sá»‘ lÆ°á»£ng cá»¥m cáº§n phÃ¢n chia.
    ![K-means Algorithm](https://machinelearningcoban.com/assets/kmeans/figure_2.png)           
                
    ### 1. Má»¥c tiÃªu cá»§a K-means
    K-means nháº±m phÃ¢n chia táº­p dá»¯ liá»‡u thÃ nh **K cá»¥m**, sao cho:
    - CÃ¡c Ä‘iá»ƒm trong cÃ¹ng má»™t cá»¥m cÃ³ Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng cao (dá»±a trÃªn khoáº£ng cÃ¡ch giá»¯a cÃ¡c Ä‘iá»ƒm).
    - Khoáº£ng cÃ¡ch giá»¯a cÃ¡c cá»¥m lÃ  lá»›n nháº¥t, nghÄ©a lÃ  cÃ¡c cá»¥m pháº£i phÃ¢n tÃ¡ch rÃµ rÃ ng.

    ### 2. NguyÃªn lÃ½ hoáº¡t Ä‘á»™ng
    Quy trÃ¬nh cá»§a K-means bao gá»“m cÃ¡c bÆ°á»›c chÃ­nh sau:
    1. **Khá»Ÿi táº¡o sá»‘ cá»¥m (K)**: NgÆ°á»i dÃ¹ng pháº£i chá»‰ Ä‘á»‹nh trÆ°á»›c sá»‘ lÆ°á»£ng cá»¥m K.
    2. **Khá»Ÿi táº¡o cÃ¡c tÃ¢m cá»¥m (centroids)**: Sau khi chá»n K, thuáº­t toÃ¡n khá»Ÿi táº¡o K centroid (tÃ¢m cá»¥m) báº±ng cÃ¡ch chá»n ngáº«u nhiÃªn hoáº·c sá»­ dá»¥ng phÆ°Æ¡ng phÃ¡p K-means++ Ä‘á»ƒ cáº£i thiá»‡n viá»‡c khá»Ÿi táº¡o.
    3. **GÃ¡n Ä‘iá»ƒm dá»¯ liá»‡u vÃ o cÃ¡c cá»¥m**: Má»—i Ä‘iá»ƒm dá»¯ liá»‡u Ä‘Æ°á»£c gÃ¡n vÃ o cá»¥m cÃ³ centroid gáº§n nháº¥t, thÆ°á»ng sá»­ dá»¥ng khoáº£ng cÃ¡ch Euclidean.
    4. **Cáº­p nháº­t centroid**: Sau khi cÃ¡c Ä‘iá»ƒm Ä‘Æ°á»£c gÃ¡n vÃ o cá»¥m, centroid cá»§a má»—i cá»¥m Ä‘Æ°á»£c tÃ­nh láº¡i lÃ  trung bÃ¬nh cá»§a cÃ¡c Ä‘iá»ƒm trong cá»¥m.
    5. **Láº·p láº¡i**: QuÃ¡ trÃ¬nh gÃ¡n Ä‘iá»ƒm vÃ o cá»¥m vÃ  cáº­p nháº­t centroid tiáº¿p tá»¥c cho Ä‘áº¿n khi cÃ¡c centroid khÃ´ng thay Ä‘á»•i.

    ### 3. Thuáº­t toÃ¡n K-means
    1. Chá»n K vÃ  khá»Ÿi táº¡o cÃ¡c centroid.
    2. GÃ¡n má»—i Ä‘iá»ƒm dá»¯ liá»‡u vÃ o cá»¥m cÃ³ centroid gáº§n nháº¥t.
    3. TÃ­nh toÃ¡n láº¡i centroid cá»§a cÃ¡c cá»¥m.
    4. Láº·p láº¡i cÃ¡c bÆ°á»›c trÃªn cho Ä‘áº¿n khi khÃ´ng cÃ³ sá»± thay Ä‘á»•i.

    ### 4. ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng phÃ¢n cá»¥m
    Má»™t trong nhá»¯ng cÃ¡ch Ä‘Ã¡nh giÃ¡ phá»• biáº¿n lÃ  sá»­ dá»¥ng **Inertia** (hoáº·c SSE - Sum of Squared Errors), tÃ­nh báº±ng tá»•ng bÃ¬nh phÆ°Æ¡ng khoáº£ng cÃ¡ch giá»¯a cÃ¡c Ä‘iá»ƒm vÃ  centroid tÆ°Æ¡ng á»©ng. Inertia cÃ ng nhá», cÃ¡c cá»¥m cÃ ng cháº·t cháº½.

    ### 5. CÃ¡c cáº£i tiáº¿n cá»§a K-means
    - **K-means++**: PhÆ°Æ¡ng phÃ¡p nÃ y cáº£i thiá»‡n viá»‡c khá»Ÿi táº¡o centroid Ä‘á»ƒ giáº£m thiá»ƒu rá»§i ro dÃ­nh vÃ o tá»‘i Æ°u Ä‘á»‹a phÆ°Æ¡ng.
    - **Elbow Method**: PhÆ°Æ¡ng phÃ¡p nÃ y giÃºp xÃ¡c Ä‘á»‹nh K tá»‘i Æ°u báº±ng cÃ¡ch váº½ Ä‘á»“ thá»‹ Inertia theo K vÃ  tÃ¬m Ä‘iá»ƒm "elbow", nÆ¡i Ä‘á»™ giáº£m cá»§a Inertia báº¯t Ä‘áº§u cháº­m láº¡i.

    ### 6. á»¨ng dá»¥ng cá»§a K-means
    K-means cÃ³ thá»ƒ á»©ng dá»¥ng trong nhiá»u lÄ©nh vá»±c:
    - PhÃ¢n loáº¡i khÃ¡ch hÃ ng trong marketing (segmentation).
    - PhÃ¢n tÃ­ch hÃ¬nh áº£nh vÃ  nháº­n dáº¡ng máº«u.
    - PhÃ¢n cá»¥m tÃ i liá»‡u trong xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn (NLP).
    - PhÃ¢n tÃ­ch dá»¯ liá»‡u gene trong sinh há»c.

    ### 7. VÃ­ dá»¥ vá» K-means trong Python
    DÆ°á»›i Ä‘Ã¢y lÃ  vÃ­ dá»¥ sá»­ dá»¥ng K-means vá»›i thÆ° viá»‡n scikit-learn:

    ```python
    import numpy as np
    import matplotlib.pyplot as plt
    from sklearn.cluster import KMeans
    from sklearn.datasets import make_blobs

    # Táº¡o dá»¯ liá»‡u giáº£
    X, _ = make_blobs(n_samples=1000, centers=4, random_state=42)

    # Khá»Ÿi táº¡o vÃ  huáº¥n luyá»‡n mÃ´ hÃ¬nh K-means vá»›i K=4
    kmeans = KMeans(n_clusters=4, random_state=42)
    kmeans.fit(X)

    # Dá»± Ä‘oÃ¡n nhÃ£n cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u
    y_kmeans = kmeans.predict(X)

    # Váº½ Ä‘á»“ thá»‹ phÃ¢n cá»¥m
    plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')

    # Váº½ cÃ¡c centroid
    centers = kmeans.cluster_centers_
    plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, marker='X')
    plt.title("K-means Clustering")
    plt.show()
    ```

    **MÃ´ táº£**:
    - Táº¡o dá»¯ liá»‡u giáº£ vá»›i 4 cá»¥m.
    - Ãp dá»¥ng thuáº­t toÃ¡n K-means vá»›i K=4.
    - Váº½ Ä‘á»“ thá»‹ phÃ¢n cá»¥m vá»›i cÃ¡c centroid mÃ u Ä‘á».
    """)



def ly_thuyet_dbscans():
    # TiÃªu Ä‘á» á»©ng dá»¥ng
    st.title("Thuáº­t ToÃ¡n DBSCAN - Density-Based Spatial Clustering with Noise")

    # MÃ´ táº£ lÃ½ thuyáº¿t
    st.header("1. Má»¥c tiÃªu cá»§a DBSCAN")
    st.write("""
        DBSCAN (Density-Based Spatial Clustering of Applications with Noise) lÃ  má»™t thuáº­t toÃ¡n phÃ¢n cá»¥m khÃ´ng giÃ¡m sÃ¡t, 
        Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ phÃ¢n chia dá»¯ liá»‡u thÃ nh cÃ¡c cá»¥m dá»±a trÃªn máº­t Ä‘á»™ Ä‘iá»ƒm dá»¯ liá»‡u vÃ  phÃ¡t hiá»‡n cÃ¡c Ä‘iá»ƒm ngoáº¡i lai.
        Thuáº­t toÃ¡n nÃ y khÃ´ng yÃªu cáº§u báº¡n pháº£i chá»‰ Ä‘á»‹nh sá»‘ cá»¥m K trÆ°á»›c khi cháº¡y vÃ  cÃ³ kháº£ nÄƒng phÃ¡t hiá»‡n cÃ¡c Ä‘iá»ƒm ngoáº¡i lai.
    """)
    st.image("https://miro.medium.com/v2/resize:fit:875/0*PAjsvIpK5dmNXfM0.png", caption = "Phan cum dbscan", use_column_width=True)

    st.header("2. CÃ¡ch thá»©c hoáº¡t Ä‘á»™ng cá»§a DBSCAN")
    st.write("""
        Thuáº­t toÃ¡n DBSCAN hoáº¡t Ä‘á»™ng theo ba bÆ°á»›c cÆ¡ báº£n:
        - **Äiá»ƒm lÃµi (Core point)**: Má»™t Ä‘iá»ƒm Ä‘Æ°á»£c coi lÃ  Ä‘iá»ƒm lÃµi náº¿u cÃ³ Ã­t nháº¥t MinPts Ä‘iá»ƒm trong bÃ¡n kÃ­nh Epsilon.
        - **Äiá»ƒm biÃªn (Border point)**: LÃ  Ä‘iá»ƒm khÃ´ng pháº£i Ä‘iá»ƒm lÃµi nhÆ°ng náº±m trong bÃ¡n kÃ­nh Epsilon cá»§a má»™t Ä‘iá»ƒm lÃµi.
        - **Äiá»ƒm ngoáº¡i lai (Noise point)**: LÃ  Ä‘iá»ƒm khÃ´ng pháº£i Ä‘iá»ƒm lÃµi vÃ  khÃ´ng náº±m trong bÃ¡n kÃ­nh Epsilon cá»§a báº¥t ká»³ Ä‘iá»ƒm lÃµi nÃ o.
        
        DBSCAN hoáº¡t Ä‘á»™ng qua cÃ¡c bÆ°á»›c sau:
        1. Khá»Ÿi táº¡o: Chá»n má»™t Ä‘iá»ƒm chÆ°a Ä‘Æ°á»£c phÃ¢n cá»¥m.
        2. XÃ¢y dá»±ng cá»¥m: Náº¿u Ä‘iá»ƒm nÃ y lÃ  Ä‘iá»ƒm lÃµi, má»Ÿ rá»™ng cá»¥m tá»« Ä‘iá»ƒm lÃµi Ä‘Ã³, bao gá»“m cÃ¡c Ä‘iá»ƒm biÃªn vÃ  cÃ¡c Ä‘iá»ƒm lÃµi.
        3. Äiá»ƒm ngoáº¡i lai: CÃ¡c Ä‘iá»ƒm khÃ´ng thuá»™c báº¥t ká»³ cá»¥m nÃ o sáº½ lÃ  Ä‘iá»ƒm ngoáº¡i lai.
    """)

    # Thá»±c hiá»‡n phÃ¢n cá»¥m DBSCAN
    st.header("3. PhÃ¢n cá»¥m vá»›i DBSCAN")
    st.write("""
        DÆ°á»›i Ä‘Ã¢y lÃ  vÃ­ dá»¥ vá» phÃ¢n cá»¥m dá»¯ liá»‡u báº±ng thuáº­t toÃ¡n DBSCAN.
        Thuáº­t toÃ¡n sáº½ phÃ¢n chia dá»¯ liá»‡u thÃ nh cÃ¡c cá»¥m dá»±a trÃªn máº­t Ä‘á»™ vÃ  phÃ¡t hiá»‡n cÃ¡c Ä‘iá»ƒm ngoáº¡i lai.
    """)

    # Táº¡o dá»¯ liá»‡u giáº£
    X, _ = make_blobs(n_samples=1000, centers=4, random_state=42)

    # Khá»Ÿi táº¡o vÃ  huáº¥n luyá»‡n mÃ´ hÃ¬nh DBSCAN
    dbscan = DBSCAN(eps=0.3, min_samples=10)
    y_dbscan = dbscan.fit_predict(X)

    # Váº½ Ä‘á»“ thá»‹ phÃ¢n cá»¥m
    fig, ax = plt.subplots()
    scatter = ax.scatter(X[:, 0], X[:, 1], c=y_dbscan, cmap='viridis')
    centroids = dbscan.components_

    # ThÃªm tiÃªu Ä‘á» vÃ  hiá»ƒn thá»‹ Ä‘á»“ thá»‹
    plt.title("PhÃ¢n Cá»¥m DBSCAN")
    plt.xlabel("Feature 1")
    plt.ylabel("Feature 2")
    st.pyplot(fig)

    # Hiá»ƒn thá»‹ giáº£i thÃ­ch vá» cÃ¡c Ä‘iá»ƒm ngoáº¡i lai
    st.header("4. Äiá»ƒm Ngoáº¡i Lai")
    st.write("""
        CÃ¡c Ä‘iá»ƒm ngoáº¡i lai (noise points) sáº½ Ä‘Æ°á»£c gÃ¡n nhÃ£n lÃ  -1 vÃ  khÃ´ng thuá»™c vÃ o báº¥t ká»³ cá»¥m nÃ o. 
        Trong Ä‘á»“ thá»‹ trÃªn, cÃ¡c Ä‘iá»ƒm ngoáº¡i lai sáº½ cÃ³ mÃ u sáº¯c khÃ¡c biá»‡t.
    """)

    st.header("5. Æ¯u Ä‘iá»ƒm vÃ  NhÆ°á»£c Ä‘iá»ƒm cá»§a DBSCAN")
    st.write("""
        **Æ¯u Ä‘iá»ƒm**:
        - KhÃ´ng cáº§n biáº¿t trÆ°á»›c sá»‘ cá»¥m.
        - PhÃ¡t hiá»‡n Ä‘iá»ƒm ngoáº¡i lai ráº¥t hiá»‡u quáº£.
        - PhÃ¢n cá»¥m cÃ¡c dáº¡ng hÃ¬nh phá»©c táº¡p.
        
        **NhÆ°á»£c Ä‘iá»ƒm**:
        - Cáº§n chá»n tham sá»‘ **Epsilon** vÃ  **MinPts** phÃ¹ há»£p.
        - KhÃ³ xá»­ lÃ½ vá»›i dá»¯ liá»‡u cÃ³ máº­t Ä‘á»™ khÃ´ng Ä‘á»“ng Ä‘á»u.
        - KhÃ´ng hiá»‡u quáº£ vá»›i dá»¯ liá»‡u quÃ¡ lá»›n.
    """)

def data(): 
    st.title("ğŸ“š Táº­p Dá»¯ Liá»‡u MNIST")
    
    st.markdown("""
    Táº­p dá»¯ liá»‡u **MNIST (Modified National Institute of Standards and Technology)** lÃ  má»™t trong nhá»¯ng bá»™ dá»¯ liá»‡u ná»•i báº­t vÃ  phá»• biáº¿n nháº¥t trong lÄ©nh vá»±c há»c mÃ¡y vÃ  nháº­n dáº¡ng hÃ¬nh áº£nh. ÄÃ¢y lÃ  táº­p dá»¯ liá»‡u bao gá»“m cÃ¡c hÃ¬nh áº£nh cá»§a cÃ¡c chá»¯ sá»‘ viáº¿t tay tá»« 0 Ä‘áº¿n 9, Ä‘Æ°á»£c thu tháº­p Ä‘á»ƒ thá»­ nghiá»‡m cÃ¡c thuáº­t toÃ¡n phÃ¢n loáº¡i vÃ  nháº­n dáº¡ng máº«u.
    
    ![Mnist-dataset](https://datasets.activeloop.ai/wp-content/uploads/2019/12/MNIST-handwritten-digits-dataset-visualized-by-Activeloop.webp)
                               

    ## 1. Tá»•ng Quan vá» MNIST:
    MNIST gá»“m hai pháº§n chÃ­nh:
    
    - **Dá»¯ liá»‡u huáº¥n luyá»‡n (Training Set)**: Gá»“m 60.000 hÃ¬nh áº£nh.
    - **Dá»¯ liá»‡u kiá»ƒm tra (Test Set)**: Gá»“m 10.000 hÃ¬nh áº£nh.
    
    Má»—i hÃ¬nh áº£nh trong bá»™ dá»¯ liá»‡u cÃ³ kÃ­ch thÆ°á»›c lÃ  28x28 pixel vÃ  biá»ƒu diá»…n má»™t trong 10 chá»¯ sá»‘ (0 Ä‘áº¿n 9). Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chuáº©n hÃ³a, vá»›i cÃ¡c hÃ¬nh áº£nh Ä‘Æ°á»£c cÄƒn chá»‰nh vÃ  cÃ³ ná»n tráº¯ng, giÃºp viá»‡c xá»­ lÃ½ trá»Ÿ nÃªn Ä‘Æ¡n giáº£n hÆ¡n.
    
    ## 2. Má»¥c TiÃªu Sá»­ Dá»¥ng Táº­p Dá»¯ Liá»‡u MNIST:
    MNIST chá»§ yáº¿u Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ huáº¥n luyá»‡n vÃ  kiá»ƒm tra cÃ¡c thuáº­t toÃ¡n phÃ¢n loáº¡i. CÃ¡c má»¥c tiÃªu chÃ­nh khi lÃ m viá»‡c vá»›i MNIST bao gá»“m:
    
    - **PhÃ¢n loáº¡i chá»¯ sá»‘ viáº¿t tay**: Dá»± Ä‘oÃ¡n chá»¯ sá»‘ tÆ°Æ¡ng á»©ng vá»›i má»—i hÃ¬nh áº£nh.
    - **Kiá»ƒm thá»­ mÃ´ hÃ¬nh há»c mÃ¡y**: ÄÆ°á»£c sá»­ dá»¥ng Ä‘á»ƒ kiá»ƒm tra hiá»‡u quáº£ cá»§a cÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y, tá»« cÃ¡c thuáº­t toÃ¡n cá»• Ä‘iá»ƒn nhÆ° K-Nearest Neighbors (KNN), Support Vector Machines (SVM) Ä‘áº¿n cÃ¡c mÃ´ hÃ¬nh há»c sÃ¢u nhÆ° máº¡ng nÆ¡-ron tÃ­ch cháº­p (CNN).
    - **Tiá»n xá»­ lÃ½ vÃ  há»c mÃ¡y cÆ¡ báº£n**: ÄÃ¢y lÃ  má»™t bá»™ dá»¯ liá»‡u tuyá»‡t vá»i Ä‘á»ƒ hiá»ƒu rÃµ cÃ¡c quy trÃ¬nh tiá»n xá»­ lÃ½ dá»¯ liá»‡u vÃ  cÃ¡ch thá»©c hoáº¡t Ä‘á»™ng cá»§a cÃ¡c mÃ´ hÃ¬nh phÃ¢n loáº¡i.
    
    ## 3. Cáº¥u TrÃºc Dá»¯ Liá»‡u MNIST:
    Má»—i hÃ¬nh áº£nh trong bá»™ dá»¯ liá»‡u MNIST cÃ³ kÃ­ch thÆ°á»›c 28x28 pixel, tá»©c lÃ  má»—i hÃ¬nh áº£nh sáº½ cÃ³ 784 giÃ¡ trá»‹ sá»‘ nguyÃªn, tÆ°Æ¡ng á»©ng vá»›i Ä‘á»™ sÃ¡ng cá»§a tá»«ng pixel. Táº¥t cáº£ cÃ¡c giÃ¡ trá»‹ nÃ y sáº½ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh. Dá»¯ liá»‡u nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng cho cÃ¡c tÃ¡c vá»¥ nhÆ°:
    
    - **PhÃ¢n loáº¡i hÃ¬nh áº£nh**: CÃ¡c mÃ´ hÃ¬nh há»c mÃ¡y cÃ³ thá»ƒ há»c cÃ¡ch phÃ¢n loáº¡i cÃ¡c hÃ¬nh áº£nh thÃ nh cÃ¡c nhÃ³m chá»¯ sá»‘ tá»« 0 Ä‘áº¿n 9.
    - **Tiá»n xá»­ lÃ½ hÃ¬nh áº£nh**: Viá»‡c chuáº©n hÃ³a dá»¯ liá»‡u vÃ  Ã¡p dá»¥ng cÃ¡c ká»¹ thuáº­t tiá»n xá»­ lÃ½ giÃºp cáº£i thiá»‡n hiá»‡u quáº£ cá»§a mÃ´ hÃ¬nh.
    
    ## 4. á»¨ng Dá»¥ng Cá»§a Táº­p Dá»¯ Liá»‡u MNIST:
    - **Nháº­n dáº¡ng chá»¯ viáº¿t tay**: ÄÃ¢y lÃ  á»©ng dá»¥ng phá»• biáº¿n nháº¥t cá»§a MNIST.
    - **Há»c sÃ¢u vÃ  phÃ¢n loáº¡i hÃ¬nh áº£nh**: CÃ¡c mÃ´ hÃ¬nh há»c sÃ¢u, Ä‘áº·c biá»‡t lÃ  máº¡ng nÆ¡-ron tÃ­ch cháº­p, Ä‘Æ°á»£c huáº¥n luyá»‡n vá»›i bá»™ dá»¯ liá»‡u nÃ y Ä‘á»ƒ phÃ¢n loáº¡i chá»¯ sá»‘.
    """)

def up_load_db():
    # TiÃªu Ä‘á»
    st.header("ğŸ“¥ Táº£i Dá»¯ Liá»‡u")

    # Kiá»ƒm tra xem dá»¯ liá»‡u Ä‘Ã£ táº£i chÆ°a
    if "data" in st.session_state and st.session_state.data is not None:
        st.warning("ğŸ”¸ **Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c táº£i lÃªn rá»“i!** Báº¡n cÃ³ thá»ƒ tiáº¿p tá»¥c vá»›i cÃ¡c bÆ°á»›c tiá»n xá»­ lÃ½ vÃ  chia dá»¯ liá»‡u.")
    else:
        # Chá»n nguá»“n dá»¯ liá»‡u
        option = st.radio("Chá»n nguá»“n dá»¯ liá»‡u:", ["Táº£i tá»« OpenML", "Upload dá»¯ liá»‡u"], key="data_source_radio")

        # Biáº¿n Ä‘á»ƒ lÆ°u trá»¯ dá»¯ liá»‡u
        if "data" not in st.session_state:
            st.session_state.data = None

        # Náº¿u chá»n táº£i tá»« OpenML
        if option == "Táº£i tá»« OpenML":
            st.markdown("#### ğŸ“‚ Táº£i dá»¯ liá»‡u MNIST tá»« OpenML")
            if st.button("Táº£i dá»¯ liá»‡u MNIST", key="download_mnist_button"):
                st.write("ğŸ”„ Äang táº£i dá»¯ liá»‡u MNIST tá»« OpenML...")
                
                # Táº£i dá»¯ liá»‡u MNIST tá»« file .npy
                X = np.load("X.npy")
                y = np.load("y.npy")
                
                # Hiá»ƒn thá»‹ 5 dÃ²ng dá»¯ liá»‡u Ä‘áº§u tiÃªn, chuyá»ƒn Ä‘á»•i má»—i áº£nh thÃ nh vector 1 chiá»u
                st.write("ğŸ“Š **Dá»¯ liá»‡u máº«u:**")
                X_reshaped = X[:5].reshape(5, -1)  # Chuyá»ƒn Ä‘á»•i 5 áº£nh Ä‘áº§u tiÃªn thÃ nh cÃ¡c vector 1 chiá»u
                st.write(pd.DataFrame(X_reshaped))  # Hiá»ƒn thá»‹ dÆ°á»›i dáº¡ng DataFrame

                st.success("âœ… Dá»¯ liá»‡u MNIST Ä‘Ã£ Ä‘Æ°á»£c táº£i thÃ nh cÃ´ng!")
                st.session_state.data = (X, y)  # LÆ°u dá»¯ liá»‡u vÃ o session_state

        # Náº¿u chá»n upload dá»¯ liá»‡u tá»« mÃ¡y
        else:
            st.markdown("#### ğŸ“¤ Upload dá»¯ liá»‡u cá»§a báº¡n")

            uploaded_file = st.file_uploader("Chá»n má»™t file áº£nh", type=["png", "jpg", "jpeg"], key="file_upload")

            if uploaded_file is not None:
                # Má»Ÿ file hÃ¬nh áº£nh
                image = Image.open(uploaded_file)

                # Hiá»ƒn thá»‹ áº£nh
                st.image(image, caption="áº¢nh Ä‘Ã£ táº£i lÃªn", use_column_width=True)

                # Kiá»ƒm tra kÃ­ch thÆ°á»›c áº£nh
                if image.size != (28, 28):
                    st.error("âŒ áº¢nh khÃ´ng Ä‘Ãºng kÃ­ch thÆ°á»›c 28x28 pixel. Vui lÃ²ng táº£i láº¡i áº£nh Ä‘Ãºng Ä‘á»‹nh dáº¡ng.")
                else:
                    st.success("âœ… áº¢nh há»£p lá»‡!")
                    # Chuyá»ƒn Ä‘á»•i hÃ¬nh áº£nh thÃ nh dáº¡ng máº£ng cho mÃ´ hÃ¬nh
                    image = image.convert('L')  # Chuyá»ƒn thÃ nh áº£nh grayscale
                    image_array = np.array(image).reshape(1, -1)  # Reshape Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch vá»›i mÃ´ hÃ¬nh
                    st.session_state.data = image_array  # LÆ°u áº£nh vÃ o session_state

    # Kiá»ƒm tra náº¿u dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c táº£i
    if st.session_state.data is not None:
        st.markdown("#### âœ… Dá»¯ liá»‡u Ä‘Ã£ sáºµn sÃ ng!")
        
        # Náº¿u lÃ  dá»¯ liá»‡u MNIST tá»« OpenML
        if isinstance(st.session_state.data, tuple):
            X, y = st.session_state.data
            # Tiá»n xá»­ lÃ½ dá»¯ liá»‡u MNIST
            st.markdown("##### ğŸ”„ Tiáº¿n hÃ nh tiá»n xá»­ lÃ½ dá»¯ liá»‡u MNIST")

            # Chá»n loáº¡i tiá»n xá»­ lÃ½
            preprocess_option = st.selectbox("Chá»n phÆ°Æ¡ng phÃ¡p tiá»n xá»­ lÃ½ dá»¯ liá»‡u:", 
                                            ["Chuáº©n hÃ³a dá»¯ liá»‡u (Standardization)", "Giáº£m chiá»u (PCA)", "KhÃ´ng tiá»n xá»­ lÃ½"], key="preprocess_mnist")

            if preprocess_option == "Chuáº©n hÃ³a dá»¯ liá»‡u (Standardization)":
                # Chuyá»ƒn Ä‘á»•i X thÃ nh máº£ng 2D
                X_reshaped = X.reshape(X.shape[0], -1)  # Reshape thÃ nh (n_samples, n_features)
                # Chuáº©n hÃ³a dá»¯ liá»‡u
                scaler = StandardScaler()
                X_scaled = scaler.fit_transform(X_reshaped)
                st.write("ğŸ“Š **Dá»¯ liá»‡u sau khi chuáº©n hÃ³a**:")
                st.write(pd.DataFrame(X_scaled).head())

            elif preprocess_option == "Giáº£m chiá»u (PCA)":
                # Giáº£m chiá»u dá»¯ liá»‡u vá»›i PCA
                pca = PCA(n_components=50)  # Giáº£m xuá»‘ng 50 chiá»u
                X_pca = pca.fit_transform(X.reshape(X.shape[0], -1))  # Reshape trÆ°á»›c khi PCA
                st.write("ğŸ“Š **Dá»¯ liá»‡u sau khi giáº£m chiá»u (PCA)**:")
                st.write(pd.DataFrame(X_pca).head())

            else:
                st.write("ğŸ“Š **Dá»¯ liá»‡u khÃ´ng cÃ³ tiá»n xá»­ lÃ½**.")

        # Náº¿u lÃ  áº£nh táº£i lÃªn tá»« mÃ¡y
        elif isinstance(st.session_state.data, np.ndarray):  # Náº¿u lÃ  áº£nh ngÆ°á»i dÃ¹ng táº£i lÃªn
            st.markdown("#### ğŸ‘ï¸ Tiáº¿n hÃ nh tiá»n xá»­ lÃ½ áº£nh")

            # Chá»n loáº¡i tiá»n xá»­ lÃ½ cho áº£nh
            preprocess_option_image = st.selectbox("Chá»n phÆ°Æ¡ng phÃ¡p tiá»n xá»­ lÃ½ áº£nh:",
                                                   ["Chuáº©n hÃ³a áº£nh", "KhÃ´ng tiá»n xá»­ lÃ½"], key="preprocess_image")

            if preprocess_option_image == "Chuáº©n hÃ³a áº£nh":
                # Chuáº©n hÃ³a áº£nh
                image_scaled = st.session_state.data / 255.0  # Chuyá»ƒn Ä‘á»•i giÃ¡ trá»‹ pixel vá» pháº¡m vi [0, 1]
                st.write("ğŸ“Š **áº¢nh sau khi chuáº©n hÃ³a**:")
                st.image(image_scaled.reshape(28, 28), caption="áº¢nh sau khi chuáº©n hÃ³a", use_column_width=True)

            else:
                st.write("ğŸ“Š **áº¢nh khÃ´ng cÃ³ tiá»n xá»­ lÃ½**.")

    else:
        st.warning("ğŸ”¸ Vui lÃ²ng táº£i dá»¯ liá»‡u trÆ°á»›c khi tiáº¿p tá»¥c lÃ m viá»‡c.")

    # Hiá»ƒn thá»‹ lÆ°u Ã½
    st.markdown("""
    ğŸ”¹ **LÆ°u Ã½:**
    - á»¨ng dá»¥ng chá»‰ sá»­ dá»¥ng dá»¯ liá»‡u áº£nh dáº¡ng **28x28 pixel (grayscale)**.
    - Dá»¯ liá»‡u pháº£i cÃ³ cá»™t **'label'** chá»©a nhÃ£n (sá»‘ tá»« 0 Ä‘áº¿n 9) khi táº£i tá»« OpenML.
    - Náº¿u dá»¯ liá»‡u cá»§a báº¡n khÃ´ng Ä‘Ãºng Ä‘á»‹nh dáº¡ng, vui lÃ²ng sá»­ dá»¥ng dá»¯ liá»‡u MNIST tá»« OpenML.
    """)


def chia_du_lieu():
    st.title("ğŸ“Œ Chia dá»¯ liá»‡u Train/Test")

    # Äá»c dá»¯ liá»‡u tá»« file
    X = np.load("X.npy")
    y = np.load("y.npy")
    total_samples = X.shape[0]

    # Náº¿u dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia trÆ°á»›c Ä‘Ã³, hiá»ƒn thá»‹ thÃ´ng tin vÃ  khÃ´ng chia láº¡i
    if "X_train" in st.session_state:
        st.success("âœ… **Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia, khÃ´ng cáº§n cháº¡y láº¡i!**")

        # Hiá»ƒn thá»‹ báº£ng dá»¯ liá»‡u Ä‘Ã£ chia
        summary_df = pd.DataFrame({
            "Táº­p dá»¯ liá»‡u": ["Train", "Validation", "Test"],
            "Sá»‘ lÆ°á»£ng máº«u": [
                len(st.session_state["X_train"]),
                len(st.session_state["X_val"]),
                len(st.session_state["X_test"])
            ]
        })
        st.table(summary_df)
        return

    # Thanh chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train
    num_samples = st.slider("ğŸ“Œ Chá»n sá»‘ lÆ°á»£ng áº£nh Ä‘á»ƒ train:", 1000, total_samples, 10000)

    # Thanh chá»n % dá»¯ liá»‡u Test
    test_size = st.slider("ğŸ“Œ Chá»n % dá»¯ liá»‡u Test", 10, 50, 20)
    remaining_size = 100 - test_size  # TÃ­nh pháº§n cÃ²n láº¡i cá»§a táº­p Train

    # Thanh chá»n % dá»¯ liá»‡u Validation (trong táº­p Train)
    val_size = st.slider("ğŸ“Œ Chá»n % dá»¯ liá»‡u Validation (trong pháº§n Train)", 0, 50, 15)

    st.markdown(f"### ğŸ“Œ **Tá»· lá»‡ phÃ¢n chia:** Test={test_size}%, Validation={val_size}%, Train={remaining_size - val_size}%")

    if st.button("âœ… XÃ¡c nháº­n & LÆ°u"):
        # Chá»n táº­p dá»¯ liá»‡u theo sá»‘ lÆ°á»£ng máº«u mong muá»‘n
        X_selected, _, y_selected, _ = train_test_split(X, y, train_size=num_samples, stratify=y, random_state=42)

        # Chia train/test
        X_train_full, X_test, y_train_full, y_test = train_test_split(X_selected, y_selected, 
                                                                      test_size=test_size / 100, 
                                                                      stratify=y_selected, random_state=42)

        # Chia train/val
        X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, 
                                                          test_size=val_size / (100 - test_size), 
                                                          stratify=y_train_full, random_state=42)

        # LÆ°u dá»¯ liá»‡u vÃ o session_state Ä‘á»ƒ sá»­ dá»¥ng sau nÃ y
        st.session_state["X_train"] = X_train
        st.session_state["X_val"] = X_val
        st.session_state["X_test"] = X_test
        st.session_state["y_train"] = y_train
        st.session_state["y_val"] = y_val
        st.session_state["y_test"] = y_test

        # Táº¡o báº£ng hiá»ƒn thá»‹ sá»‘ lÆ°á»£ng máº«u cá»§a tá»«ng táº­p dá»¯ liá»‡u
        summary_df = pd.DataFrame({
            "Táº­p dá»¯ liá»‡u": ["Train", "Validation", "Test"],
            "Sá»‘ lÆ°á»£ng máº«u": [X_train.shape[0], X_val.shape[0], X_test.shape[0]]
        })

        st.success("âœ… **Dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c chia thÃ nh cÃ´ng!**")
        st.table(summary_df)

###Thiet lap dagshub
def mlflow_input():
    #st.title("ğŸš€ MLflow DAGsHub Tracking vá»›i Streamlit")
    DAGSHUB_USERNAME = "Snxtruc"  # Thay báº±ng username cá»§a báº¡n
    DAGSHUB_REPO_NAME = "HocMayPython"
    DAGSHUB_TOKEN = "ca4b78ae4dd9d511c1e0c333e3b709b2cd789a19"  # Thay báº±ng Access Token cá»§a báº¡n

    # Äáº·t URI MLflow Ä‘á»ƒ trá» Ä‘áº¿n DagsHub
    mlflow.set_tracking_uri(f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO_NAME}.mlflow")

    # Thiáº¿t láº­p authentication báº±ng Access Token
    os.environ["MLFLOW_TRACKING_USERNAME"] = DAGSHUB_USERNAME
    os.environ["MLFLOW_TRACKING_PASSWORD"] = DAGSHUB_TOKEN

    # Äáº·t thÃ­ nghiá»‡m MLflow
    mlflow.set_experiment("Clustering Algorithms")   

    st.session_state['mlflow_url'] = f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO_NAME}.mlflow"

def train():
    st.header("âš™ï¸ Chá»n mÃ´ hÃ¬nh & Huáº¥n luyá»‡n")

    if "X_train" not in st.session_state:
        st.warning("âš ï¸ Vui lÃ²ng chia dá»¯ liá»‡u trÆ°á»›c khi train!")
        return

    X_train = st.session_state["X_train"]
    y_train = st.session_state["y_train"]
    X_train_norm = (X_train / 255.0).reshape(X_train.shape[0], -1)  # Chuáº©n hÃ³a vÃ  lÃ m pháº³ng

    model_choice = st.selectbox("Chá»n mÃ´ hÃ¬nh:", ["K-Means", "DBSCAN"])

    if model_choice == "K-Means":
        st.markdown("ğŸ”¹ **K-Means**")
        n_clusters = st.slider("ğŸ”¢ Chá»n sá»‘ cá»¥m (K):", 2, 20, 10)
        pca = PCA(n_components=2)
        X_train_pca = pca.fit_transform(X_train_norm)
        model = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)

    elif model_choice == "DBSCAN":
        st.markdown("ğŸ› ï¸ **DBSCAN**")
        eps = st.slider("ğŸ“ BÃ¡n kÃ­nh lÃ¢n cáº­n (eps):", 0.1, 10.0, 0.5)
        min_samples = st.slider("ğŸ‘¥ Sá»‘ Ä‘iá»ƒm tá»‘i thiá»ƒu trong cá»¥m:", 2, 20, 5)
        pca = PCA(n_components=2)
        X_train_pca = pca.fit_transform(X_train_norm)
        model = DBSCAN(eps=eps, min_samples=min_samples)

    mlflow_input()
    if st.button("ğŸš€ Huáº¥n luyá»‡n mÃ´ hÃ¬nh"):
        with mlflow.start_run():
            model.fit(X_train_pca)
            st.success("âœ… Huáº¥n luyá»‡n thÃ nh cÃ´ng!")

            labels = model.labels_

            if model_choice == "K-Means":
                label_mapping = {}
                for i in range(n_clusters):
                    mask = labels == i
                    if np.sum(mask) > 0:
                        most_common_label = stats.mode(y_train[mask], keepdims=True).mode[0]
                        label_mapping[i] = most_common_label

                predicted_labels = np.array([label_mapping[label] for label in labels])
                accuracy_train = np.mean(predicted_labels == y_train)
                st.write(f"ğŸ¯ **Äá»™ chÃ­nh xÃ¡c trÃªn táº­p train:** `{accuracy_train * 100:.2f}%`")

                # Kiá»ƒm tra vÃ  tÃ­nh Ä‘á»™ chÃ­nh xÃ¡c trÃªn táº­p validation vÃ  test náº¿u cÃ³
                if "X_val" in st.session_state and "y_val" in st.session_state:
                    X_val = st.session_state["X_val"]
                    y_val = st.session_state["y_val"]
                    X_val_norm = (X_val / 255.0).reshape(X_val.shape[0], -1)
                    X_val_pca = pca.transform(X_val_norm)
                    val_labels = model.predict(X_val_pca)
                    predicted_val_labels = np.array([label_mapping.get(label, -1) for label in val_labels])
                    accuracy_val = np.mean(predicted_val_labels == y_val)
                    st.write(f"ğŸ¯ **Äá»™ chÃ­nh xÃ¡c trÃªn táº­p validation:** `{accuracy_val * 100:.2f}%`")

                if "X_test" in st.session_state and "y_test" in st.session_state:
                    X_test = st.session_state["X_test"]
                    y_test = st.session_state["y_test"]
                    X_test_norm = (X_test / 255.0).reshape(X_test.shape[0], -1)
                    X_test_pca = pca.transform(X_test_norm)
                    test_labels = model.predict(X_test_pca)
                    predicted_test_labels = np.array([label_mapping.get(label, -1) for label in test_labels])
                    accuracy_test = np.mean(predicted_test_labels == y_test)
                    st.write(f"ğŸ¯ **Äá»™ chÃ­nh xÃ¡c trÃªn táº­p test:** `{accuracy_test * 100:.2f}%`")

                # Log vÃ o MLflow
                mlflow.log_param("model", "K-Means")
                mlflow.log_param("n_clusters", n_clusters)
                mlflow.log_metric("accuracy_train", accuracy_train)
                if "accuracy_val" in locals():
                    mlflow.log_metric("accuracy_val", accuracy_val)
                if "accuracy_test" in locals():
                    mlflow.log_metric("accuracy_test", accuracy_test)
                mlflow.sklearn.log_model(model, "kmeans_model")

            elif model_choice == "DBSCAN":
                unique_clusters = set(labels) - {-1}
                n_clusters_found = len(unique_clusters)
                noise_ratio = np.sum(labels == -1) / len(labels)
                st.write(f"ğŸ” **Sá»‘ cá»¥m tÃ¬m tháº¥y:** `{n_clusters_found}`")
                st.write(f"ğŸš¨ **Tá»‰ lá»‡ nhiá»…u:** `{noise_ratio * 100:.2f}%`")

                # Log vÃ o MLflow
                mlflow.log_param("model", "DBSCAN")
                mlflow.log_param("eps", eps)
                mlflow.log_param("min_samples", min_samples)
                mlflow.log_metric("n_clusters_found", n_clusters_found)
                mlflow.log_metric("noise_ratio", noise_ratio)
                mlflow.sklearn.log_model(model, "dbscan_model")

            if "models" not in st.session_state:
                st.session_state["models"] = []

            model_name = model_choice.lower().replace(" ", "_")
            count = 1
            new_model_name = model_name
            while any(m["name"] == new_model_name for m in st.session_state["models"]):
                new_model_name = f"{model_name}_{count}"
                count += 1

            st.session_state["models"].append({"name": new_model_name, "model": model})
            st.write(f"ğŸ”¹ **MÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vá»›i tÃªn:** `{new_model_name}`")
            st.write(f"ğŸ“‹ **Danh sÃ¡ch cÃ¡c mÃ´ hÃ¬nh:** {[m['name'] for m in st.session_state['models']]}")
            mlflow.end_run()
            st.success("âœ… ÄÃ£ log dá»¯ liá»‡u!")
            st.markdown(f"### ğŸ”— [Truy cáº­p MLflow]({st.session_state['mlflow_url']})")


def du_doan():
    st.header("Demo Dá»± Ä‘oÃ¡n Cá»¥m")

    # Kiá»ƒm tra xem mÃ´ hÃ¬nh phÃ¢n cá»¥m vÃ  nhÃ£n Ä‘Ã£ cÃ³ chÆ°a
    if 'cluster_model' in st.session_state and 'cluster_labels' in st.session_state:
        # Táº£i lÃªn áº£nh hoáº·c file CSV
        uploaded_image = st.file_uploader("Upload áº£nh chá»¯ sá»‘ (28x28, grayscale) hoáº·c file CSV", type=["png", "jpg", "csv"])
        true_label = st.text_input("Nháº­p nhÃ£n tháº­t (náº¿u cÃ³):")
        
        if uploaded_image is not None:
            if uploaded_image.name.endswith('.csv'):
                # Äá»c file CSV vÃ  tiá»n xá»­ lÃ½
                df = pd.read_csv(uploaded_image)
                # Giáº£ sá»­ dá»¯ liá»‡u CSV cÃ³ cá»™t tÃªn 'features' chá»©a dá»¯ liá»‡u Ä‘áº·c trÆ°ng áº£nh 28x28
                # Náº¿u file CSV cÃ³ cáº¥u trÃºc khÃ¡c, báº¡n cáº§n Ä‘iá»u chá»‰nh pháº§n nÃ y cho phÃ¹ há»£p
                img_array = df['features'].values.flatten() / 255.0  # Tiá»n xá»­ lÃ½ náº¿u cáº§n
            else:
                # Äá»c áº£nh vÃ  tiá»n xá»­ lÃ½
                img = Image.open(uploaded_image).convert('L').resize((28, 28))
                img_array = np.array(img).flatten() / 255.0  # Tiá»n xá»­ lÃ½ áº£nh Ä‘á»ƒ Ä‘Æ°a vá» dáº¡ng (1, 28*28)

            if st.button("Dá»± Ä‘oÃ¡n cá»¥m"):
                model = st.session_state['cluster_model']
                if isinstance(model, KMeans):
                    # Dá»± Ä‘oÃ¡n cá»¥m vá»›i KMeans
                    predicted_cluster = model.predict([img_array])[0]
                elif isinstance(model, DBSCAN):
                    # DBSCAN khÃ´ng cÃ³ phÆ°Æ¡ng thá»©c predict() nÃªn cáº§n tÃ­nh toÃ¡n khoáº£ng cÃ¡ch
                    # TÃ­nh toÃ¡n khoáº£ng cÃ¡ch vá»›i cÃ¡c Ä‘iá»ƒm dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c phÃ¢n cá»¥m
                    distances = np.linalg.norm(model.components_ - img_array, axis=1)
                    predicted_cluster = model.labels_[np.argmin(distances)]  # Dá»± Ä‘oÃ¡n cá»¥m vá»›i DBSCAN

                # Láº¥y nhÃ£n phÃ¢n cá»¥m tá»« session_state
                cluster_labels = st.session_state['cluster_labels']
                st.write(f"**Dá»± Ä‘oÃ¡n cá»¥m:** {predicted_cluster} - NhÃ£n phÃ¢n cá»¥m: {cluster_labels[predicted_cluster]}")

                # Ãnh xáº¡ cá»¥m thÃ nh chá»¯ sá»‘ náº¿u cÃ³
                if 'cluster_mapping' in st.session_state:
                    mapped_digit = st.session_state['cluster_mapping'].get(predicted_cluster, "N/A")
                    st.write(f"**MÃ£ hÃ³a thÃ nh chá»¯ sá»‘:** {mapped_digit}")
                    
                    if true_label:
                        if str(mapped_digit) == str(true_label):
                            st.success("Dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c!")
                        else:
                            st.error("Dá»± Ä‘oÃ¡n chÆ°a chÃ­nh xÃ¡c!")

                # Hiá»ƒn thá»‹ áº£nh hoáº·c dá»¯ liá»‡u tá»« file CSV
                if uploaded_image.name.endswith('.csv'):
                    st.write("Dá»¯ liá»‡u tá»« file CSV Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng cho dá»± Ä‘oÃ¡n.")
                else:
                    st.image(img, caption="áº¢nh Ä‘Ã£ upload", use_container_width=True)
    else:
        st.info("Vui lÃ²ng thá»±c hiá»‡n phÃ¢n cá»¥m vÃ  huáº¥n luyá»‡n mÃ´ hÃ¬nh trÆ°á»›c.")

def display_mlflow_experiments():
    try:
        st.title("ğŸ” Quáº£n lÃ½ MLflow Experiments")

        # Káº¿t ná»‘i MlflowClient
        client = MlflowClient()

        # Láº¥y danh sÃ¡ch thÃ­ nghiá»‡m
        experiments = mlflow.search_experiments()
        
        if experiments:
            st.write("### ğŸ“Œ Danh sÃ¡ch ThÃ­ nghiá»‡m")
            experiment_data = [
                {"Experiment ID": exp.experiment_id, "Experiment Name": exp.name, "Artifact Location": exp.artifact_location}
                for exp in experiments
            ]
            st.data_editor(pd.DataFrame(experiment_data))
            
            # Chá»n thÃ­ nghiá»‡m
            selected_exp_id = st.selectbox("ğŸ—‚ Chá»n thÃ­ nghiá»‡m", sorted([exp.experiment_id for exp in experiments]))
            
            # Äá»•i tÃªn thÃ­ nghiá»‡m
            new_exp_name = st.text_input("âœï¸ Nháº­p tÃªn má»›i cho thÃ­ nghiá»‡m", "")
            if st.button("ğŸ’¾ Äá»•i tÃªn") and new_exp_name:
                client.rename_experiment(selected_exp_id, new_exp_name)
                st.success("âœ… Äá»•i tÃªn thÃ nh cÃ´ng! Vui lÃ²ng táº£i láº¡i trang.")
            
            # XÃ³a thÃ­ nghiá»‡m
            if st.button("ğŸ—‘ï¸ XÃ³a thÃ­ nghiá»‡m"):
                client.delete_experiment(selected_exp_id)
                st.success("âœ… XÃ³a thÃ­ nghiá»‡m thÃ nh cÃ´ng! Vui lÃ²ng táº£i láº¡i trang.")
            
            # Láº¥y danh sÃ¡ch runs trong thÃ­ nghiá»‡m Ä‘Ã£ chá»n
            runs = client.search_runs(experiment_ids=[selected_exp_id])
            if runs:
                st.write("### ğŸ“Œ Danh sÃ¡ch Run")
                
                # Bá»™ lá»c tÃ¬m kiáº¿m Run
                search_term = st.text_input("ğŸ” TÃ¬m kiáº¿m Run", "")
                
                # Bá»™ lá»c theo khoáº£ng thá»i gian
                start_date = st.date_input("ğŸ“… Chá»n ngÃ y báº¯t Ä‘áº§u", pd.to_datetime("2023-01-01"))
                end_date = st.date_input("ğŸ“… Chá»n ngÃ y káº¿t thÃºc", pd.to_datetime("today"))
                
                # Bá»™ lá»c theo tráº¡ng thÃ¡i Run
                status_filter = st.multiselect("ğŸ“Œ Lá»c theo tráº¡ng thÃ¡i", ["RUNNING", "FINISHED", "FAILED", "KILLED"], default=["RUNNING", "FINISHED"])
                
                # Hiá»ƒn thá»‹ danh sÃ¡ch Runs
                run_data = [
                    {
                        "Run ID": run.info.run_id,
                        "Run Name": run.data.tags.get("mlflow.runName", "Unnamed"),
                        "Start Time": pd.to_datetime(run.info.start_time, unit='ms'),
                        "End Time": pd.to_datetime(run.info.end_time, unit='ms') if run.info.end_time else None,
                        "Duration": (pd.to_datetime(run.info.end_time, unit='ms') - pd.to_datetime(run.info.start_time, unit='ms')).total_seconds() if run.info.end_time else None,
                        "Status": run.info.status,
                        "Source": run.data.tags.get("mlflow.source.name", "Unknown"),
                        "Metrics": run.data.metrics
                    }
                    for run in runs
                ]
                df_runs = pd.DataFrame(run_data).sort_values(by="Start Time", ascending=False)
                
                # Ãp dá»¥ng bá»™ lá»c
                df_runs = df_runs[(df_runs["Start Time"] >= pd.to_datetime(start_date)) & (df_runs["Start Time"] <= pd.to_datetime(end_date))]
                df_runs = df_runs[df_runs["Status"].isin(status_filter)]
                
                if search_term:
                    df_runs = df_runs[df_runs["Run Name"].str.contains(search_term, case=False, na=False)]
                
                # Bá»™ lá»c theo Metrics cá»¥ thá»ƒ
                metric_name = st.text_input("ğŸ“Š Nháº­p tÃªn Metric Ä‘á»ƒ lá»c", "accuracy")
                metric_value = st.number_input("ğŸ“ˆ GiÃ¡ trá»‹ tá»‘i thiá»ƒu cá»§a Metric", min_value=0.0, step=0.01, format="%.2f")
                
                def filter_by_metric(run):
                    return metric_name in run["Metrics"] and run["Metrics"][metric_name] >= metric_value
                
                df_runs = df_runs[df_runs.apply(filter_by_metric, axis=1)]
                
                st.data_editor(df_runs)
                
                run_options = {run["Run ID"]: f"{run['Run Name']} - {run['Run ID']}" for _, run in df_runs.iterrows()}
                        
                # Chá»n Run trong thÃ­ nghiá»‡m Ä‘á»ƒ Ä‘á»•i tÃªn hoáº·c xÃ³a
                runs = client.search_runs(experiment_ids=[selected_exp_id])
                if runs:
                    run_options = {run.info.run_id: f"{run.data.tags.get('mlflow.runName', 'Unnamed')} - {run.info.run_id}" for run in runs}
                    selected_run_id = st.selectbox("âœï¸ Chá»n Run Ä‘á»ƒ Ä‘á»•i tÃªn", list(run_options.keys()), format_func=lambda x: run_options[x])
                    new_run_name = st.text_input("ğŸ“› Nháº­p tÃªn má»›i cho Run", "")
                    if st.button("âœ… Cáº­p nháº­t tÃªn Run") and new_run_name:
                        client.set_tag(selected_run_id, "mlflow.runName", new_run_name)
                        st.success("âœ… Cáº­p nháº­t tÃªn Run thÃ nh cÃ´ng! Vui lÃ²ng táº£i láº¡i trang.")
                    
                    selected_run_id_delete = st.selectbox("ğŸ—‘ï¸ Chá»n Run Ä‘á»ƒ xÃ³a", list(run_options.keys()), format_func=lambda x: run_options[x])
                    if st.button("âŒ XÃ³a Run"):
                        client.delete_run(selected_run_id_delete)
                        st.success("âœ… XÃ³a Run thÃ nh cÃ´ng! Vui lÃ²ng táº£i láº¡i trang.")
                    

                # Chá»n Run Ä‘á»ƒ xem chi tiáº¿t
                selected_run_id = st.selectbox("ğŸ” Chá»n Run Ä‘á»ƒ xem chi tiáº¿t", list(run_options.keys()), format_func=lambda x: run_options[x])
                selected_run = client.get_run(selected_run_id)
                
                st.write("### ğŸ“‹ ThÃ´ng tin Run")
                st.write(f"**Run ID:** {selected_run_id}")
                st.write(f"**Run Name:** {selected_run.data.tags.get('mlflow.runName', 'Unnamed')}")
                st.write(f"**Start Time:** {pd.to_datetime(selected_run.info.start_time, unit='ms')}")
                st.write(f"**End Time:** {pd.to_datetime(selected_run.info.end_time, unit='ms') if selected_run.info.end_time else 'N/A'}")
                st.write(f"**Duration:** {(pd.to_datetime(selected_run.info.end_time, unit='ms') - pd.to_datetime(selected_run.info.start_time, unit='ms')).total_seconds() if selected_run.info.end_time else 'N/A'} seconds")
                st.write(f"**Status:** {selected_run.info.status}")
                st.write(f"**Source:** {selected_run.data.tags.get('mlflow.source.name', 'Unknown')}")
                
                # Hiá»ƒn thá»‹ Metrics
                st.write("### ğŸ“Š Metrics")
                metrics = selected_run.data.metrics
                if metrics:
                    df_metrics = pd.DataFrame(metrics.items(), columns=["Metric Name", "Value"])
                    st.data_editor(df_metrics)
                else:
                    st.write("ğŸ“­ KhÃ´ng cÃ³ Metrics nÃ o.")
                
                # Hiá»ƒn thá»‹ Artifacts
                artifact_uri = selected_run.info.artifact_uri
                st.write(f"**Artifact Location:** {artifact_uri}")
                
                st.write("### ğŸ“‚ Danh sÃ¡ch Artifacts")
                artifacts = client.list_artifacts(selected_run_id)
                if artifacts:
                    artifact_paths = [artifact.path for artifact in artifacts]
                    st.write(artifact_paths)
                    for artifact in artifacts:
                        if artifact.path.endswith(".png") or artifact.path.endswith(".jpg"):
                            st.image(f"{artifact_uri}/{artifact.path}", caption=artifact.path)
                        if artifact.path.endswith(".csv") or artifact.path.endswith(".txt"):
                            with open(f"{artifact_uri}/{artifact.path}", "r") as f:
                                st.download_button(label=f"ğŸ“¥ Táº£i {artifact.path}", data=f.read(), file_name=artifact.path)
                else:
                    st.write("ğŸ“­ KhÃ´ng cÃ³ artifacts nÃ o.")
                
                # Truy cáº­p MLflow UI
                st.write("### ğŸ”— Truy cáº­p MLflow UI")
                st.markdown("[Má»Ÿ MLflow UI](https://dagshub.com/Snxtruc/HocMayVoiPython.mlflow)")
            else:
                st.warning("âš ï¸ KhÃ´ng cÃ³ Run nÃ o trong thÃ­ nghiá»‡m nÃ y.")
        else:
            st.warning("âš ï¸ KhÃ´ng cÃ³ ThÃ­ nghiá»‡m nÃ o Ä‘Æ°á»£c tÃ¬m tháº¥y.")
    except Exception as e:
        st.error(f"âŒ Lá»—i khi láº¥y danh sÃ¡ch thÃ­ nghiá»‡m: {e}")



def ClusteringAlgorithms():
  
    # Thiáº¿t láº­p CSS Ä‘á»ƒ há»— trá»£ hiá»ƒn thá»‹ tabs vá»›i hiá»‡u á»©ng hover vÃ  thanh cuá»™n
    st.markdown(
        """
        <style>
        .stTabs [role="tablist"] {
            overflow-x: auto;
            white-space: nowrap;
            display: flex;
            scrollbar-width: thin;
            scrollbar-color: #888 #f0f0f0;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar {
            height: 6px;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar-thumb {
            background-color: #888;
            border-radius: 3px;
        }
        .stTabs [role="tablist"]::-webkit-scrollbar-track {
            background: #f0f0f0;
        }
        .stTabs [role="tab"]:hover {
            background-color: #f0f0f0;
            transition: background-color 0.3s ease-in-out;
        }
        </style>
        """,
        unsafe_allow_html=True
    )

    st.title("ğŸ–Šï¸ MNIST Clusterings App")

    # Ensure the tab names are properly separated
    tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8 = st.tabs([
    "ğŸ“˜ LÃ½ thuyáº¿t K-MEANS", 
    "ğŸ“˜ LÃ½ thuyáº¿t DBSCANS", 
    "ğŸ“˜ Review database", 
    "ğŸ“¥ Táº£i dá»¯ liá»‡u", 
    "ğŸ”€ Chia dá»¯ liá»‡u", 
    "ğŸ¤– PhÃ¢n cá»¥m", 
    "ğŸ” ThÃ´ng tin phÃ¢n cá»¥m",
    "ğŸ§  Dá»± Ä‘oÃ¡n"
    ])


    with tab1:
        ly_thuyet_kmeans()

    with tab2:
        ly_thuyet_dbscans()
    
    with tab3:
        data()
        
    with tab4:
       up_load_db()
        
    with tab5:
        chia_du_lieu()
    
    with tab6: 
        train()

    with tab7: 
        display_mlflow_experiments() 
    
    with tab8: 
        du_doan()

def run():
    ClusteringAlgorithms()

if __name__ == "__main__":
    run()